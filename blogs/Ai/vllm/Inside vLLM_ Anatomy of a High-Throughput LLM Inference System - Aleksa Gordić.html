<!DOCTYPE html>
<!-- saved from url=(0038)https://www.aleksagordic.com/blog/vllm -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="preload" href="https://www.aleksagordic.com/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"><link rel="preload" href="https://www.aleksagordic.com/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/engine_constructor.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/engine_loop.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/kv_cache_blocks.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fwd_pass.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/chunked_pt1.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt1.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt2.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt3.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fsm.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fsm2.png"><link rel="stylesheet" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/0fea4a98dee3ff8f.css" data-precedence="next"><link rel="preload" as="script" fetchpriority="low" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/webpack-c7d969e615b48ab2.js.‰∏ãËΩΩ"><script src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/4bd1b696-c023c6e3521b1417.js.‰∏ãËΩΩ" async=""></script><script src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/255-5f42bd7b85567e6b.js.‰∏ãËΩΩ" async=""></script><script src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/main-app-f9b5d20365cb8be2.js.‰∏ãËΩΩ" async=""></script><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/specdec_pt1.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/specdec_pt2.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/pd.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/multiprocexecutor.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/server_setup.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/dpenginecoreproc.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/latency_diagram.png"><link rel="preload" as="image" href="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/roofline.png"><meta name="next-size-adjust" content=""><title>Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá</title><meta name="description" content="From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale."><meta name="keywords" content="How does vLLM work,how vllm works,vLLM explained,AGI,artificial intelligence,ASI,technology,vLLM,inference,engine"><meta name="robots" content="index, follow"><link rel="canonical" href="https://aleksagordic.com/blog/vllm"><meta property="og:title" content="Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá"><meta property="og:description" content="From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale."><meta property="og:image" content="https://aleksagordic.com/blog/vllm/engine_constructor.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="vLLM"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@gordic_aleksa"><meta name="twitter:title" content="Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá"><meta name="twitter:description" content="From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale."><meta name="twitter:image" content="https://aleksagordic.com/blog/vllm/engine_constructor.png"><meta name="twitter:image:width" content="1200"><meta name="twitter:image:height" content="630"><meta name="twitter:image:alt" content="vLLM"><link rel="icon" href="https://www.aleksagordic.com/profile_favicon.ico"><style>
          @font-face {
            font-family: 'Monaco';
            src: local('Monaco');
            font-display: swap;
          }
        </style><script src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/polyfills-42372ed130431b0a.js.‰∏ãËΩΩ" nomodule=""></script><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-dialog {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  display: flex;
  width: 300px;
  flex-direction: column;
  align-items: center;
  font-size: 15px;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto;
  height: fit-content;
  border-radius: 20px;
  background-color: #fff;
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
  word-break: break-all;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style></head><body class="__variable_188709 __variable_9a8899 antialiased font-mono"><div hidden=""><!--$--><!--/$--></div><div class="flex justify-center min-h-screen bg-white font-mono"><div class="text-left max-w-[800px] w-full mt-16 px-4 sm:px-8 lg:px-0"><div class="mb-6"><a href="https://www.aleksagordic.com/blog" class="underline decoration-1 decoration-black hover:decoration-2 text-gray-700">‚Üê Back to blog</a></div><article><header class="mb-8"><h1 class="font-bold text-black text-3xl mb-4">Inside vLLM: Anatomy of a High-Throughput LLM Inference System</h1><h2 class="text-black text-xl mb-3 mt-6">From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale</h2><p class="text-gray-600 text-sm">August 29, 2025</p></header><div class="prose prose-gray max-w-none leading-relaxed text-gray-700 [&amp;_p]:text-gray-700 [&amp;_p]:mb-4 [&amp;_code]:bg-gray-200 [&amp;_code]:text-red-600 [&amp;_code]:px-1 [&amp;_code]:py-0.5 [&amp;_code]:rounded [&amp;_code]:text-sm [&amp;_code]:font-mono [&amp;_ol]:text-gray-700 [&amp;_ol]:list-decimal [&amp;_ol]:list-inside [&amp;_ol]:pl-6 [&amp;_ol]:mb-6 [&amp;_ol]:mt-3 [&amp;_li]:mb-3 [&amp;_ul]:list-disc [&amp;_ul]:list-inside [&amp;_ul]:pl-6 [&amp;_ul]:space-y-1"><p>In this post, I'll gradually introduce all of the core system components and advanced features that make up a modern high-throughput LLM inference system. In particular I'll be doing a breakdown of how vLLM <a href="https://www.aleksagordic.com/blog/vllm#ref-1" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[1]</a> works.</p><p>This post is the first in a series. It starts broad and then layers in detail (following an inverse-pyramid approach) so you can form an accurate high-level mental model of the complete system without drowning in minutiae.</p><p>Later posts will dive into specific subsystems.</p><p>This post is structured into five parts:</p><ol><li><a href="https://www.aleksagordic.com/blog/vllm#cpt1" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">LLM engine &amp; engine core</a>: fundamentals of vLLM (scheduling, paged attention, continuous batching, etc.)  </li><li><a href="https://www.aleksagordic.com/blog/vllm#cpt2" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">Advanced features</a>: chunked prefill, prefix caching, guided &amp; speculative decoding, disaggregated P/D</li><li><a href="https://www.aleksagordic.com/blog/vllm#cpt3" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">Scaling up</a>: from single-GPU to multi-GPU execution</li><li><a href="https://www.aleksagordic.com/blog/vllm#cpt4" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">Serving layer</a>: distributed / concurrent web scaffolding</li><li><a href="https://www.aleksagordic.com/blog/vllm#cpt5" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">Benchmarks and auto-tuning</a>: measuring latency and throughput  </li></ol><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Notes</div><div class="text-sm leading-relaxed"><ul><li>Analysis is based on <a href="https://github.com/vllm-project/vllm/tree/42172ad" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">commit 42172ad</a> (August 9th, 2025).</li><li>Target audience: anyone curious about how state-of-the-art LLM engines work, as well as those interested in contributing to vLLM, SGLang, etc.</li><li>I'll focus on the <a href="https://docs.vllm.ai/en/latest/usage/v1_guide.html" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">V1 engine</a>. I also explored V0 (<a href="https://github.com/vllm-project/vllm/issues/18571" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">now deprecated</a>), which was valuable for understanding how the project evolved, and many concepts still carry over.</li><li>The first section on LLM Engine / Engine Core might be a bit overwhelming/dry - but the rest of the blog has plenty examples and visuals. :)</li></ul></div></div><h2 id="cpt1" class="font-semibold text-black text-xl mb-3 mt-6">LLM Engine &amp; Engine Core</h2><p>The LLM engine is the fundamental building block of vLLM. On its own, it already enables high-throughput inference - but only in an offline setting. You can't serve it to customers over the web yet.</p><p>We'll use the following offline inference snippet as our running example (adapted from <a href="https://github.com/vllm-project/vllm/blob/main/examples/offline_inference/basic/basic.py" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">basic.py</a>).</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> SamplingParams
</span>
<span>prompts </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"Hello, my name is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"The president of the United States is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span>
</span>
<span>sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>temperature</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.8</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> top_p</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.95</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>    outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">if</span><span> __name__ </span><span class="token" style="color:hsl(221, 87%, 60%)">==</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"__main__"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Environment vars:</div><div class="text-sm leading-relaxed"><ul><li>VLLM_USE_V1="1" # we're using engine V1</li><li>VLLM_ENABLE_V1_MULTIPROCESSING="0" # we're running in a single process</li></ul></div></div><p>This configuration is:</p><ul><li>offline (no web/distributed system scaffolding)</li><li>synchronous (all execution happens in a single blocking process)</li><li>single-GPU (no data/model/pipeline/expert parallelism; DP/TP/PP/EP = 1)</li><li>using standard transformer <a href="https://www.aleksagordic.com/blog/vllm#ref-2" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[2]</a> (supporting hybrid models like Jamba requires a more complex hybrid KV-cache memory allocator)</li></ul><p>From here, we'll gradually build up to an online, async, multi-GPU, multi-node inference system - but still serving a standard transformer.</p><p>In this example we do two things, we:</p><ol><li>Instantiate an engine</li><li>Call <code>generate</code> on it to sample from the given prompts</li></ol><p>Let's start analyzing the constructor.</p><h2 class="text-black text-xl mb-3 mt-6">LLM Engine constructor</h2><p>The main components of the engine are:</p><ul><li>vLLM config (contains all of the knobs for configuring model, cache, parallelism, etc.)</li><li>processor (turns raw inputs ‚Üí <code>EngineCoreRequests</code> via validation, tokenization, and processing)</li><li>engine core client (in our running example we're using <code>InprocClient</code> which is basically == <code>EngineCore</code>; we'll gradually build up to <code>DPLBAsyncMPClient</code> which allows serving at scale)</li><li>output processor (converts raw <code>EngineCoreOutputs</code> ‚Üí <code>RequestOutput</code> that the user sees)</li></ul><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">With the V0 engine being deprecated, class names and details may shift. I'll emphasize the core ideas rather than exact signatures. I'll abstract away some but not all of those details.</div></div><p>Engine core itself is made up of several sub components:</p><ul><li>Model Executor (drives forward passes on the model, we're currently dealing with <code>UniProcExecutor</code> which has a single <code>Worker</code> process on a single GPU). We'll gradually build up to <code>MultiProcExecutor</code> which supports multiple GPUs</li><li>Structured Output Manager (used for guided decoding - we'll cover this later)</li><li>Scheduler (decides which requests go into the next engine step) - it further contains:<ol style="list-style-type:lower-alpha" class="ml-6 mt-2 space-y-1"><li>policy setting - it can be either <b>FCFS</b> (first come first served) or <b>priority</b> (higher priority requests are served first)</li><li><code>waiting</code> and <code>running</code> queues</li><li>KV cache manager - the heart of paged attention <a href="https://www.aleksagordic.com/blog/vllm#ref-3" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[3]</a></li></ol></li></ul><p>The KV-cache manager maintains a <code>free_block_queue</code> - a pool of available KV-cache blocks (often on the order of hundreds of thousands, depending on VRAM size and block size). During paged attention, the blocks serve as the indexing structure that map tokens to their computed KV cache blocks.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/engine_constructor.png" alt="LLM engine constructor" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">Core components described in this section and their relationships</div></div><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Block size for a standard transformer layer (non-MLA <a href="https://www.aleksagordic.com/blog/vllm#ref-4" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[4]</a>) is computed as follows:<br> 2 (key/value) * <code>block_size</code> (default=16) * <code>num_kv_heads</code> * <code>head_size</code> * <code>dtype_num_bytes</code> (e.g. 2 for bf16)</div></div><p>During model executor construction, a <code>Worker</code> object is created, and three key procedures are executed. (Later, with <code>MultiProcExecutor</code>, these same procedures run independently on each worker process across different GPUs.)</p><ol><li>Init device:<ul class="ml-6 mt-2 space-y-1"><li>Assign a CUDA device (e.g. "cuda:0") to the worker and check that the model dtype is supported (e.g. bf16)</li><li>Verify enough VRAM is available, given the requested <code>gpu_memory_utilization</code> (e.g. 0.8 ‚Üí 80% of total VRAM)</li><li>Set up distributed settings (DP / TP / PP / EP, etc.)</li><li>Instantiate a <code>model_runner</code> (holds the sampler, KV cache, and forward-pass buffers such as <code>input_ids</code>, <code>positions</code>, etc.)</li><li>Instantiate an <code>InputBatch</code> object (holds CPU-side forward-pass buffers, block tables for KV-cache indexing, sampling metadata, etc.)</li></ul></li><li>Load model:<ul class="ml-6 mt-2 space-y-1"><li>Instantiate the model architecture</li><li>Load the model weights</li><li>Call model.eval() (PyTorch's inference mode)</li><li>Optional: call torch.compile() on the model</li></ul></li><li>Initialize KV cache<ul class="ml-6 mt-2 space-y-1"><li>Get per-layer KV-cache spec. Historically this was always <code>FullAttentionSpec</code> (homogeneous transformer), but with hybrid models (sliding window, Transformer/SSM like Jamba) it became more complex (see Jenga <a href="https://www.aleksagordic.com/blog/vllm#ref-5" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[5]</a>)</li><li>Run a dummy/profiling forward pass and take a GPU memory snapshot to compute how many KV cache blocks fit in available VRAM</li><li>Allocate, reshape and bind KV cache tensors to attention layers</li><li>Prepare attention metadata (e.g. set the backend to FlashAttention) later consumed by kernels during the fwd pass</li><li>Unless <code>--enforce-eager</code> is provided, for each of warmup batch sizes do a dummy run and capture CUDA graphs. CUDA graphs record the whole sequence of GPU work into a DAG. Later during fwd pass we launch/replay pre-baked graphs and cut on kernel launch overhead and thus improve latency.</li></ul></li></ol><p>I've abstracted away many low-level details here ‚Äî but these are the core pieces I'll introduce now, since I'll reference them repeatedly in the following sections.</p>Now that we have the engine initialized let's proceed to the <code>generate</code> function.<h2 class="text-black text-xl mb-3 mt-6">Generate function</h2><p>The first step is to validate and feed requests into the engine. For each prompt we:</p><ol><li>Create a unique request ID and capture its arrival time</li><li>Call an input preprocessor that tokenizes the prompt and returns a dictionary containing <code>prompt</code>, <code>prompt_token_ids</code>, and a <code>type</code> (text, tokens, embeds, etc.)</li><li>Pack this info into an <code>EngineCoreRequest</code>, adding priority, sampling params, and other metadata</li><li>Pass the request into the engine core, which wraps it in a <code>Request</code> object and sets its status to <code>WAITING</code>. This request is then added to the scheduler's <code>waiting</code> queue (append if FCFS, or heap-push if priority)</li></ol><p>At this point the engine has been fed and execution can begin. In the synchronous engine example, these initial prompts are the only ones we'll process ‚Äî there's no mechanism to inject new requests mid-run. In contrast, the asynchronous engine supports this (aka <b>continuous batching</b> <a href="https://www.aleksagordic.com/blog/vllm#ref-6" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[6]</a>): after each step, both new and old requests are considered.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Because the forward pass flattens the batch into a single sequence and custom kernels handle it efficiently, continuous batching is fundamentally supported even in the synchronous engine.</div></div><p>Next, as long as there are requests to process, the engine repeatedly calls its <code>step()</code> function. Each step has three stages:</p><ol><li>Schedule: select which requests to run in this step (decode, and/or (chunked) prefill)</li><li>Forward pass: run the model and sample tokens</li><li>Postprocess: append sampled token IDs to each <code>Request</code>, detokenize, and check stop conditions. If a request is finished, clean up (e.g. return its KV-cache blocks to <code>free_block_queue</code>) and return the output early</li></ol><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Stop conditions are:</div><div class="text-sm leading-relaxed"><ul class="mt-2 space-y-1"><li>The request exceeds its length limit (<code>max_model_length</code> or its own <code>max_tokens</code>)</li><li>The sampled token is the EOS ID (unless <code>ignore_eos</code> is enabled -<!-- -->&gt;<!-- --> useful for benchmarking when we want to force a generation of a certain number of out tokens)</li><li>The sampled token matches any of the <code>stop_token_ids</code> specified in the sampling parameters</li><li>Stop strings are present in the output - we truncate the output until the first stop string appearance and abort the request in the engine (note that <code>stop_token_ids</code> will be present in the output but stop strings will not).</li></ul></div></div><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/engine_loop.png" alt="Engine loop" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">Engine loop</div></div><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">In streaming mode, we would send intermediate tokens as they are generated, but we'll ignore that for now.</div></div><p>Next, we'll examine scheduling in more detail.</p><h2 class="font-semibold text-black text-xl mb-3 mt-6">Scheduler</h2><p>There are two main types of workloads an inference engine handles:</p><ol><li><b>Prefill</b> requests ‚Äî a forward pass over all prompt tokens. These are usually <b>compute-bound</b> (threshold depends on hardware and prompt length). At the end, we sample a single token from the probability distribution of the final token's position.</li><li><b>Decode</b> requests ‚Äî a forward pass over just the most recent token. All earlier KV vectors are already cached. These are <b>memory-bandwidth-bound</b>, since we still need to load all LLM weights (and KV caches) just to compute one token.</li></ol><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">In the <a href="https://www.aleksagordic.com/blog/vllm#cpt5" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">benchmarking section</a> we'll analyze the so-called roofline model of GPU perf. That will go into more detail behind prefill/decode perf profiles.</div></div><p>The V1 scheduler can mix both types of requests in the same step, thanks to smarter design choices. In contrast, the V0 engine could only process either prefill or decode at once.</p>The scheduler prioritizes decode requests ‚Äî i.e. those already in the <code>running</code> queue. For each such request it:<ol><li>Computes the number of new tokens to generate (not always 1, due to speculative decoding and async scheduling ‚Äî more on that later).</li><li>Calls the KV-cache manager's <code>allocate_slots</code> function (details below).</li><li>Updates the token budget by subtracting the number of tokens from step 1.</li></ol>After that, it processes prefill requests from the <code>waiting</code> queue, it:<ol><li>Retrieves the number of computed blocks (returns 0 if prefix caching is disabled ‚Äî we'll cover that later).</li><li>Calls the KV-cache manager's <code>allocate_slots</code> function.</li><li>Pops the request from waiting and moves it to running, setting its status to <code>RUNNING</code>.</li><li>Updates the token budget.</li></ol>Let's now look at what <code>allocate_slots</code> does, it:<ol><li><strong>Computes number of blocks</strong> ‚Äî determines how many new KV-cache blocks (<code>n</code>) must be allocated. Each block stores 16 tokens by default. For example, if a prefill request has 17 new tokens, we need <code>ceil(17/16) = 2</code> blocks.</li><li><strong>Checks availability</strong> ‚Äî if there aren't enough blocks in the manager's pool, exit early. Depending on whether it's a decode or prefill request, the engine may attempt recompute preemption (swap preemption was supported in V0) by evicting low-priority requests (calling <code>kv_cache_manager.free</code> which returns KV blocks to block pool), or it might skip scheduling and continue execution.</li><li><strong>Allocates blocks</strong> ‚Äî via the KV-cache manager's coordinator, fetches the first <code>n</code> blocks from the block pool (the <code>free_block_queue</code> doubly linked list mentioned earlier). Stores to <code>req_to_blocks</code>, the dictionary mapping each <code>request_id</code> to its list of KV-cache blocks.</li></ol><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/kv_cache_blocks.png" alt="KV cache blocks" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">list of KV cache blocks</div></div>We're finally ready to do a forward pass!<h2 class="font-semibold text-black text-xl mb-3 mt-6">Run forward pass</h2><p>We call model executor's <code>execute_model</code>, which delegates to the <code>Worker</code>, which in turn delegates to the model runner.</p><p>Here are the main steps:</p><ol><li><strong>Update states</strong> ‚Äî prune finished requests from <code>input_batch</code>; update misc fwd pass related metadata (e.g., KV cache blocks per request that will be used to index into paged KV cache memory).</li><li><strong>Prepare inputs</strong> ‚Äî copy buffers from CPU‚ÜíGPU; compute positions; build <code>slot_mapping</code> (more on that in example); construct attention metadata.</li><li><strong>Forward pass</strong> ‚Äî run the model with custom paged attn kernels. All sequences are flattened and concatenated into one long "super sequence". Position indices and attention masks ensure each sequence only attends to its own tokens, which enables continuous batching without right-padding.</li><li><strong>Gather last-token states</strong> ‚Äî extract hidden states for each sequence's final position and compute logits.</li><li><strong>Sample</strong> ‚Äî sample tokens from computed logits as dictated by the sampling config (greedy, temperature, top-p, top-k, etc.).</li></ol><p>Forward-pass step itself has two execution modes:</p><ol><li><strong>Eager mode</strong> ‚Äî run the standard PyTorch forward pass when eager execution is enabled.</li><li><strong>"Captured" mode</strong> ‚Äî execute/replay a pre-captured CUDA Graph when eager is not enforced (remember we captured these during engine construction in the initialize KV cache procedure).</li></ol><p>Here is a concrete example that should make continuous batching and paged attention clear:</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fwd_pass.png" alt="fwd pass - continuous batching &amp; paged attn" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">Forward pass: continuous batching and paged attention</div></div><h2 id="cpt2" class="font-semibold text-black text-xl mb-3 mt-6">Advanced Features ‚Äî extending the core engine logic</h2><p>With the basic engine flow in place, we can now look at the advanced features.</p><p>We've already discussed preemption, paged attention, and continuous batching.</p><p>Next, we'll dive into:</p><ol><li>Chunked prefill</li><li>Prefix caching</li><li>Guided decoding (through grammar-constrained finite-state machines)</li><li>Speculative decoding</li><li>Disaggregated P/D (prefill/decoding)</li></ol><h2 class="font-semibold text-black text-xl mb-3 mt-6">Chunked prefill</h2><p>Chunked prefill is a technique for handling long prompts by splitting their prefill step into smaller chunks. Without it, we could end up with a single very long request monopolizing one engine step disallowing other prefill requests to run. That would postpone all other requests and increase their latency.</p><p>For example, let each chunk contain <code>n</code> (=8) tokens, labeled with lowercase letters separated by "-". A long prompt <code>P</code> could look like <code>x-y-z</code>, where <code>z</code> is an incomplete chunk (e.g. 2 toks). Executing the full prefill for <code>P</code> would then take ‚â• 3 engine steps (<!-- -->&gt;<!-- --> can happen if it's not scheduled for execution in one of the steps), and only in the last chunked prefill step would we sample one new token.</p><p>Here is that same example visually:</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/chunked_pt1.png" alt="Chunked prefilling - pt 1" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><p>Implementation is straightforward: cap the number of new tokens per step. If the requested number exceeds <code>long_prefill_token_threshold</code>, reset it to exactly that value. The underlying indexing logic (described earlier) takes care of the rest.</p><p>In vLLM V1, you enable chunked prefill by setting <code>long_prefill_token_threshold</code> to a positive integer. (Technically, it can happen irrespective of this, if the prompt length exceeds the token budget we truncate it and run a chunked prefill.)</p><h2 class="font-semibold text-black text-xl mb-3 mt-6">Prefix Caching</h2><p>To explain how prefix caching works, let's take the original code example and tweak it a bit:</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> SamplingParams
</span>
<span>long_prefix </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"&lt;a piece of text that is encoded into more than block_size tokens&gt;"</span><span>
</span>
<span>prompts </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"Hello, my name is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"The president of the United States is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span>
</span>
<span>sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>temperature</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.8</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> top_p</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.95</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>    outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>long_prefix </span><span class="token" style="color:hsl(221, 87%, 60%)">+</span><span> prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span class="token" style="color:hsl(35, 99%, 36%)">0</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>    outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>long_prefix </span><span class="token" style="color:hsl(221, 87%, 60%)">+</span><span> prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span class="token" style="color:hsl(35, 99%, 36%)">1</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">if</span><span> __name__ </span><span class="token" style="color:hsl(221, 87%, 60%)">==</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"__main__"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre><p>Prefix caching avoids recomputing tokens that multiple prompts share at the beginning - hence <b>prefix</b>.</p><p>The crucial piece is the <code>long_prefix</code>: it's defined as any prefix longer than a KV-cache block (16 tokens by default). To simplify our example let's say <code>long_prefix</code> has exactly length <code>n x block_size</code> (where <code>n ‚â• 1</code>).</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">i.e. it perfectly aligns with block boundary - otherwise we'd have to recompute <code>long_prefix_len % block_size</code> tokens as we can't cache incomplete blocks.</div></div><p>Without prefix caching, each time we process a new request with the same <code>long_prefix</code>, we'd recompute all <code>n x block_size</code> tokens.</p><p>With prefix caching, those tokens are computed once (their KVs stored in KV cache paged memory) and then reused, so only the new prompt tokens need processing. This speeds up prefill requests (though it doesn't help with decode).</p><p>How does this work in vLLM?</p><p>During the first <code>generate</code> call, in the scheduling stage, inside <code>kv_cache_manager.get_computed_blocks</code>, the engine invokes <code>hash_request_tokens</code>:</p><ol><li>This function splits the <code>long_prefix + prompts[0]</code> into 16-token chunks.</li><li>For each complete chunk, it computes a hash (using either the built-in hash or SHA-256, which is slower but has fewer collisions). The hash combines the previous block's hash, the current tokens, and optional metadata.</li><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">optional metadata includes: MM hash, LoRA ID, cache salt (injected into hash of the first block ensures only requests with this cache salt can reuse blocks).</div></div><li>Each result is stored as a <code>BlockHash</code> object containing both the hash and its token IDs. We return a list of block hashes.</li></ol><p>The list is stored in <code>self.req_to_block_hashes[request_id]</code>.</p><p>Next, the engine calls <code>find_longest_cache_hit</code> to check if any of these hashes already exist in <code>cached_block_hash_to_block</code>. On the first request, no hits are found.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt1.png" alt="Prefix caching logic - pt 1" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><p>Then we call <code>allocate_slots</code> which calls <code>coordinator.cache_blocks</code>, which associates the new <code>BlockHash</code> entries with allocated KV blocks and records them in <code>cached_block_hash_to_block</code>.</p><p>Afterwards, the forward pass will populate KVs in paged KV cache memory corresponding to KV cache blocks that we allocated above.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">After many engine steps it'll allocate more KV cache blocks but it doesn't matter for our example because the prefix has diverged immediately after <code>long_prefix</code>.</div></div><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt2.png" alt="Prefix caching logic - pt 2" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><p>On a second <code>generate</code> call with the same prefix, steps 1-3 repeat, but now <code>find_longest_cache_hit</code> finds matches for all <code>n</code> blocks (via linear search). The engine can reuse those KV blocks directly.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/prefix_pt3.png" alt="Prefix caching logic - pt 3" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><p>If the original request were still alive, the reference count for those blocks would increment (e.g. to 2). In this example, the first request has already completed, so the blocks were freed back to the pool and their reference counts set back to 0. Because we were able to retrieve them from <code>cached_block_hash_to_block</code> we know they're valid (the logic of the KV cache manager is setup in such a way), so we just remove them from <code>free_block_queue</code> again.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Advanced note:</div><div class="text-sm leading-relaxed">KV-cache blocks become invalid only when they're about to be reallocated from the <code>free_block_queue</code> (which pops from the left) and we discover the block still has an associated hash and is present in <code>cached_block_hash_to_block</code>. At that moment, we clear the block's hash and remove its entry from <code>cached_block_hash_to_block</code>, ensuring it can't be reused via prefix caching (at least not for that old prefix).</div></div><p>And that's the gist of prefix caching: don't recompute prefixes you've already seen ‚Äî just reuse their KV cache!</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">If you understood this example you also understood how paged attention works.</div></div><p>Prefix caching is enabled by default. To disable it: <code>enable_prefix_caching = False</code>.</p><h2 class="font-semibold text-black text-xl mb-3 mt-6">Guided Decoding (FSM)</h2><p>Guided decoding is a technique where, at each decoding step, the logits are constrained by a grammar-based finite state machine. This ensures that only tokens allowed by the grammar can be sampled.</p><p>It's a powerful setup: you can enforce anything from regular grammars (Chomsky type-3, e.g. arbitrary regex patterns) all the way up to context-free grammars (type-2, which cover most programming languages).</p><p>To make this less abstract, let's start with the simplest possible example, building on our earlier code:</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> SamplingParams
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>sampling_params </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> GuidedDecodingParams
</span>
<span>prompts </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"This sucks"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"The weather is beautiful"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span>
</span>
<span>guided_decoding_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> GuidedDecodingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>choice</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span class="token" style="color:hsl(119, 34%, 47%)">"Positive"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"Negative"</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>guided_decoding</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>guided_decoding_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>    outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">if</span><span> __name__ </span><span class="token" style="color:hsl(221, 87%, 60%)">==</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"__main__"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre><p>In the toy example I gave (assume character-level tokenization): at prefill, the FSM masks logits so only "P" or "N" are viable. If "P" is sampled, the FSM moves to the "Positive" branch; next step only "o" is allowed, and so on.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fsm.png" alt="FSM" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">Toy example FSM</div></div><p>How this works in vLLM:</p><ol><li>At LLM engine construction, a <code>StructuredOutputManager</code> is created; it has access to the tokenizer and maintains a <code>_grammar_bitmask</code> tensor.</li><li>When adding a request, its status is set to <code>WAITING_FOR_FSM</code> and <code>grammar_init</code> selects the backend compiler (e.g., <code>xgrammar</code> <a href="https://www.aleksagordic.com/blog/vllm#ref-7" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[7]</a>; note that backends are 3rd party code).</li><li>The grammar for this request is compiled asynchronously.</li><li>During scheduling, if the async compile has completed, the status switches to <code>WAITING</code> and <code>request_id</code> is added to <code>structured_output_request_ids</code>; otherwise it's placed in <code>skipped_waiting_requests</code> to retry on next engine step.</li><li>After the scheduling loop (still inside scheduling), if there are FSM requests, the <code>StructuredOutputManager</code> asks the backend to prepare/update <code>_grammar_bitmask</code>.</li><li>After the forward pass produces logits, xgr_torch_compile's function expands the bitmask to vocab size (32x expansion ratio because we use 32 bit integers) and masks disallowed logits to ‚Äì‚àû.</li><li>After sampling the next token, the request's FSM is advanced via <code>accept_tokens</code>. Visually we move to the next state on the FSM diagram.</li></ol><p>Step 6 deserves further clarification.</p><p>If <code>vocab_size = 32</code>, <code>_grammar_bitmask</code> is a single integer; its binary representation encodes which tokens are allowed ("1") vs disallowed ("0"). For example, "101‚Ä¶001" expands to a length-32 array <code>[1, 0, 1, ‚Ä¶, 0, 0, 1]</code>; positions with 0 get logits set to ‚Äì‚àû. For larger vocabularies, multiple 32-bit words are used and expanded/concatenated accordingly. The backend (e.g., <code>xgrammar</code>) is responsible for producing these bit patterns using the current FSM state.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">Most of the complexity here is hidden in the 3rd party libs like xgrammar.</div></div><p>Here is an even simpler example with vocab_size = 8 and 8-bit integers (for those of you who like my visuals):</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/fsm2.png" alt="FSM" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">Toy example</div></div><p>You can enable this in vLLM by passing in a desired <code>guided_decoding</code> config.</p><h2 class="font-semibold text-black text-xl mb-3 mt-6">Speculative Decoding</h2><p>In autoregressive generation, each new token requires a forward pass of the large LM. This is expensive ‚Äî every step reloads and applies all model weights just to compute a single token! (assuming batch size == 1, in general it's <code>B</code>)</p><p>Speculative decoding <a href="https://www.aleksagordic.com/blog/vllm#ref-8" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[8]</a> speeds this up by introducing a smaller draft LM. The draft proposes <code>k</code> tokens cheaply. But we don't ultimately want to sample from the smaller model ‚Äî it's only there to guess candidate continuations. The large model still decides what's valid.</p><p>Here are the steps:</p><ol><li><strong>Draft:</strong> run the small model on the current context and propose <code>k</code> tokens</li><li><strong>Verify:</strong> run the large model once on context + <code>k</code> draft tokens. This produces probabilities for those <code>k</code> positions plus one extra (so we get <code>k+1</code> candidates)</li><li><strong>Accept/reject:</strong> going from left to right over the <code>k</code> draft tokens:<ul><li>If the large model's probability for the draft token ‚â• the draft's probability, accept it</li><li>Otherwise, accept it with probability <code>p_large(token)/p_draft(token)</code></li><li>Stop at the first rejection, or accept all <code>k</code> draft tokens.</li><ul><li>If all <code>k</code> draft tokens are accepted, also sample the extra <code>(k+1)</code>-th token "for free" from the large model (we already computed that distribution).</li><li>If there was a rejection create a new rebalanced distribution at that position (<code>p_large - p_draft</code>, clamp min at 0, normalize to sum to 1) and sample the last token from it.</li></ul></ul></li></ol><p><strong>Why this works:</strong> Although we use the small model to propose candidates, the accept/reject rule guarantees that in expectation the sequence is distributed exactly as if we had sampled token by token from the large model. This means speculative decoding is statistically equivalent to standard autoregressive decoding ‚Äî but potentially much faster, since a single large-model pass can yield up to <code>k+1</code> tokens.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">I recommend looking at <a href="https://github.com/meta-pytorch/gpt-fast" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">gpt-fast</a> for a simple implementation, and the <a href="https://arxiv.org/abs/2302.01318" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">original paper</a> for the math details and the proof of equivalence to sampling from the full model.</div></div><p>vLLM V1 does not support the LLM draft model method, instead it implements faster‚Äîbut less accurate‚Äîproposal schemes: n-gram, EAGLE <a href="https://www.aleksagordic.com/blog/vllm#ref-9" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[9]</a>, and Medusa <a href="https://www.aleksagordic.com/blog/vllm#ref-10" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[10]</a>.</p><p>One-liners on each:</p><ol><li><strong>n-gram:</strong> take the last <code>prompt_lookup_max</code> tokens; find a prior match in the sequence; if found, propose the <code>k</code> tokens that followed that match; otherwise decrement the window and retry down to <code>prompt_lookup_min</code></li><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">The current implementation returns <code>k</code> tokens after the <b>first</b> match. It feels more natural to introduce a recency bias and reverse the search direction? (i.e. last match)</div></div><li><strong>Eagle:</strong> perform "model surgery" on the large LM‚Äîkeep embeddings and LM head, replace the transformer stack with a lightweight MLP; fine-tune that as a cheap draft</li><li><strong>Medusa:</strong> train auxiliary linear heads on top (embeddings before LM head) of the large model to predict the next <code>k</code> tokens in parallel; use these heads to propose tokens more efficiently than running a separate small LM</li></ol>Here's how to invoke speculative decoding in vLLM using <code>ngram</code> as the draft method:<pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> SamplingParams
</span>
<span>prompts </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"Hello, my name is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"The president of the United States is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span>
</span>
<span>sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>temperature</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.8</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> top_p</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.95</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>speculative_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">{</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"method"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"ngram"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"prompt_lookup_max"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(35, 99%, 36%)">5</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"prompt_lookup_min"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(35, 99%, 36%)">3</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"num_speculative_tokens"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(35, 99%, 36%)">3</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> speculative_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>speculative_config</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>    outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">if</span><span> __name__ </span><span class="token" style="color:hsl(221, 87%, 60%)">==</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"__main__"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>    main</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre><p>How does this work in vLLM?</p><p><strong>Setup (during engine construction):</strong></p><ol><li>Init device: create a <code>drafter</code> (draft model, e.g., <code>NgramProposer</code>) and a <code>rejection_sampler</code> (parts of it are written in Triton).</li><li>Load model: load draft model weights (no-op for n-gram).</li></ol><p><strong>After that in the <code>generate</code> function</strong> (assume we get a brand new request):</p><ol><li>Run the regular prefill step with the large model.</li><li>After the forward pass and standard sampling, call <code>propose_draft_token_ids(k)</code> to sample <code>k</code> draft tokens from the draft model.</li><li>Store these in <code>request.spec_token_ids</code> (update the request metadata).</li><li>On the next engine step, when the request is in the running queue, add <code>len(request.spec_token_ids)</code> to the "new tokens" count so <code>allocate_slots</code> reserves sufficient KV blocks for the fwd pass.</li><li>Copy <code>spec_token_ids</code> into <code>input_batch.token_ids_cpu</code> to form (context + draft) tokens.</li><li>Compute metadata via <code>_calc_spec_decode_metadata</code> (this copies over tokens from <code>input_batch.token_ids_cpu</code>, prepares logits, etc.), then run a large-model forward pass over the draft tokens.</li><li>Instead of regular sampling from logits, use the <code>rejection_sampler</code> to accept/reject left-to-right and produce <code>output_token_ids</code>.</li><li>Repeat steps 2-7 until a stop condition is met.</li></ol>The best way to internalize this is to fire up your debugger and step through the codebase, but this section hopefully gives you a taste for it. This as well:<div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/specdec_pt1.png" alt="Drafting stage" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/specdec_pt2.png" alt="Verify stage &amp; rejection sampling stage" class="w-max max-w-full h-auto rounded-lg mx-auto "></div><h2 class="font-semibold text-black text-xl mb-3 mt-6">Disaggregated P/D</h2><p>I've already previously hinted at the motivation behind disaggregated P/D (prefill/decode).</p><p>Prefill and decode have very different performance profiles (compute-bound vs. memory-bandwidth-bound), so separating their execution is a sensible design. It gives tighter control over latency ‚Äî both <code>TFTT</code> (time-to-first-token) and <code>ITL</code> (inter-token latency) ‚Äî more on this in the <a href="https://www.aleksagordic.com/blog/vllm#cpt5" rel="noopener noreferrer" class="text-yellow-600 hover:text-yellow-800 ">benchmarking</a> section.</p><p>In practice, we run <code>N</code> vLLM prefill instances and <code>M</code> vLLM decode instances, autoscaling them based on the live request mix. Prefill workers write KV to a dedicated KV-cache service; decode workers read from it. This isolates long, bursty prefill from steady, latency-sensitive decode.</p><p>How does this work in vLLM?</p><p>For clarity, the example below relies on <code>SharedStorageConnector</code>, a debugging connector implementation used to illustrate the mechanics.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Connector is vLLM's abstraction for handling the exchange of KVs between instances. Connector interface is not yet stable, there are some near-term improvements planned which will involve changes, some potentially breaking.</div></div><p>We launch 2 vLLM instances (GPU 0 for prefill and GPU 1 for decode), and then transfer the KV cache between them:</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> time
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> multiprocessing </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> Event</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> Process
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> multiprocessing </span><span class="token" style="color:hsl(301, 63%, 40%)">as</span><span> mp
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> SamplingParams
</span><span></span><span class="token" style="color:hsl(301, 63%, 40%)">from</span><span> vllm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>config </span><span class="token" style="color:hsl(301, 63%, 40%)">import</span><span> KVTransferConfig
</span>
<span>prompts </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"Hello, my name is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(119, 34%, 47%)">"The president of the United States is"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">run_prefill</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>  os</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>environ</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span class="token" style="color:hsl(119, 34%, 47%)">"CUDA_VISIBLE_DEVICES"</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"0"</span><span>
</span>
<span>  sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>temperature</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> top_p</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.95</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> max_tokens</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">1</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  ktc</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>KVTransferConfig</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>
</span><span>      kv_connector</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"SharedStorageConnector"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>      kv_role</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"kv_both"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>      kv_connector_extra_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">{</span><span class="token" style="color:hsl(119, 34%, 47%)">"shared_storage_path"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"local_storage"</span><span class="token" style="color:hsl(230, 8%, 24%)">}</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> kv_transfer_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>ktc</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span class="token" style="color:hsl(119, 34%, 47%)">set</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>  </span><span class="token" style="color:hsl(230, 4%, 64%);font-style:italic"># notify decode instance that KV cache is ready</span><span>
</span>
<span>  </span><span class="token" style="color:hsl(230, 4%, 64%);font-style:italic"># To keep the prefill node running in case the decode node is not done;</span><span>
</span><span>  </span><span class="token" style="color:hsl(230, 4%, 64%);font-style:italic"># otherwise, the script might exit prematurely, causing incomplete decoding.</span><span>
</span><span>  </span><span class="token" style="color:hsl(301, 63%, 40%)">try</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>      </span><span class="token" style="color:hsl(301, 63%, 40%)">while</span><span> </span><span class="token" style="color:hsl(35, 99%, 36%)">True</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>          time</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>sleep</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(35, 99%, 36%)">1</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  </span><span class="token" style="color:hsl(301, 63%, 40%)">except</span><span> KeyboardInterrupt</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>      </span><span class="token" style="color:hsl(301, 63%, 40%)">print</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(119, 34%, 47%)">"Script stopped by user."</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">def</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">run_decode</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>  os</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>environ</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span class="token" style="color:hsl(119, 34%, 47%)">"CUDA_VISIBLE_DEVICES"</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span> </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"1"</span><span>
</span>
<span>  sampling_params </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> SamplingParams</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>temperature</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> top_p</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">0.95</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  ktc</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>KVTransferConfig</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>
</span><span>      kv_connector</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"SharedStorageConnector"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>      kv_role</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"kv_both"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>      kv_connector_extra_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">{</span><span class="token" style="color:hsl(119, 34%, 47%)">"shared_storage_path"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"local_storage"</span><span class="token" style="color:hsl(230, 8%, 24%)">}</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  llm </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> LLM</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> kv_transfer_config</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>ktc</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>wait</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>  </span><span class="token" style="color:hsl(230, 4%, 64%);font-style:italic"># block waiting for KV cache from prefill instance</span><span>
</span>
<span>  </span><span class="token" style="color:hsl(230, 4%, 64%);font-style:italic"># Internally it'll first fetch KV cache before starting the decoding loop</span><span>
</span><span>  outputs </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> llm</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>generate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prompts</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> sampling_params</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(301, 63%, 40%)">if</span><span> __name__ </span><span class="token" style="color:hsl(221, 87%, 60%)">==</span><span> </span><span class="token" style="color:hsl(119, 34%, 47%)">"__main__"</span><span class="token" style="color:hsl(230, 8%, 24%)">:</span><span>
</span><span>  prefill_done </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> Event</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  prefill_process </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> Process</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>target</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>run_prefill</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> args</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  decode_process </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> Process</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>target</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span>run_decode</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> args</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>prefill_done</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  prefill_process</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>start</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  decode_process</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>start</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span>
<span>  decode_process</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>join</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>  prefill_process</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>terminate</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span></code></pre><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">I've also experimented with <code>LMCache</code> <a href="https://www.aleksagordic.com/blog/vllm#ref-11" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 ">[11]</a>, the fastest production-ready connector (uses NVIDIA's NIXL as the backend), but it's still at the bleeding edge and I ran into some bugs. Since much of its complexity lives in an external repo, <code>SharedStorageConnector</code> is a better choice for explanation.</div></div><p>These are the steps in vLLM:</p><ol><li><strong>Instantiation</strong> ‚Äî During engine construction, connectors are created in two places:<ul><li>Inside the worker's init device procedure (under init worker distributed environment function), with role "worker".</li><li>Inside the scheduler constructor, with role "scheduler".</li></ul></li><li><strong>Cache lookup</strong> ‚Äî When the scheduler processes prefill requests from the <code>waiting</code> queue (after local prefix-cache checks), it calls connector's <code>get_num_new_matched_tokens</code>. This checks for externally cached tokens in the KV-cache server. Prefill always sees 0 here; decode may have a cache hit. The result is added to the local count before calling <code>allocate_slots</code>.</li><li><strong>State update</strong> ‚Äî The scheduler then calls <code>connector.update_state_after_alloc</code>, which records requests that had a cache (no-op for prefill).</li><li><strong>Meta build</strong> ‚Äî At the end of scheduling, the scheduler calls <code>meta = connector.build_connector_meta</code>:<ul><li>Prefill adds all requests with <code>is_store=True</code> (to upload KV).</li><li>Decode adds requests with <code>is_store=False</code> (to fetch KV).</li></ul></li><li><strong>Context manager</strong> ‚Äî Before the forward pass, the engine enters a KV-connector context manager:<ul><li>On enter: <code>kv_connector.start_load_kv</code> is called. For decode, this loads KV from the external server and injects it into paged memory. For prefill, it's a no-op.</li><li>On exit: <code>kv_connector.wait_for_save</code> is called. For prefill, this blocks until KV is uploaded to the external server. For decode, it's a no-op.</li></ul></li></ol><p>Here is a visual example:</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/pd.png" alt="disaggregated P/D" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">disaggregated P/D</div></div><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Additional notes:</div><div class="text-sm leading-relaxed"><ul><li>For <code>SharedStorageConnector</code> "external server" is just a local file system.</li><li>Depending on configuration, KV transfers can also be done layer-by-layer (before/after each attention layer).</li><li>Decode loads external KV only once, on the first step of its requests; afterwards it computes/stores locally.</li></ul></div></div><h2 id="cpt3" class="font-semibold text-black text-xl mb-3 mt-6">From UniprocExecutor to MultiProcExecutor</h2><p>With the core techniques in place, we can now talk about scaling up.</p><p>Suppose your model weights no longer fit into a single GPU's VRAM.</p><p>The first option is to shard the model across multiple GPUs on the same node using tensor parallelism (e.g., <code>TP=8</code>). If the model still doesn't fit, the next step is pipeline parallelism across nodes.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Notes:</div><div class="text-sm leading-relaxed"><ul><li>Intranode bandwidth is significantly higher than internode, which is why tensor parallelism (TP) is generally preferred over pipeline parallelism (PP). (It is also true that PP communicates less data than TP.)</li><li>I'm not covering expert parallelism (EP) since we're focusing on standard transformers rather than MoE, nor sequence parallelism, as TP and PP are the most commonly used in practice.</li></ul></div></div><p>At this stage, we need multiple GPU processes (workers) and an orchestration layer to coordinate them. That's exactly what <code>MultiProcExecutor</code> provides.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/multiprocexecutor.png" alt="MultiProcExecutor" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">MultiProcExecutor in a TP=8 setting (driver worker being rank 0)</div></div><p>How this works in vLLM:</p><ol><li><code>MultiProcExecutor</code> initializes an <code>rpc_broadcast_mq</code> message queue (implemented with shared memory under the hood).</li><li>The constructor loops over <code>world_size</code> (e.g. <code>TP=8 ‚áí world_size=8</code>) and spawns a daemon process for each rank via <code>WorkerProc.make_worker_process</code>.</li><li>For each worker, the parent first creates a reader and writer pipe.</li><li>The new process runs <code>WorkerProc.worker_main</code>, which instantiates a worker (going through the same "init device", "load model", etc. as in <code>UniprocExecutor</code>).</li><li>Each worker determines whether it is the driver (rank 0 in the TP group) or a regular worker. Every worker sets up two queues:<ul><li><code>rpc_broadcast_mq</code> (shared with the parent) for receiving work.</li><li><code>worker_response_mq</code> for sending responses back.</li></ul></li><li>During initialization, each child sends its <code>worker_response_mq</code> handle to the parent via the pipe. Once all are received, the parent unblocks ‚Äî this completes coordination.</li><li>Workers then enter a busy loop, blocking on <code>rpc_broadcast_mq.dequeue</code>. When a work item arrives, they execute it (just like in <code>UniprocExecutor</code>, but now with TP/PP-specific partitioned work). Results are sent back through <code>worker_response_mq.enqueue</code>.</li><li>At runtime, when a request arrives, <code>MultiProcExecutor</code> enqueues it into <code>rpc_broadcast_mq</code> (non-blocking) for all children workers. It then waits on the designated output rank's <code>worker_response_mq.dequeue</code> to collect the final result.</li></ol><p>From the engine's perspective, nothing has changed ‚Äî all of this multiprocessing complexity is abstracted away through a call to model executor's <code>execute_model</code>.</p><ul><li>In the <code>UniProcExecutor</code> case: execute_model directly leads to calling execute_model on the worker</li><li>In the <code>MultiProcExecutor</code> case: execute_model indirectly leads to calling execute_model on each worker through <code>rpc_broadcast_mq</code></li></ul><p>At this point, we can run models that are as large as resources allow using the same engine interface.</p><p>The next step is to scale out: enable data parallelism (<code>DP <!-- -->&gt;<!-- --> 1</code>) replicating the model across nodes, add a lightweight DP coordination layer, introduce load balancing across replicas, and place one or more API servers in front to handle incoming traffic.</p><h2 id="cpt4" class="font-semibold text-black text-xl mb-3 mt-6">Distributed system serving vLLM</h2><p>There are many ways to set up serving infrastructure, but to stay concrete, here's one example: suppose we have two H100 nodes and want to run four vLLM engines across them.</p><p>If the model requires <code>TP=4</code>, we can configure the nodes like this.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/server_setup.png" alt="server configuration with 2 8xH100 nodes" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">server configuration with 2 8xH100 nodes (1 headless, 1 api server)</div></div><p>On the first node, run the engine in headless mode (no API server) with the following arguments:</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>vllm serve </span><span class="token" style="color:hsl(221, 87%, 60%)">&lt;</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>name</span><span class="token" style="color:hsl(221, 87%, 60%)">&gt;</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>tensor</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size </span><span class="token" style="color:hsl(35, 99%, 36%)">4</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size </span><span class="token" style="color:hsl(35, 99%, 36%)">4</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>local </span><span class="token" style="color:hsl(35, 99%, 36%)">2</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>start</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>rank </span><span class="token" style="color:hsl(35, 99%, 36%)">0</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>address </span><span class="token" style="color:hsl(221, 87%, 60%)">&lt;</span><span>master</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>ip</span><span class="token" style="color:hsl(221, 87%, 60%)">&gt;</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>rpc</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>port </span><span class="token" style="color:hsl(35, 99%, 36%)">13345</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>headless
</span></code></pre><p>and run that same command on the other node with few tweaks:</p><ul><li>no <code>--headless</code></li><li>modify DP start rank</li></ul><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>vllm serve </span><span class="token" style="color:hsl(221, 87%, 60%)">&lt;</span><span>model</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>name</span><span class="token" style="color:hsl(221, 87%, 60%)">&gt;</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>tensor</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size </span><span class="token" style="color:hsl(35, 99%, 36%)">4</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size </span><span class="token" style="color:hsl(35, 99%, 36%)">4</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>size</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>local </span><span class="token" style="color:hsl(35, 99%, 36%)">2</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>start</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>rank </span><span class="token" style="color:hsl(35, 99%, 36%)">2</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>address </span><span class="token" style="color:hsl(221, 87%, 60%)">&lt;</span><span>master</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>ip</span><span class="token" style="color:hsl(221, 87%, 60%)">&gt;</span><span>
</span><span>  </span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>data</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>parallel</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>rpc</span><span class="token" style="color:hsl(221, 87%, 60%)">-</span><span>port </span><span class="token" style="color:hsl(35, 99%, 36%)">13345</span><span>
</span></code></pre><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">This assumes networking is configured so all nodes can reach the specified IP and port.</div></div><p>How does this work in VLLM?</p><h2 class="text-black text-xl mb-3 mt-6">On the headless server node</h2><p>On the headless node, a <code>CoreEngineProcManager</code> launches 2 processes (per <code>--data-parallel-size-local</code>) each running <code>EngineCoreProc.run_engine_core</code>. Each of these functions creates a <code>DPEngineCoreProc</code> (the engine core) and then enters its busy loop.</p><p><code>DPEngineCoreProc</code> initializes its parent <code>EngineCoreProc</code> (child of <code>EngineCore</code>), which:</p><ol><li>Creates an <code>input_queue</code> and <code>output_queue</code> (<code>queue.Queue</code>).</li><li>Performs an initial handshake with the frontend on the other node using a <code>DEALER</code> ZMQ socket (async messaging lib), and receives coordination address info.</li><li>Initializes DP group (e.g. using NCCL backend).</li><li>Initializes the <code>EngineCore</code> with <code>MultiProcExecutor</code> (<code>TP=4</code> on 4 GPUs as described earlier).</li><li>Creates a <code>ready_event</code> (<code>threading.Event</code>).</li><li>Starts an input deamon thread (<code>threading.Thread</code>) running <code>process_input_sockets(‚Ä¶, ready_event)</code>. Similarly starts an output thread.</li><li>Still in the main thread, waits on <code>ready_event</code> until all input threads across all 4 processes (spanning the 2 nodes) have completed the coordination handshake finally executing <code>ready_event.set()</code>.</li><li>Once unblocked, sends a "ready" message to the frontend with metadata (e.g., <code>num_gpu_blocks</code> available in paged KV cache memory).</li><li>The main, input, and output threads then enter their respective busy loops.</li></ol><p>TL;DR: We end up with 4 child processes (one per DP replica), each running a main, input, and output thread. They complete a coordination handshake with the DP coordinator and frontend, then all three threads per process run in steady-state busy loops.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/dpenginecoreproc.png" alt="distributed system with 4 DPEngineCoreProc" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">distributed system with 4 DP replicas running 4 DPEngineCoreProc</div></div><p><strong>Current steady state:</strong></p><ul><li><strong>Input thread</strong> ‚Äî blocks on the input socket until a request is routed from the API server; upon receipt, it decodes the payload, enqueues a work item via <code>input_queue.put_nowait(...)</code>, and returns to blocking on the socket.</li><li><strong>Main thread</strong> ‚Äî wakes on <code>input_queue.get(...)</code>, feeds the request to the engine; <code>MultiProcExecutor</code> runs the forward pass and enqueues results to <code>output_queue</code>.</li><li><strong>Output thread</strong> ‚Äî wakes on <code>output_queue.get(...)</code>, sends the result back to the API server, then resumes blocking.</li></ul><p><strong>Additional mechanics:</strong></p><ul><li><strong>DP wave counter</strong> ‚Äî the system tracks "waves"; when all engines become idle they quiesce, and the counter increments when new work arrives (useful for coordination/metrics).</li><li><strong>Control messages</strong> ‚Äî the API server can send more than just inference requests (e.g., aborts and utility/control RPCs).</li><li><strong>Dummy steps for lockstep</strong> ‚Äî if any DP replica has work, all replicas execute a forward step; replicas without requests perform a dummy step to participate in required synchronization points (avoids blocking the active replica).</li></ul><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Lockstep clarification: this is actually only required for MoE models where the expert layers form an EP or TP group while attention layers are still DP. It's currently always done with DP - this is just because there's limited use for "built-in" non-MoE DP since you could just run multiple independent vLLMs and load-balance between them in a normal way.</div></div>Now for the second part, what happens on the API server node?<h2 class="text-black text-xl mb-3 mt-6">On the API server node</h2><p>We instantiate an <code>AsyncLLM</code> object (an asyncio wrapper around the LLM engine). Internally this creates a <code>DPLBAsyncMPClient</code> (data-parallel, load-balancing, asynchronous, multiprocessing client).</p><p>Inside the parent class of <code>MPClient</code>, the <code>launch_core_engines</code> function runs and:</p><ol><li>Creates the ZMQ addresses used for the startup handshake (as seen on the headless node).</li><li>Spawns a <code>DPCoordinator</code> process.</li><li>Creates a <code>CoreEngineProcManager</code> (same as on the headless node).</li></ol><p>Inside <code>AsyncMPClient</code> (child of <code>MPClient</code>), we:</p><ol><li>Create an <code>outputs_queue</code> (<code>asyncio.Queue</code>).</li><li>We create an asyncio task <code>process_outputs_socket</code> which communicates (through the output socket) with output threads of all 4 <code>DPEngineCoreProc</code> and writes into <code>outputs_queue</code>.</li><li>Subsequently one more asyncio task <code>output_handler</code> from <code>AsyncLLM</code> reads from this queue and finally sends out information to the <code>create_completion</code> function.</li></ol><p>Inside <code>DPAsyncMPClient</code> we create an asyncio task <code>run_engine_stats_update_task</code> which communicates with DP coordinator.</p><p>The DP coordinator mediates between the frontend (API server) and backend (engine cores). It:</p><ul><li>Periodically sends load-balancing info (queue sizes, waiting/running requests) to the frontend's <code>run_engine_stats_update_task</code>.</li><li>Handles <code>SCALE_ELASTIC_EP</code> commands from the frontend by dynamically changing the number of engines (only works with Ray backend).</li><li>Sends <code>START_DP_WAVE</code> events to the backend (when triggered by frontend) and reports wave-state updates back.</li></ul><p>To recap, the frontend (<code>AsyncLLM</code>) runs several asyncio tasks (remember: concurrent, not parallel):</p><ul><li>A class of tasks handles input requests through the <code>generate</code> path (each new client request spawns a new asyncio task).</li><li>Two tasks (<code>process_outputs_socket</code>, <code>output_handler</code>) process output messages from the underlying engines.</li><li>One task (<code>run_engine_stats_update_task</code>) maintains communication with the DP coordinator: sending wave triggers, polling LB state, and handling dynamic scaling requests.</li></ul><p>Finally, the main server process creates a FastAPI app and mounts endpoints such as <code>OpenAIServingCompletion</code> and <code>OpenAIServingChat</code>, which expose <code>/completion</code>, <code>/chat/completion</code>, and others. The stack is then served via Uvicorn.</p><p>So, putting it all together, here's the full request lifecycle!</p><p>You send from your terminal:</p><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-bash" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(221, 87%, 60%)">curl</span><span> -X POST http://localhost:8000/v1/completions -H </span><span class="token" style="color:hsl(119, 34%, 47%)">"Content-Type: application/json"</span><span> -d </span><span class="token" style="color:hsl(119, 34%, 47%)">'{
</span><span class="token" style="color:hsl(119, 34%, 47%)">  "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
</span><span class="token" style="color:hsl(119, 34%, 47%)">  "prompt": "The capital of France is",
</span><span class="token" style="color:hsl(119, 34%, 47%)">  "max_tokens": 50,
</span><span class="token" style="color:hsl(119, 34%, 47%)">  "temperature": 0.7
</span><span class="token" style="color:hsl(119, 34%, 47%)">}'</span><span>
</span></code></pre><p>What happens next:</p><ol><li>The request hits <code>OpenAIServingCompletion</code>'s <code>create_completion</code> route on the API server.</li><li>The function tokenizes the prompt asynchronously, and prepares metadata (request ID, sampling params, timestamp, etc.).</li><li>It then calls <code>AsyncLLM.generate</code>, which follows the same flow as the synchronous engine, eventually invoking <code>DPAsyncMPClient.add_request_async</code>.</li><li>This in turn calls <code>get_core_engine_for_request</code>, which does load balancing across engines based on the DP coordinator's state (picking the one that has minimal score / lowest load: <code>score = len(waiting) * 4 + len(running)</code>).</li><li>The <code>ADD</code> request is sent to the chosen engine's <code>input_socket</code>.</li><li>At that engine:<ul><li>Input thread ‚Äî unblocks, decodes data from the input socket, and places a work item on the <code>input_queue</code> for the main thread.</li><li>Main thread ‚Äî unblocks on <code>input_queue</code>, adds the request to the engine, and repeatedly calls <code>engine_core.step()</code>, enqueueing intermediate results to <code>output_queue</code> until a stop condition is met.</li><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Reminder: <code>step()</code> calls the scheduler, model executor (which in turn can be <code>MultiProcExecutor</code>!), etc. We have already seen this!</div></div><li>Output thread ‚Äî unblocks on <code>output_queue</code> and sends results back through the output socket.</li></ul></li><li>Those results trigger the <code>AsyncLLM</code> output asyncio tasks (<code>process_outputs_socket</code> and <code>output_handler</code>), which propagate tokens back to FastAPI's <code>create_completion</code> route.</li><li>FastAPI attaches metadata (finish reason, logprobs, usage info, etc.) and returns a <code>JSONResponse</code> via Uvicorn to your terminal!</li></ol><p>And just like that, your completion came back ‚Äî the whole distributed machinery hidden behind a simple <code>curl</code> command! :) So much fun!!!</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Additional notes:</div><div class="text-sm leading-relaxed"><ul><li>When adding more API servers, load balancing is handled at the OS/socket level. From the application's perspective, nothing significant changes ‚Äî the complexity is hidden.</li><li>With Ray as a DP backend, you can expose a URL endpoint (<code>/scale_elastic_ep</code>) that enables automatic scaling of the number of engine replicas up or down.</li></ul></div></div><h2 id="cpt5" class="font-semibold text-black text-xl mb-3 mt-6">Benchmarks and auto-tuning - latency vs throughput</h2><p>So far we've been analyzing the "gas particles" ‚Äî the internals of how requests flow through the engine/system. Now it's time to zoom out and look at the system as a whole, and ask: how do we measure the performance of an inference system?</p><p>At the highest level there are two competing metrics:</p><ol><li><strong>Latency</strong> ‚Äî the time from when a request is submitted until tokens are returned</li><li><strong>Throughput</strong> ‚Äî the number of tokens/requests per second the system can generate/process</li></ol><p><strong>Latency</strong> matters most for interactive applications, where users are waiting on responses.</p><p><strong>Throughput</strong> matters in offline workloads like synthetic data generation for pre/post-training runs, data cleaning/processing, and in general - any type of offline batch inference jobs.</p><p>Before explaining why latency and throughput compete, let's define a few common inference metrics:</p><table class="border border-gray-300 border-collapse w-full my-4"><thead><tr class="bg-gray-100"><th class="border border-gray-300 px-4 py-2 text-left font-semibold">Metric</th><th class="border border-gray-300 px-4 py-2 text-left font-semibold">Definition</th></tr></thead><tbody><tr><td class="border border-gray-300 px-4 py-2"><code>TTFT</code><br>(time to first token)</td><td class="border border-gray-300 px-4 py-2">Time from request submission until the first output token is received</td></tr><tr><td class="border border-gray-300 px-4 py-2"><code>ITL</code><br>(inter-token latency)</td><td class="border border-gray-300 px-4 py-2">Time between two consecutive tokens (e.g., from token i-1 to token i)</td></tr><tr><td class="border border-gray-300 px-4 py-2"><code>TPOT</code><br>(time per output token)</td><td class="border border-gray-300 px-4 py-2">The average ITL across all output tokens in a request</td></tr><tr><td class="border border-gray-300 px-4 py-2"><code>Latency / E2E</code><br>(end-to-end latency)</td><td class="border border-gray-300 px-4 py-2">Total time to process a request, i.e. TTFT + sum of all ITLs, or equivalently the time between submitting request and receiving the last output token</td></tr><tr><td class="border border-gray-300 px-4 py-2"><code>Throughput</code></td><td class="border border-gray-300 px-4 py-2">Total tokens processed per second (input, output, or both), or alternatively requests per second</td></tr><tr><td class="border border-gray-300 px-4 py-2"><code>Goodput</code></td><td class="border border-gray-300 px-4 py-2">Throughput that meets service-level objectives (SLOs) such as max TTFT, TPOT, or e2e latency. For example, only tokens from requests meeting those SLOs are counted</td></tr></tbody></table><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/latency_diagram.png" alt="ttft, itl, e2e latency" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">ttft, itl, e2e latency</div></div><p>Here is a simplified model explaining the competing nature of these 2 metrics.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Assumption: weight i/o and not KV cache i/o dominates; i.e. we're dealing with short sequences.</div></div><p>The tradeoff becomes clear when looking at how batch size <code>B</code> affects a single decode step. As <code>B ‚Üì</code> toward 1, ITL drops: there's less work per step and the token isn't "competing" with others. As <code>B ‚Üë</code> toward infinity, ITL rises because we do more FLOPs per step‚Äîbut throughput improves (until we hit peak perf) because weight I/O is amortized across more tokens.</p><p>A roofline model helps with understanding here: below a saturation batch <code>B_sat</code>, the step time is dominated by HBM bandwidth (streaming weights layer-by-layer into on-chip memory), so step latency is nearly flat‚Äîcomputing 1 vs 10 tokens can take a similar time. Beyond <code>B_sat</code>, the kernels become compute-bound and step time grows roughly with <code>B</code>; each extra token adds to ITL.</p><div class="my-6"><img src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/roofline.png" alt="roofline perf model" class="w-max max-w-full h-auto rounded-lg mx-auto "><div class="text-gray-500 text-center text-sm mt-2">roofline perf model</div></div><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#f5f5f5;border-left-color:#757575;color:#424242"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üìù</span>Note:</div><div class="text-sm leading-relaxed">For a more rigorous treatment, we have to account for kernel auto-tuning: as <code>B</code> grows, the runtime may switch to more efficient kernels for that shape, changing the achieved performance <code>P_kernel</code>. Step latency is <code>t = FLOPs_step / P_kernel</code>, where <code>FLOPs_step</code> is the work in the step. You can see that as <code>P_kernel</code> hits <code>P_peak</code> more compute per step will directly lead to an increase in latency.</div></div><h2 class="text-black text-xl mb-3 mt-6">How to benchmark in vLLM</h2><p>vLLM provides a <code>vllm bench <!-- -->{<!-- -->serve,latency,throughput<!-- -->}</code> CLI that wraps vllm / benchmarks / <!-- -->{<!-- -->server,latency,throughput<!-- -->}<!-- -->.py.</p><p>Here is what the scripts do:</p><ul><li><strong>latency</strong> ‚Äî uses a short input (default 32 tokens) and samples 128 output tokens with a small batch (default 8). It runs several iterations and reports e2e latency for the batch.</li><li><strong>throughput</strong> ‚Äî submits a fixed set of prompts (default: 1000 ShareGPT samples) all at once (aka as <code>QPS=Inf</code> mode), and reports input/output/total tokens and requests per second across the run.</li><li><strong>serve</strong> ‚Äî Launches a vLLM server and simulates a real-world workload by sampling request inter-arrival times from a Poisson (or more generally, Gamma) distribution. It sends requests over a time window, measures all the metrics we‚Äôve discussed, and can optionally enforce a server-side max concurrency (via a semaphore, e.g. limiting the server to 64 concurrent requests).</li></ul>Here is an example of how you can run the latency script:<pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:1rem 0;overflow:auto;border-radius:6px;background-color:#f8f9fa;border:1px solid #e9ecef;font-size:14px"><code class="language-bash" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>vllm bench latency
</span><span>  --model </span><span class="token" style="color:hsl(221, 87%, 60%)">&lt;</span><span>model-name</span><span class="token" style="color:hsl(221, 87%, 60%)">&gt;</span><span>
</span><span>  --input-tokens </span><span class="token" style="color:hsl(35, 99%, 36%)">32</span><span>
</span><span>  --output-tokens </span><span class="token" style="color:hsl(35, 99%, 36%)">128</span><span>
</span><span>  --batch-size </span><span class="token" style="color:hsl(35, 99%, 36%)">8</span><span>
</span></code></pre><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="text-sm leading-relaxed">Benchmark configs used in CI live under <code>.buildkite/nightly-benchmarks/tests</code>.</div></div><p>There is also an auto-tune script that drives the serve benchmark to find argument settings that meet target SLOs (e.g., "maximize throughput while keeping p99 e2e <!-- -->&lt;<!-- --> 500 ms"), returning a suggested config.</p><h2 class="font-semibold text-black text-xl mb-3 mt-6">Epilogue</h2><p>We began with the basic engine core (<code>UniprocExecutor</code>), added advanced features like speculative decoding and prefix caching, scaled up to <code>MultiProcExecutor</code> (with <code>TP/PP <!-- -->&gt;<!-- --> 1</code>), and finally scaled out, wrapped everything in the asynchronous engine and distributed serving stack‚Äîclosing with how to measure system performance.</p><p>vLLM also includes specialized handling that I've skipped. E.g.:</p><ul><li><strong>Diverse hardware backends:</strong> TPUs, AWS Neuron (Trainium/Inferentia), etc.</li><li><strong>Architectures/techniques:</strong> <code>MLA</code>, <code>MoE</code>, encoder-decoder (e.g., Whisper), pooling/embedding models, <code>EPLB</code>, <code>m-RoPE</code>, <code>LoRA</code>, <code>ALiBi</code>, attention-free variants, sliding-window attention, multimodal LMs, and state-space models (e.g., Mamba/Mamba-2, Jamba)</li><li><strong>TP/PP/SP</strong></li><li><strong>Hybrid KV-cache logic</strong> (Jenga), more complex sampling methods like beam sampling, and more</li><li><strong>Experimental</strong>: async scheduling</li></ul><p>The nice thing is that most of these are orthogonal to the main flow described above‚Äîyou can almost treat them like "plugins" (in practice there's some coupling, of course).</p><p>I love understanding systems. Having said that, the resolution definitely suffered at this altitude. In the next posts I'll zoom in on specific subsystems and get into the nitty-gritty details.</p><div class="my-4 p-4 rounded-lg border-l-4" style="background-color:#e3f2fd;border-left-color:#2196f3;color:#0d47a1"><div class="flex items-center mb-2 font-semibold"><span class="mr-2 text-lg">üí°</span>Get in touch:</div><div class="text-sm leading-relaxed">If you spot any errors in the post, please DM me - feel free to drop me a message on <a href="https://x.com/gordic_aleksa" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">X</a> or <a href="https://www.linkedin.com/in/aleksagordic/" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">LinkedIn</a> or via <a href="https://docs.google.com/forms/d/1z1fEirrN2xtGxAsJvptpM7yV4ByT5SF25S-XiMPrXNA/edit" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">anon feedback</a>.</div></div><h2 id="references" class="text-black text-xl mb-3 mt-6">Acknowledgements</h2><p>A huge thank you to <a href="https://www.hyperstack.cloud/" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">Hyperstack</a> for providing me with H100s for my experiments over the past year!</p><p>Thanks to <a href="https://www.linkedin.com/in/nickhillprofile/" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">Nick Hill</a> (core vLLM contributor, RedHat), <a href="https://x.com/marksaroufim" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">Mark Saroufim</a> (PyTorch), <a href="https://www.linkedin.com/in/kyle-kranen/" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">Kyle Krannen</a> (NVIDIA, Dynamo), and <a href="https://www.linkedin.com/in/ashish-vaswani-99892181/" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">Ashish Vaswani</a> for reading pre-release version of this blog post and providing feedback!</p><h2 id="references" class="text-black text-xl mb-3 mt-6">References</h2><ol class="break-words overflow-hidden"><li id="ref-1">vLLM <a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://github.com/vllm-project/vllm</a></li><li id="ref-2">"Attention Is All You Need", <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/1706.03762</a></li><li id="ref-3">"Efficient Memory Management for Large Language Model Serving with PagedAttention", <a href="https://arxiv.org/abs/2309.06180" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2309.06180</a></li><li id="ref-4">"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model", <a href="https://arxiv.org/abs/2405.04434" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2405.04434</a></li><li id="ref-5">"Jenga: Effective Memory Management for Serving LLM with Heterogeneity", <a href="https://arxiv.org/abs/2503.18292" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2503.18292</a></li><li id="ref-6">"Orca: A Distributed Serving System for Transformer-Based Generative Models", <a href="https://www.usenix.org/conference/osdi22/presentation/yu" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://www.usenix.org/conference/osdi22/presentation/yu</a></li><li id="ref-7">"XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models", <a href="https://arxiv.org/abs/2411.15100" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2411.15100</a></li><li id="ref-8">"Accelerating Large Language Model Decoding with Speculative Sampling", <a href="https://arxiv.org/abs/2302.01318" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2302.01318</a></li><li id="ref-9">"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty", <a href="https://arxiv.org/abs/2401.15077" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2401.15077</a></li><li id="ref-10">"Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads", <a href="https://arxiv.org/abs/2401.10774" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://arxiv.org/abs/2401.10774</a></li><li id="ref-11">LMCache, <a href="https://github.com/LMCache/LMCache" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline hover:text-blue-800 ">https://github.com/LMCache/LMCache</a></li></ol></div></article></div></div><!--$--><!--/$--><script src="./Inside vLLM_ Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá_files/webpack-c7d969e615b48ab2.js.‰∏ãËΩΩ" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9766,[],\"\"]\n3:I[8924,[],\"\"]\nf0:I[7150,[],\"\"]\n:HL[\"/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/0fea4a98dee3ff8f.css?dpl=dpl_74SobJ1Bb64XmBtyRox4RHACyX8i\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"gV5ncQn3ms-Uyetf8SovW\",\"p\":\"\",\"c\":[\"\",\"blog\",\"vllm\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[\"vllm\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0fea4a98dee3ff8f.css?dpl=dpl_74SobJ1Bb64XmBtyRox4RHACyX8i\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"style\",null,{\"children\":\"\\n          @font-face {\\n            font-family: 'Monaco';\\n            src: local('Monaco');\\n            font-display: swap;\\n          }\\n        \"}]}],[\"$\",\"body\",null,{\"className\":\"__variable_188709 __variable_9a8899 antialiased font-mono\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"vllm\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex justify-center min-h-screen bg-white font-mono\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-left max-w-[800px] w-full mt-16 px-4 sm:px-8 lg:px-0\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-6\",\"children\":[\"$\",\"a\",null,{\"href\":\"/blog\",\"className\":\"underline decoration-1 decoration-black hover:decoration-2 text-gray-700\",\"children\":\"‚Üê Back to blog\"}]}],[\"$\",\"article\",null,{\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"font-bold text-black text-3xl mb-4\",\"children\":\"Inside vLLM: Anatomy of a High-Throughput LLM Inference System\"}],[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-sm\",\"children\":\"August 29, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"prose prose-gray max-w-none leading-relaxed text-gray-700 [\u0026_p]:text-gray-700 [\u0026_p]:mb-4 [\u0026_code]:bg-gray-200 [\u0026_code]:text-red-600 [\u0026_code]:px-1 [\u0026_code]:py-0.5 [\u0026_code]:rounded [\u0026_code]:text-sm [\u0026_code]:font-mono [\u0026_ol]:text-gray-700 [\u0026_ol]:list-decimal [\u0026_ol]:list-inside [\u0026_ol]:pl-6 [\u0026_ol]:mb-6 [\u0026_ol]:mt-3 [\u0026_li]:mb-3 [\u0026_ul]:list-disc [\u0026_ul]:list-inside [\u0026_ul]:pl-6 [\u0026_ul]:space-y-1\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"In this post, I'll gradually introduce all of the core system components and advanced features that make up a modern high-throughput LLM inference system. In particular I'll be doing a breakdown of how vLLM \",[\"$\",\"a\",null,{\"href\":\"#ref-1\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[1]\"}],\" works.\"]}],\"$L4\",\"$L5\",\"$L6\",\"$L7\",\"$L8\",\"$L9\",\"$La\",\"$Lb\",\"$Lc\",\"$Ld\",\"$Le\",\"$Lf\",\"$L10\",\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\",\"$L18\",\"$L19\",\"$L1a\",\"$L1b\",\"$L1c\",\"$L1d\",\"$L1e\",\"$L1f\",\"Now that we have the engine initialized let's proceed to the \",\"$L20\",\" function.\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\",\"$L2d\",\"$L2e\",\"$L2f\",\"$L30\",\"The scheduler prioritizes decode requests ‚Äî i.e. those already in the \",\"$L31\",\" queue. For each such request it:\",\"$L32\",\"After that, it processes prefill requests from the \",\"$L33\",\" queue, it:\",\"$L34\",\"Let's now look at what \",\"$L35\",\" does, it:\",\"$L36\",\"$L37\",\"We're finally ready to do a forward pass!\",\"$L38\",\"$L39\",\"$L3a\",\"$L3b\",\"$L3c\",\"$L3d\",\"$L3e\",\"$L3f\",\"$L40\",\"$L41\",\"$L42\",\"$L43\",\"$L44\",\"$L45\",\"$L46\",\"$L47\",\"$L48\",\"$L49\",\"$L4a\",\"$L4b\",\"$L4c\",\"$L4d\",\"$L4e\",\"$L4f\",\"$L50\",\"$L51\",\"$L52\",\"$L53\",\"$L54\",\"$L55\",\"$L56\",\"$L57\",\"$L58\",\"$L59\",\"$L5a\",\"$L5b\",\"$L5c\",\"$L5d\",\"$L5e\",\"$L5f\",\"$L60\",\"$L61\",\"$L62\",\"$L63\",\"$L64\",\"$L65\",\"$L66\",\"$L67\",\"$L68\",\"$L69\",\"$L6a\",\"$L6b\",\"$L6c\",\"$L6d\",\"$L6e\",\"$L6f\",\"$L70\",\"$L71\",\"$L72\",\"$L73\",\"$L74\",\"$L75\",\"$L76\",\"$L77\",\"$L78\",\"$L79\",\"$L7a\",\"$L7b\",\"$L7c\",\"$L7d\",\"Here's how to invoke speculative decoding in vLLM using \",\"$L7e\",\" as the draft method:\",\"$L7f\",\"$L80\",\"$L81\",\"$L82\",\"$L83\",\"$L84\",\"The best way to internalize this is to fire up your debugger and step through the codebase, but this section hopefully gives you a taste for it. This as well:\",\"$L85\",\"$L86\",\"$L87\",\"$L88\",\"$L89\",\"$L8a\",\"$L8b\",\"$L8c\",\"$L8d\",\"$L8e\",\"$L8f\",\"$L90\",\"$L91\",\"$L92\",\"$L93\",\"$L94\",\"$L95\",\"$L96\",\"$L97\",\"$L98\",\"$L99\",\"$L9a\",\"$L9b\",\"$L9c\",\"$L9d\",\"$L9e\",\"$L9f\",\"$La0\",\"$La1\",\"$La2\",\"$La3\",\"$La4\",\"$La5\",\"$La6\",\"$La7\",\"$La8\",\"$La9\",\"$Laa\",\"$Lab\",\"$Lac\",\"$Lad\",\"$Lae\",\"$Laf\",\"$Lb0\",\"$Lb1\",\"$Lb2\",\"$Lb3\",\"$Lb4\",\"$Lb5\",\"$Lb6\",\"$Lb7\",\"$Lb8\",\"Now for the second part, what happens on the API server node?\",\"$Lb9\",\"$Lba\",\"$Lbb\",\"$Lbc\",\"$Lbd\",\"$Lbe\",\"$Lbf\",\"$Lc0\",\"$Lc1\",\"$Lc2\",\"$Lc3\",\"$Lc4\",\"$Lc5\",\"$Lc6\",\"$Lc7\",\"$Lc8\",\"$Lc9\",\"$Lca\",\"$Lcb\",\"$Lcc\",\"$Lcd\",\"$Lce\",\"$Lcf\",\"$Ld0\",\"$Ld1\",\"$Ld2\",\"$Ld3\",\"$Ld4\",\"$Ld5\",\"$Ld6\",\"$Ld7\",\"$Ld8\",\"$Ld9\",\"$Lda\",\"$Ldb\",\"$Ldc\",\"$Ldd\",\"$Lde\",\"Here is an example of how you can run the latency script:\",\"$Ldf\",\"$Le0\",\"$Le1\",\"$Le2\",\"$Le3\",\"$Le4\",\"$Le5\",\"$Le6\",\"$Le7\",\"$Le8\",\"$Le9\",\"$Lea\",\"$Leb\",\"$Lec\",\"$Led\"]}]]}]]}]}],null,\"$Lee\"]}],{},null,false]},null,false]},null,false]},null,false],\"$Lef\",false]],\"m\":\"$undefined\",\"G\":[\"$f0\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"359:I[4431,[],\"OutletBoundary\"]\n35b:I[5278,[],\"AsyncMetadataOutlet\"]\n35d:I[4431,[],\"ViewportBoundary\"]\n35f:I[4431,[],\"MetadataBoundary\"]\n360:\"$Sreact.suspense\"\n4:[\"$\",\"p\",null,{\"children\":\"This post is the first in a series. It starts broad and then layers in detail (following an inverse-pyramid approach) so you can form an accurate high-level mental model of the complete system without drowning in minutiae.\"}]\n5:[\"$\",\"p\",null,{\"children\":\"Later posts will dive into specific subsystems.\"}]\n6:[\"$\",\"p\",null,{\"children\":\"This post is structured into five parts:\"}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"#cpt1\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"LLM engine \u0026 engine core\"}],\": fundamentals of vLLM (scheduling, paged attention, continuous batching, etc.)  \"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"#cpt2\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"Advanced features\"}],\": chunked prefill, prefix caching, guided \u0026 speculative decoding, disaggregated P/D\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"#cpt3\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"Scaling up\"}],\": from single-GPU to multi-GPU execution\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"#cpt4\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"Serving layer\"}],\": distributed / concurrent web scaffolding\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"#cpt5\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"Benchmarks and auto-tuning\"}],\": measuring latency and throughput  \"]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Notes\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Analysis is based on \",[\"$\",\"a\",null,{\"href\":\"https://github.com/vllm-project/vllm/tree/42172ad\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"commit 42172ad\"}],\" (August 9th, 2025).\"]}],[\"$\",\"li\",null,{\"children\":\"Target audience: anyone curious about how state-of-the-art LLM engines work, as well as those interested in contributing to vLLM, SGLang, etc.\"}],[\"$\",\"li\",null,{\"children\":[\"I'll focus on the \",[\"$\",\"a\",null,{\"href\":\"https://docs.vllm.ai/en/latest/usage/v1_guide.html\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"V1 engine\"}],\". I also explored V0 (\",[\"$\",\"a\",null,{\"href\":\"https://github.com/vllm-project/vllm/issues/18571\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"now deprecated\"}],\"), which was valuable for understanding how the project evolved, and many concepts still carry over.\"]}],[\"$\",\"li\",null,{\"children\":\"The first section on LLM Engine / Engine Core might be a bit overwhelming/dry - but the rest of the blog has plenty examples and visuals. :)\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"h2\",null,{\"id\":\"cpt1\",\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"LLM Engine \u0026 Engine Core\"}]\na:[\"$\",\"p\",null,{\"children\":\"The LLM engine is the fundamental building block of vLLM. On its own, it already enables high-throughput inference - but only in an offline setting. You can't serve it to customers over the web yet.\"}]\nb:[\"$\",\"p\",null,{\"children\":[\"We'll use the following offline inference snippet as our running example (adapted from \",[\"$\",\"a\",null,{\"href\":\"https://github.com/vllm-project/vllm/blob/main/examples/offline_inference/basic/basic.py\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"basic.py\"}],\").\"]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts \"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Hello, my name is\\\"\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"The president of the United States is\\\"\"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-24\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sampling_params \"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"temperature\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-30\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.8\"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" top_p\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.95\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-38\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-39\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}],\"$Lf1\",\"$Lf2\",\"$Lf3\",\"$Lf4\",\"$Lf5\",\"$Lf6\",\"$Lf7\",\"$Lf8\",\"$Lf9\",\"$Lfa\",\"$Lfb\",\"$Lfc\",\"$Lfd\",\"$Lfe\",\"$Lff\",\"\\n\",\"$L100\",\"$L101\",\"$L102\",\"$L103\",\"$L104\",\"$L105\",\"$L106\",\"$L107\",\"$L108\",\"$L109\",\"$L10a\",\"\\n\",\"$L10b\",\"$L10c\",\"$L10d\",\"$L10e\",\"$L10f\",\"$L110\",\"$L111\",\"$L112\",\"$L113\",\"$L114\",\"$L115\"]]}]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Environment vars:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"VLLM_USE_V1=\\\"1\\\" # we're using engine V1\"}],[\"$\",\"li\",null,{\"children\":\"VLLM_ENABLE_V1_MULTIPROCESSING=\\\"0\\\" # we're running in a single process\"}]]}]}]]}]\ne:[\"$\",\"p\",null,{\"children\":\"This configuration is:\"}]\nf:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"offline (no web/distributed system scaffolding)\"}],[\"$\",\"li\",null,{\"children\":\"synchronous (all execution happens in a single blocking process)\"}],[\"$\",\"li\",null,{\"children\":\"single-GPU (no data/model/pipeline/expert parallelism; DP/TP/PP/EP = 1)\"}],[\"$\",\"li\",null,{\"children\":[\"using standard transformer \",[\"$\",\"a\",null,{\"href\":\"#ref-2\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[2]\"}],\" (supporting hybrid models like Jamba requires a more complex hybrid KV-cache memory allocator)\"]}]]}]\n10:[\"$\",\"p\",null,{\"children\":\"From here, we'll gradually build up to an online, async, multi-GPU, multi-node inference system - but still serving a standard transformer.\"}]\n11:[\"$\",\"p\",null,{\"children\":\"In this example we do two things, we:\"}]\n12:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Instantiate an engine\"}],[\"$\",\"li\",null,{\"children\":[\"Call \",[\"$\",\"code\",null,{\"children\":\"generate\"}],\" on it to sample from the given prompts\"]}]]}]\n13:[\"$\",\"p\",null,{\"children\":\"Let's start analyzing the constructor.\"}]\n14:[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"LLM Engine constructor\"}]\n15:[\"$\",\"p\",null,{\"children\":\"The main components of the engine are:\"}]\n"])</script><script>self.__next_f.push([1,"16:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"vLLM config (contains all of the knobs for configuring model, cache, parallelism, etc.)\"}],[\"$\",\"li\",null,{\"children\":[\"processor (turns raw inputs ‚Üí \",[\"$\",\"code\",null,{\"children\":\"EngineCoreRequests\"}],\" via validation, tokenization, and processing)\"]}],[\"$\",\"li\",null,{\"children\":[\"engine core client (in our running example we're using \",[\"$\",\"code\",null,{\"children\":\"InprocClient\"}],\" which is basically == \",[\"$\",\"code\",null,{\"children\":\"EngineCore\"}],\"; we'll gradually build up to \",[\"$\",\"code\",null,{\"children\":\"DPLBAsyncMPClient\"}],\" which allows serving at scale)\"]}],[\"$\",\"li\",null,{\"children\":[\"output processor (converts raw \",[\"$\",\"code\",null,{\"children\":\"EngineCoreOutputs\"}],\" ‚Üí \",[\"$\",\"code\",null,{\"children\":\"RequestOutput\"}],\" that the user sees)\"]}]]}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"With the V0 engine being deprecated, class names and details may shift. I'll emphasize the core ideas rather than exact signatures. I'll abstract away some but not all of those details.\"}]]}]\n18:[\"$\",\"p\",null,{\"children\":\"Engine core itself is made up of several sub components:\"}]\n"])</script><script>self.__next_f.push([1,"19:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Model Executor (drives forward passes on the model, we're currently dealing with \",[\"$\",\"code\",null,{\"children\":\"UniProcExecutor\"}],\" which has a single \",[\"$\",\"code\",null,{\"children\":\"Worker\"}],\" process on a single GPU). We'll gradually build up to \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" which supports multiple GPUs\"]}],[\"$\",\"li\",null,{\"children\":\"Structured Output Manager (used for guided decoding - we'll cover this later)\"}],[\"$\",\"li\",null,{\"children\":[\"Scheduler (decides which requests go into the next engine step) - it further contains:\",[\"$\",\"ol\",null,{\"style\":{\"listStyleType\":\"lower-alpha\"},\"className\":\"ml-6 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"policy setting - it can be either \",[\"$\",\"b\",null,{\"children\":\"FCFS\"}],\" (first come first served) or \",[\"$\",\"b\",null,{\"children\":\"priority\"}],\" (higher priority requests are served first)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"waiting\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"running\"}],\" queues\"]}],[\"$\",\"li\",null,{\"children\":[\"KV cache manager - the heart of paged attention \",[\"$\",\"a\",null,{\"href\":\"#ref-3\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[3]\"}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"1a:[\"$\",\"p\",null,{\"children\":[\"The KV-cache manager maintains a \",[\"$\",\"code\",null,{\"children\":\"free_block_queue\"}],\" - a pool of available KV-cache blocks (often on the order of hundreds of thousands, depending on VRAM size and block size). During paged attention, the blocks serve as the indexing structure that map tokens to their computed KV cache blocks.\"]}]\n1b:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/engine_constructor.png\",\"alt\":\"LLM engine constructor\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"Core components described in this section and their relationships\"}]]}]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"Block size for a standard transformer layer (non-MLA \",[\"$\",\"a\",null,{\"href\":\"#ref-4\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[4]\"}],\") is computed as follows:\",[\"$\",\"br\",null,{}],\" 2 (key/value) * \",[\"$\",\"code\",null,{\"children\":\"block_size\"}],\" (default=16) * \",[\"$\",\"code\",null,{\"children\":\"num_kv_heads\"}],\" * \",[\"$\",\"code\",null,{\"children\":\"head_size\"}],\" * \",[\"$\",\"code\",null,{\"children\":\"dtype_num_bytes\"}],\" (e.g. 2 for bf16)\"]}]]}]\n"])</script><script>self.__next_f.push([1,"1d:[\"$\",\"p\",null,{\"children\":[\"During model executor construction, a \",[\"$\",\"code\",null,{\"children\":\"Worker\"}],\" object is created, and three key procedures are executed. (Later, with \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\", these same procedures run independently on each worker process across different GPUs.)\"]}]\n"])</script><script>self.__next_f.push([1,"1e:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Init device:\",[\"$\",\"ul\",null,{\"className\":\"ml-6 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Assign a CUDA device (e.g. \\\"cuda:0\\\") to the worker and check that the model dtype is supported (e.g. bf16)\"}],[\"$\",\"li\",null,{\"children\":[\"Verify enough VRAM is available, given the requested \",[\"$\",\"code\",null,{\"children\":\"gpu_memory_utilization\"}],\" (e.g. 0.8 ‚Üí 80% of total VRAM)\"]}],[\"$\",\"li\",null,{\"children\":\"Set up distributed settings (DP / TP / PP / EP, etc.)\"}],[\"$\",\"li\",null,{\"children\":[\"Instantiate a \",[\"$\",\"code\",null,{\"children\":\"model_runner\"}],\" (holds the sampler, KV cache, and forward-pass buffers such as \",[\"$\",\"code\",null,{\"children\":\"input_ids\"}],\", \",[\"$\",\"code\",null,{\"children\":\"positions\"}],\", etc.)\"]}],[\"$\",\"li\",null,{\"children\":[\"Instantiate an \",[\"$\",\"code\",null,{\"children\":\"InputBatch\"}],\" object (holds CPU-side forward-pass buffers, block tables for KV-cache indexing, sampling metadata, etc.)\"]}]]}]]}],[\"$\",\"li\",null,{\"children\":[\"Load model:\",[\"$\",\"ul\",null,{\"className\":\"ml-6 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Instantiate the model architecture\"}],[\"$\",\"li\",null,{\"children\":\"Load the model weights\"}],[\"$\",\"li\",null,{\"children\":\"Call model.eval() (PyTorch's inference mode)\"}],[\"$\",\"li\",null,{\"children\":\"Optional: call torch.compile() on the model\"}]]}]]}],[\"$\",\"li\",null,{\"children\":[\"Initialize KV cache\",[\"$\",\"ul\",null,{\"className\":\"ml-6 mt-2 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"Get per-layer KV-cache spec. Historically this was always \",[\"$\",\"code\",null,{\"children\":\"FullAttentionSpec\"}],\" (homogeneous transformer), but with hybrid models (sliding window, Transformer/SSM like Jamba) it became more complex (see Jenga \",[\"$\",\"a\",null,{\"href\":\"#ref-5\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[5]\"}],\")\"]}],[\"$\",\"li\",null,{\"children\":\"Run a dummy/profiling forward pass and take a GPU memory snapshot to compute how many KV cache blocks fit in available VRAM\"}],[\"$\",\"li\",null,{\"children\":\"Allocate, reshape and bind KV cache tensors to attention layers\"}],[\"$\",\"li\",null,{\"children\":\"Prepare attention metadata (e.g. set the backend to FlashAttention) later consumed by kernels during the fwd pass\"}],[\"$\",\"li\",null,{\"children\":[\"Unless \",[\"$\",\"code\",null,{\"children\":\"--enforce-eager\"}],\" is provided, for each of warmup batch sizes do a dummy run and capture CUDA graphs. CUDA graphs record the whole sequence of GPU work into a DAG. Later during fwd pass we launch/replay pre-baked graphs and cut on kernel launch overhead and thus improve latency.\"]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"1f:[\"$\",\"p\",null,{\"children\":\"I've abstracted away many low-level details here ‚Äî but these are the core pieces I'll introduce now, since I'll reference them repeatedly in the following sections.\"}]\n20:[\"$\",\"code\",null,{\"children\":\"generate\"}]\n21:[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"Generate function\"}]\n22:[\"$\",\"p\",null,{\"children\":\"The first step is to validate and feed requests into the engine. For each prompt we:\"}]\n"])</script><script>self.__next_f.push([1,"23:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Create a unique request ID and capture its arrival time\"}],[\"$\",\"li\",null,{\"children\":[\"Call an input preprocessor that tokenizes the prompt and returns a dictionary containing \",[\"$\",\"code\",null,{\"children\":\"prompt\"}],\", \",[\"$\",\"code\",null,{\"children\":\"prompt_token_ids\"}],\", and a \",[\"$\",\"code\",null,{\"children\":\"type\"}],\" (text, tokens, embeds, etc.)\"]}],[\"$\",\"li\",null,{\"children\":[\"Pack this info into an \",[\"$\",\"code\",null,{\"children\":\"EngineCoreRequest\"}],\", adding priority, sampling params, and other metadata\"]}],[\"$\",\"li\",null,{\"children\":[\"Pass the request into the engine core, which wraps it in a \",[\"$\",\"code\",null,{\"children\":\"Request\"}],\" object and sets its status to \",[\"$\",\"code\",null,{\"children\":\"WAITING\"}],\". This request is then added to the scheduler's \",[\"$\",\"code\",null,{\"children\":\"waiting\"}],\" queue (append if FCFS, or heap-push if priority)\"]}]]}]\n"])</script><script>self.__next_f.push([1,"24:[\"$\",\"p\",null,{\"children\":[\"At this point the engine has been fed and execution can begin. In the synchronous engine example, these initial prompts are the only ones we'll process ‚Äî there's no mechanism to inject new requests mid-run. In contrast, the asynchronous engine supports this (aka \",[\"$\",\"b\",null,{\"children\":\"continuous batching\"}],\" \",[\"$\",\"a\",null,{\"href\":\"#ref-6\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[6]\"}],\"): after each step, both new and old requests are considered.\"]}]\n25:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"Because the forward pass flattens the batch into a single sequence and custom kernels handle it efficiently, continuous batching is fundamentally supported even in the synchronous engine.\"}]]}]\n26:[\"$\",\"p\",null,{\"children\":[\"Next, as long as there are requests to process, the engine repeatedly calls its \",[\"$\",\"code\",null,{\"children\":\"step()\"}],\" function. Each step has three stages:\"]}]\n27:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Schedule: select which requests to run in this step (decode, and/or (chunked) prefill)\"}],[\"$\",\"li\",null,{\"children\":\"Forward pass: run the model and sample tokens\"}],[\"$\",\"li\",null,{\"children\":[\"Postprocess: append sampled token IDs to each \",[\"$\",\"code\",null,{\"children\":\"Request\"}],\", detokenize, and check stop conditions. If a request is finished, clean up (e.g. return its KV-cache blocks to \",[\"$\",\"code\",null,{\"children\":\"free_block_queue\"}],\") and return the output early\"]}]]}]\n"])</script><script>self.__next_f.push([1,"28:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Stop conditions are:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"className\":\"mt-2 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"The request exceeds its length limit (\",[\"$\",\"code\",null,{\"children\":\"max_model_length\"}],\" or its own \",[\"$\",\"code\",null,{\"children\":\"max_tokens\"}],\")\"]}],[\"$\",\"li\",null,{\"children\":[\"The sampled token is the EOS ID (unless \",[\"$\",\"code\",null,{\"children\":\"ignore_eos\"}],\" is enabled -\",\"\u003e\",\" useful for benchmarking when we want to force a generation of a certain number of out tokens)\"]}],[\"$\",\"li\",null,{\"children\":[\"The sampled token matches any of the \",[\"$\",\"code\",null,{\"children\":\"stop_token_ids\"}],\" specified in the sampling parameters\"]}],[\"$\",\"li\",null,{\"children\":[\"Stop strings are present in the output - we truncate the output until the first stop string appearance and abort the request in the engine (note that \",[\"$\",\"code\",null,{\"children\":\"stop_token_ids\"}],\" will be present in the output but stop strings will not).\"]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"29:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/engine_loop.png\",\"alt\":\"Engine loop\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"Engine loop\"}]]}]\n2a:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"In streaming mode, we would send intermediate tokens as they are generated, but we'll ignore that for now.\"}]]}]\n2b:[\"$\",\"p\",null,{\"children\":\"Next, we'll examine scheduling in more detail.\"}]\n2c:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Scheduler\"}]\n2d:[\"$\",\"p\",null,{\"children\":\"There are two main types of workloads an inference engine handles:\"}]\n"])</script><script>self.__next_f.push([1,"2e:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"Prefill\"}],\" requests ‚Äî a forward pass over all prompt tokens. These are usually \",[\"$\",\"b\",null,{\"children\":\"compute-bound\"}],\" (threshold depends on hardware and prompt length). At the end, we sample a single token from the probability distribution of the final token's position.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"Decode\"}],\" requests ‚Äî a forward pass over just the most recent token. All earlier KV vectors are already cached. These are \",[\"$\",\"b\",null,{\"children\":\"memory-bandwidth-bound\"}],\", since we still need to load all LLM weights (and KV caches) just to compute one token.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"2f:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"In the \",[\"$\",\"a\",null,{\"href\":\"#cpt5\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"benchmarking section\"}],\" we'll analyze the so-called roofline model of GPU perf. That will go into more detail behind prefill/decode perf profiles.\"]}]]}]\n30:[\"$\",\"p\",null,{\"children\":\"The V1 scheduler can mix both types of requests in the same step, thanks to smarter design choices. In contrast, the V0 engine could only process either prefill or decode at once.\"}]\n31:[\"$\",\"code\",null,{\"children\":\"running\"}]\n32:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Computes the number of new tokens to generate (not always 1, due to speculative decoding and async scheduling ‚Äî more on that later).\"}],[\"$\",\"li\",null,{\"children\":[\"Calls the KV-cache manager's \",[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}],\" function (details below).\"]}],[\"$\",\"li\",null,{\"children\":\"Updates the token budget by subtracting the number of tokens from step 1.\"}]]}]\n33:[\"$\",\"code\",null,{\"children\":\"waiting\"}]\n34:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Retrieves the number of computed blocks (returns 0 if prefix caching is disabled ‚Äî we'll cover that later).\"}],[\"$\",\"li\",null,{\"children\":[\"Calls the KV-cache manager's \",[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}],\" function.\"]}],[\"$\",\"li\",null,{\"children\":[\"Pops the request from waiting and moves it to running, setting its status to \",[\"$\",\"code\",null,{\"children\":\"RUNNING\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":\"Updates the token budget.\"}]]}]\n35:[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}]\n"])</script><script>self.__next_f.push([1,"36:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Computes number of blocks\"}],\" ‚Äî determines how many new KV-cache blocks (\",[\"$\",\"code\",null,{\"children\":\"n\"}],\") must be allocated. Each block stores 16 tokens by default. For example, if a prefill request has 17 new tokens, we need \",[\"$\",\"code\",null,{\"children\":\"ceil(17/16) = 2\"}],\" blocks.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Checks availability\"}],\" ‚Äî if there aren't enough blocks in the manager's pool, exit early. Depending on whether it's a decode or prefill request, the engine may attempt recompute preemption (swap preemption was supported in V0) by evicting low-priority requests (calling \",[\"$\",\"code\",null,{\"children\":\"kv_cache_manager.free\"}],\" which returns KV blocks to block pool), or it might skip scheduling and continue execution.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Allocates blocks\"}],\" ‚Äî via the KV-cache manager's coordinator, fetches the first \",[\"$\",\"code\",null,{\"children\":\"n\"}],\" blocks from the block pool (the \",[\"$\",\"code\",null,{\"children\":\"free_block_queue\"}],\" doubly linked list mentioned earlier). Stores to \",[\"$\",\"code\",null,{\"children\":\"req_to_blocks\"}],\", the dictionary mapping each \",[\"$\",\"code\",null,{\"children\":\"request_id\"}],\" to its list of KV-cache blocks.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"37:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/kv_cache_blocks.png\",\"alt\":\"KV cache blocks\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"list of KV cache blocks\"}]]}]\n38:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Run forward pass\"}]\n39:[\"$\",\"p\",null,{\"children\":[\"We call model executor's \",[\"$\",\"code\",null,{\"children\":\"execute_model\"}],\", which delegates to the \",[\"$\",\"code\",null,{\"children\":\"Worker\"}],\", which in turn delegates to the model runner.\"]}]\n3a:[\"$\",\"p\",null,{\"children\":\"Here are the main steps:\"}]\n"])</script><script>self.__next_f.push([1,"3b:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Update states\"}],\" ‚Äî prune finished requests from \",[\"$\",\"code\",null,{\"children\":\"input_batch\"}],\"; update misc fwd pass related metadata (e.g., KV cache blocks per request that will be used to index into paged KV cache memory).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Prepare inputs\"}],\" ‚Äî copy buffers from CPU‚ÜíGPU; compute positions; build \",[\"$\",\"code\",null,{\"children\":\"slot_mapping\"}],\" (more on that in example); construct attention metadata.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Forward pass\"}],\" ‚Äî run the model with custom paged attn kernels. All sequences are flattened and concatenated into one long \\\"super sequence\\\". Position indices and attention masks ensure each sequence only attends to its own tokens, which enables continuous batching without right-padding.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Gather last-token states\"}],\" ‚Äî extract hidden states for each sequence's final position and compute logits.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Sample\"}],\" ‚Äî sample tokens from computed logits as dictated by the sampling config (greedy, temperature, top-p, top-k, etc.).\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3c:[\"$\",\"p\",null,{\"children\":\"Forward-pass step itself has two execution modes:\"}]\n3d:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Eager mode\"}],\" ‚Äî run the standard PyTorch forward pass when eager execution is enabled.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"\\\"Captured\\\" mode\"}],\" ‚Äî execute/replay a pre-captured CUDA Graph when eager is not enforced (remember we captured these during engine construction in the initialize KV cache procedure).\"]}]]}]\n3e:[\"$\",\"p\",null,{\"children\":\"Here is a concrete example that should make continuous batching and paged attention clear:\"}]\n3f:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/fwd_pass.png\",\"alt\":\"fwd pass - continuous batching \u0026 paged attn\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"Forward pass: continuous batching and paged attention\"}]]}]\n40:[\"$\",\"h2\",null,{\"id\":\"cpt2\",\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Advanced Features ‚Äî extending the core engine logic\"}]\n41:[\"$\",\"p\",null,{\"children\":\"With the basic engine flow in place, we can now look at the advanced features.\"}]\n42:[\"$\",\"p\",null,{\"children\":\"We've already discussed preemption, paged attention, and continuous batching.\"}]\n43:[\"$\",\"p\",null,{\"children\":\"Next, we'll dive into:\"}]\n44:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Chunked prefill\"}],[\"$\",\"li\",null,{\"children\":\"Prefix caching\"}],[\"$\",\"li\",null,{\"children\":\"Guided decoding (through grammar-constrained finite-state machines)\"}],[\"$\",\"li\",null,{\"children\":\"Speculative decoding\"}],[\"$\",\"li\",null,{\"children\":\"Disaggregated P/D (prefill/decoding)\"}]]}]\n45:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Chunked prefill\"}]\n46:[\"$\",\"p\",null,{\"children\":\"Chunked prefill is a technique for handling long prompts by splitting their prefill step into smaller chunks. Without it, we c"])</script><script>self.__next_f.push([1,"ould end up with a single very long request monopolizing one engine step disallowing other prefill requests to run. That would postpone all other requests and increase their latency.\"}]\n47:[\"$\",\"p\",null,{\"children\":[\"For example, let each chunk contain \",[\"$\",\"code\",null,{\"children\":\"n\"}],\" (=8) tokens, labeled with lowercase letters separated by \\\"-\\\". A long prompt \",[\"$\",\"code\",null,{\"children\":\"P\"}],\" could look like \",[\"$\",\"code\",null,{\"children\":\"x-y-z\"}],\", where \",[\"$\",\"code\",null,{\"children\":\"z\"}],\" is an incomplete chunk (e.g. 2 toks). Executing the full prefill for \",[\"$\",\"code\",null,{\"children\":\"P\"}],\" would then take ‚â• 3 engine steps (\",\"\u003e\",\" can happen if it's not scheduled for execution in one of the steps), and only in the last chunked prefill step would we sample one new token.\"]}]\n48:[\"$\",\"p\",null,{\"children\":\"Here is that same example visually:\"}]\n49:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/chunked_pt1.png\",\"alt\":\"Chunked prefilling - pt 1\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n4a:[\"$\",\"p\",null,{\"children\":[\"Implementation is straightforward: cap the number of new tokens per step. If the requested number exceeds \",[\"$\",\"code\",null,{\"children\":\"long_prefill_token_threshold\"}],\", reset it to exactly that value. The underlying indexing logic (described earlier) takes care of the rest.\"]}]\n4b:[\"$\",\"p\",null,{\"children\":[\"In vLLM V1, you enable chunked prefill by setting \",[\"$\",\"code\",null,{\"children\":\"long_prefill_token_threshold\"}],\" to a positive integer. (Technically, it can happen irrespective of this, if the prompt length exceeds the token budget we truncate it and run a chunked prefill.)\"]}]\n4c:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Prefix Caching\"}]\n4d:[\"$\",\"p\",null,{\"children\":\"To explain how prefix caching works, let's take the original code example and tweak it a bit:\"}]\n"])</script><script>self.__next_f.push([1,"4e:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"long_prefix \"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"\u003ca piece of text that is encoded into more than block_size tokens\u003e\\\"\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-13\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts \"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Hello, my name is\\\"\"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-23\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"The president of the United States is\\\"\"]}],[\"$\",\"span\",\"code-segment-24\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-30\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sampling_params \"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"temperature\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.8\"]}],[\"$\",\"span\",\"code-segment-37\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-38\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" top_p\"]}],\"$L116\",\"$L117\",\"$L118\",\"$L119\",\"\\n\",\"$L11a\",\"$L11b\",\"$L11c\",\"$L11d\",\"$L11e\",\"$L11f\",\"$L120\",\"$L121\",\"$L122\",\"$L123\",\"$L124\",\"$L125\",\"$L126\",\"$L127\",\"$L128\",\"$L129\",\"$L12a\",\"\\n\",\"$L12b\",\"$L12c\",\"$L12d\",\"$L12e\",\"$L12f\",\"$L130\",\"$L131\",\"$L132\",\"$L133\",\"$L134\",\"$L135\",\"$L136\",\"$L137\",\"$L138\",\"$L139\",\"$L13a\",\"$L13b\",\"$L13c\",\"$L13d\",\"$L13e\",\"$L13f\",\"$L140\",\"$L141\",\"$L142\",\"$L143\",\"$L144\",\"$L145\",\"$L146\",\"$L147\",\"$L148\",\"$L149\",\"$L14a\",\"\\n\",\"$L14b\",\"$L14c\",\"$L14d\",\"$L14e\",\"$L14f\",\"$L150\",\"$L151\",\"$L152\",\"$L153\",\"$L154\",\"$L155\"]]}]}]\n"])</script><script>self.__next_f.push([1,"4f:[\"$\",\"p\",null,{\"children\":[\"Prefix caching avoids recomputing tokens that multiple prompts share at the beginning - hence \",[\"$\",\"b\",null,{\"children\":\"prefix\"}],\".\"]}]\n50:[\"$\",\"p\",null,{\"children\":[\"The crucial piece is the \",[\"$\",\"code\",null,{\"children\":\"long_prefix\"}],\": it's defined as any prefix longer than a KV-cache block (16 tokens by default). To simplify our example let's say \",[\"$\",\"code\",null,{\"children\":\"long_prefix\"}],\" has exactly length \",[\"$\",\"code\",null,{\"children\":\"n x block_size\"}],\" (where \",[\"$\",\"code\",null,{\"children\":\"n ‚â• 1\"}],\").\"]}]\n51:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"i.e. it perfectly aligns with block boundary - otherwise we'd have to recompute \",[\"$\",\"code\",null,{\"children\":\"long_prefix_len % block_size\"}],\" tokens as we can't cache incomplete blocks.\"]}]]}]\n52:[\"$\",\"p\",null,{\"children\":[\"Without prefix caching, each time we process a new request with the same \",[\"$\",\"code\",null,{\"children\":\"long_prefix\"}],\", we'd recompute all \",[\"$\",\"code\",null,{\"children\":\"n x block_size\"}],\" tokens.\"]}]\n53:[\"$\",\"p\",null,{\"children\":\"With prefix caching, those tokens are computed once (their KVs stored in KV cache paged memory) and then reused, so only the new prompt tokens need processing. This speeds up prefill requests (though it doesn't help with decode).\"}]\n54:[\"$\",\"p\",null,{\"children\":\"How does this work in vLLM?\"}]\n55:[\"$\",\"p\",null,{\"children\":[\"During the first \",[\"$\",\"code\",null,{\"children\":\"generate\"}],\" call, in the scheduling stage, inside \",[\"$\",\"code\",null,{\"children\":\"kv_cache_manager.get_computed_blocks\"}],\", the engine invokes \",[\"$\",\"code\",null,{\"children\":\"hash_request_tokens\"}],\":\"]}]\n"])</script><script>self.__next_f.push([1,"56:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"This function splits the \",[\"$\",\"code\",null,{\"children\":\"long_prefix + prompts[0]\"}],\" into 16-token chunks.\"]}],[\"$\",\"li\",null,{\"children\":\"For each complete chunk, it computes a hash (using either the built-in hash or SHA-256, which is slower but has fewer collisions). The hash combines the previous block's hash, the current tokens, and optional metadata.\"}],[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"optional metadata includes: MM hash, LoRA ID, cache salt (injected into hash of the first block ensures only requests with this cache salt can reuse blocks).\"}]]}],[\"$\",\"li\",null,{\"children\":[\"Each result is stored as a \",[\"$\",\"code\",null,{\"children\":\"BlockHash\"}],\" object containing both the hash and its token IDs. We return a list of block hashes.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"57:[\"$\",\"p\",null,{\"children\":[\"The list is stored in \",[\"$\",\"code\",null,{\"children\":\"self.req_to_block_hashes[request_id]\"}],\".\"]}]\n58:[\"$\",\"p\",null,{\"children\":[\"Next, the engine calls \",[\"$\",\"code\",null,{\"children\":\"find_longest_cache_hit\"}],\" to check if any of these hashes already exist in \",[\"$\",\"code\",null,{\"children\":\"cached_block_hash_to_block\"}],\". On the first request, no hits are found.\"]}]\n59:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/prefix_pt1.png\",\"alt\":\"Prefix caching logic - pt 1\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n5a:[\"$\",\"p\",null,{\"children\":[\"Then we call \",[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}],\" which calls \",[\"$\",\"code\",null,{\"children\":\"coordinator.cache_blocks\"}],\", which associates the new \",[\"$\",\"code\",null,{\"children\":\"BlockHash\"}],\" entries with allocated KV blocks and records them in \",[\"$\",\"code\",null,{\"children\":\"cached_block_hash_to_block\"}],\".\"]}]\n5b:[\"$\",\"p\",null,{\"children\":\"Afterwards, the forward pass will populate KVs in paged KV cache memory corresponding to KV cache blocks that we allocated above.\"}]\n5c:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"After many engine steps it'll allocate more KV cache blocks but it doesn't matter for our example because the prefix has diverged immediately after \",[\"$\",\"code\",null,{\"children\":\"long_prefix\"}],\".\"]}]]}]\n5d:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/prefix_pt2.png\",\"alt\":\"Prefix caching logic - pt 2\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n5e:[\"$\",\"p\",null,{\"children\":[\"On a second \",[\"$\",\"code\",null,{\"children\":\"generate\"}],\" call with the same prefix, steps 1-3 repeat, but now \",[\"$\",\"code\",null,{\"children\":\"find_longest_cache_hit\"}],\" finds matches for all \",[\"$\",\"code\",null,{\"children\":\"n\"}]"])</script><script>self.__next_f.push([1,",\" blocks (via linear search). The engine can reuse those KV blocks directly.\"]}]\n5f:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/prefix_pt3.png\",\"alt\":\"Prefix caching logic - pt 3\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n60:[\"$\",\"p\",null,{\"children\":[\"If the original request were still alive, the reference count for those blocks would increment (e.g. to 2). In this example, the first request has already completed, so the blocks were freed back to the pool and their reference counts set back to 0. Because we were able to retrieve them from \",[\"$\",\"code\",null,{\"children\":\"cached_block_hash_to_block\"}],\" we know they're valid (the logic of the KV cache manager is setup in such a way), so we just remove them from \",[\"$\",\"code\",null,{\"children\":\"free_block_queue\"}],\" again.\"]}]\n"])</script><script>self.__next_f.push([1,"61:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Advanced note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"KV-cache blocks become invalid only when they're about to be reallocated from the \",[\"$\",\"code\",null,{\"children\":\"free_block_queue\"}],\" (which pops from the left) and we discover the block still has an associated hash and is present in \",[\"$\",\"code\",null,{\"children\":\"cached_block_hash_to_block\"}],\". At that moment, we clear the block's hash and remove its entry from \",[\"$\",\"code\",null,{\"children\":\"cached_block_hash_to_block\"}],\", ensuring it can't be reused via prefix caching (at least not for that old prefix).\"]}]]}]\n"])</script><script>self.__next_f.push([1,"62:[\"$\",\"p\",null,{\"children\":\"And that's the gist of prefix caching: don't recompute prefixes you've already seen ‚Äî just reuse their KV cache!\"}]\n63:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"If you understood this example you also understood how paged attention works.\"}]]}]\n64:[\"$\",\"p\",null,{\"children\":[\"Prefix caching is enabled by default. To disable it: \",[\"$\",\"code\",null,{\"children\":\"enable_prefix_caching = False\"}],\".\"]}]\n65:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Guided Decoding (FSM)\"}]\n66:[\"$\",\"p\",null,{\"children\":\"Guided decoding is a technique where, at each decoding step, the logits are constrained by a grammar-based finite state machine. This ensures that only tokens allowed by the grammar can be sampled.\"}]\n67:[\"$\",\"p\",null,{\"children\":\"It's a powerful setup: you can enforce anything from regular grammars (Chomsky type-3, e.g. arbitrary regex patterns) all the way up to context-free grammars (type-2, which cover most programming languages).\"}]\n68:[\"$\",\"p\",null,{\"children\":\"To make this less abstract, let's start with the simplest possible example, building on our earlier code:\"}]\n"])</script><script>self.__next_f.push([1,"69:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\\n\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sampling_params \"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" GuidedDecodingParams\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-14\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts \"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"This sucks\\\"\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-23\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-24\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"The weather is beautiful\\\"\"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-31\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"guided_decoding_params \"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" GuidedDecodingParams\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"choice\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-37\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-38\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Positive\\\"\"]}],\"$L156\",\"$L157\",\"$L158\",\"$L159\",\"$L15a\",\"$L15b\",\"$L15c\",\"$L15d\",\"$L15e\",\"$L15f\",\"$L160\",\"$L161\",\"$L162\",\"$L163\",\"$L164\",\"\\n\",\"$L165\",\"$L166\",\"$L167\",\"$L168\",\"$L169\",\"$L16a\",\"$L16b\",\"$L16c\",\"$L16d\",\"$L16e\",\"$L16f\",\"$L170\",\"$L171\",\"$L172\",\"$L173\",\"$L174\",\"$L175\",\"\\n\",\"$L176\",\"$L177\",\"$L178\",\"$L179\",\"$L17a\",\"$L17b\",\"$L17c\",\"$L17d\",\"$L17e\",\"$L17f\",\"$L180\",\"\\n\",\"$L181\",\"$L182\",\"$L183\",\"$L184\",\"$L185\",\"$L186\",\"$L187\",\"$L188\",\"$L189\",\"$L18a\",\"$L18b\"]]}]}]\n"])</script><script>self.__next_f.push([1,"6a:[\"$\",\"p\",null,{\"children\":\"In the toy example I gave (assume character-level tokenization): at prefill, the FSM masks logits so only \\\"P\\\" or \\\"N\\\" are viable. If \\\"P\\\" is sampled, the FSM moves to the \\\"Positive\\\" branch; next step only \\\"o\\\" is allowed, and so on.\"}]\n6b:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/fsm.png\",\"alt\":\"FSM\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"Toy example FSM\"}]]}]\n6c:[\"$\",\"p\",null,{\"children\":\"How this works in vLLM:\"}]\n"])</script><script>self.__next_f.push([1,"6d:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"At LLM engine construction, a \",[\"$\",\"code\",null,{\"children\":\"StructuredOutputManager\"}],\" is created; it has access to the tokenizer and maintains a \",[\"$\",\"code\",null,{\"children\":\"_grammar_bitmask\"}],\" tensor.\"]}],[\"$\",\"li\",null,{\"children\":[\"When adding a request, its status is set to \",[\"$\",\"code\",null,{\"children\":\"WAITING_FOR_FSM\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"grammar_init\"}],\" selects the backend compiler (e.g., \",[\"$\",\"code\",null,{\"children\":\"xgrammar\"}],\" \",[\"$\",\"a\",null,{\"href\":\"#ref-7\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[7]\"}],\"; note that backends are 3rd party code).\"]}],[\"$\",\"li\",null,{\"children\":\"The grammar for this request is compiled asynchronously.\"}],[\"$\",\"li\",null,{\"children\":[\"During scheduling, if the async compile has completed, the status switches to \",[\"$\",\"code\",null,{\"children\":\"WAITING\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"request_id\"}],\" is added to \",[\"$\",\"code\",null,{\"children\":\"structured_output_request_ids\"}],\"; otherwise it's placed in \",[\"$\",\"code\",null,{\"children\":\"skipped_waiting_requests\"}],\" to retry on next engine step.\"]}],[\"$\",\"li\",null,{\"children\":[\"After the scheduling loop (still inside scheduling), if there are FSM requests, the \",[\"$\",\"code\",null,{\"children\":\"StructuredOutputManager\"}],\" asks the backend to prepare/update \",[\"$\",\"code\",null,{\"children\":\"_grammar_bitmask\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":\"After the forward pass produces logits, xgr_torch_compile's function expands the bitmask to vocab size (32x expansion ratio because we use 32 bit integers) and masks disallowed logits to ‚Äì‚àû.\"}],[\"$\",\"li\",null,{\"children\":[\"After sampling the next token, the request's FSM is advanced via \",[\"$\",\"code\",null,{\"children\":\"accept_tokens\"}],\". Visually we move to the next state on the FSM diagram.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"6e:[\"$\",\"p\",null,{\"children\":\"Step 6 deserves further clarification.\"}]\n6f:[\"$\",\"p\",null,{\"children\":[\"If \",[\"$\",\"code\",null,{\"children\":\"vocab_size = 32\"}],\", \",[\"$\",\"code\",null,{\"children\":\"_grammar_bitmask\"}],\" is a single integer; its binary representation encodes which tokens are allowed (\\\"1\\\") vs disallowed (\\\"0\\\"). For example, \\\"101‚Ä¶001\\\" expands to a length-32 array \",[\"$\",\"code\",null,{\"children\":\"[1, 0, 1, ‚Ä¶, 0, 0, 1]\"}],\"; positions with 0 get logits set to ‚Äì‚àû. For larger vocabularies, multiple 32-bit words are used and expanded/concatenated accordingly. The backend (e.g., \",[\"$\",\"code\",null,{\"children\":\"xgrammar\"}],\") is responsible for producing these bit patterns using the current FSM state.\"]}]\n70:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"Most of the complexity here is hidden in the 3rd party libs like xgrammar.\"}]]}]\n71:[\"$\",\"p\",null,{\"children\":\"Here is an even simpler example with vocab_size = 8 and 8-bit integers (for those of you who like my visuals):\"}]\n72:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/fsm2.png\",\"alt\":\"FSM\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"Toy example\"}]]}]\n73:[\"$\",\"p\",null,{\"children\":[\"You can enable this in vLLM by passing in a desired \",[\"$\",\"code\",null,{\"children\":\"guided_decoding\"}],\" config.\"]}]\n74:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Speculative Decoding\"}]\n75:[\"$\",\"p\",null,{\"children\":[\"In autoregressive generation, each new token requires a forward pass of the large LM. This is expensive ‚Äî every step reloads and applies all model wei"])</script><script>self.__next_f.push([1,"ghts just to compute a single token! (assuming batch size == 1, in general it's \",[\"$\",\"code\",null,{\"children\":\"B\"}],\")\"]}]\n76:[\"$\",\"p\",null,{\"children\":[\"Speculative decoding \",[\"$\",\"a\",null,{\"href\":\"#ref-8\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[8]\"}],\" speeds this up by introducing a smaller draft LM. The draft proposes \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" tokens cheaply. But we don't ultimately want to sample from the smaller model ‚Äî it's only there to guess candidate continuations. The large model still decides what's valid.\"]}]\n77:[\"$\",\"p\",null,{\"children\":\"Here are the steps:\"}]\n"])</script><script>self.__next_f.push([1,"78:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Draft:\"}],\" run the small model on the current context and propose \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" tokens\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Verify:\"}],\" run the large model once on context + \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" draft tokens. This produces probabilities for those \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" positions plus one extra (so we get \",[\"$\",\"code\",null,{\"children\":\"k+1\"}],\" candidates)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Accept/reject:\"}],\" going from left to right over the \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" draft tokens:\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"If the large model's probability for the draft token ‚â• the draft's probability, accept it\"}],[\"$\",\"li\",null,{\"children\":[\"Otherwise, accept it with probability \",[\"$\",\"code\",null,{\"children\":\"p_large(token)/p_draft(token)\"}]]}],[\"$\",\"li\",null,{\"children\":[\"Stop at the first rejection, or accept all \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" draft tokens.\"]}],[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"If all \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" draft tokens are accepted, also sample the extra \",[\"$\",\"code\",null,{\"children\":\"(k+1)\"}],\"-th token \\\"for free\\\" from the large model (we already computed that distribution).\"]}],[\"$\",\"li\",null,{\"children\":[\"If there was a rejection create a new rebalanced distribution at that position (\",[\"$\",\"code\",null,{\"children\":\"p_large - p_draft\"}],\", clamp min at 0, normalize to sum to 1) and sample the last token from it.\"]}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"79:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Why this works:\"}],\" Although we use the small model to propose candidates, the accept/reject rule guarantees that in expectation the sequence is distributed exactly as if we had sampled token by token from the large model. This means speculative decoding is statistically equivalent to standard autoregressive decoding ‚Äî but potentially much faster, since a single large-model pass can yield up to \",[\"$\",\"code\",null,{\"children\":\"k+1\"}],\" tokens.\"]}]\n"])</script><script>self.__next_f.push([1,"7a:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"I recommend looking at \",[\"$\",\"a\",null,{\"href\":\"https://github.com/meta-pytorch/gpt-fast\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"gpt-fast\"}],\" for a simple implementation, and the \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2302.01318\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"original paper\"}],\" for the math details and the proof of equivalence to sampling from the full model.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"7b:[\"$\",\"p\",null,{\"children\":[\"vLLM V1 does not support the LLM draft model method, instead it implements faster‚Äîbut less accurate‚Äîproposal schemes: n-gram, EAGLE \",[\"$\",\"a\",null,{\"href\":\"#ref-9\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[9]\"}],\", and Medusa \",[\"$\",\"a\",null,{\"href\":\"#ref-10\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[10]\"}],\".\"]}]\n7c:[\"$\",\"p\",null,{\"children\":\"One-liners on each:\"}]\n"])</script><script>self.__next_f.push([1,"7d:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"n-gram:\"}],\" take the last \",[\"$\",\"code\",null,{\"children\":\"prompt_lookup_max\"}],\" tokens; find a prior match in the sequence; if found, propose the \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" tokens that followed that match; otherwise decrement the window and retry down to \",[\"$\",\"code\",null,{\"children\":\"prompt_lookup_min\"}]]}],[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"The current implementation returns \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" tokens after the \",[\"$\",\"b\",null,{\"children\":\"first\"}],\" match. It feels more natural to introduce a recency bias and reverse the search direction? (i.e. last match)\"]}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Eagle:\"}],\" perform \\\"model surgery\\\" on the large LM‚Äîkeep embeddings and LM head, replace the transformer stack with a lightweight MLP; fine-tune that as a cheap draft\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Medusa:\"}],\" train auxiliary linear heads on top (embeddings before LM head) of the large model to predict the next \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" tokens in parallel; use these heads to propose tokens more efficiently than running a separate small LM\"]}]]}]\n"])</script><script>self.__next_f.push([1,"7e:[\"$\",\"code\",null,{\"children\":\"ngram\"}]\n"])</script><script>self.__next_f.push([1,"7f:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts \"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Hello, my name is\\\"\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"The president of the United States is\\\"\"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-24\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sampling_params \"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"temperature\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-30\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.8\"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" top_p\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.95\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-38\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"speculative_config\"]}],[\"$\",\"span\",\"code-segment-39\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],\"$L18c\",\"$L18d\",\"$L18e\",\"$L18f\",\"$L190\",\"$L191\",\"$L192\",\"$L193\",\"$L194\",\"$L195\",\"$L196\",\"$L197\",\"$L198\",\"$L199\",\"$L19a\",\"$L19b\",\"$L19c\",\"$L19d\",\"$L19e\",\"$L19f\",\"$L1a0\",\"$L1a1\",\"$L1a2\",\"$L1a3\",\"$L1a4\",\"$L1a5\",\"$L1a6\",\"$L1a7\",\"$L1a8\",\"$L1a9\",\"$L1aa\",\"$L1ab\",\"$L1ac\",\"\\n\",\"$L1ad\",\"$L1ae\",\"$L1af\",\"$L1b0\",\"$L1b1\",\"$L1b2\",\"$L1b3\",\"$L1b4\",\"$L1b5\",\"$L1b6\",\"$L1b7\",\"$L1b8\",\"$L1b9\",\"$L1ba\",\"$L1bb\",\"$L1bc\",\"$L1bd\",\"$L1be\",\"$L1bf\",\"$L1c0\",\"$L1c1\",\"\\n\",\"$L1c2\",\"$L1c3\",\"$L1c4\",\"$L1c5\",\"$L1c6\",\"$L1c7\",\"$L1c8\",\"$L1c9\",\"$L1ca\",\"$L1cb\",\"$L1cc\",\"\\n\",\"$L1cd\",\"$L1ce\",\"$L1cf\",\"$L1d0\",\"$L1d1\",\"$L1d2\",\"$L1d3\",\"$L1d4\",\"$L1d5\",\"$L1d6\",\"$L1d7\"]]}]}]\n"])</script><script>self.__next_f.push([1,"80:[\"$\",\"p\",null,{\"children\":\"How does this work in vLLM?\"}]\n81:[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Setup (during engine construction):\"}]}]\n82:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Init device: create a \",[\"$\",\"code\",null,{\"children\":\"drafter\"}],\" (draft model, e.g., \",[\"$\",\"code\",null,{\"children\":\"NgramProposer\"}],\") and a \",[\"$\",\"code\",null,{\"children\":\"rejection_sampler\"}],\" (parts of it are written in Triton).\"]}],[\"$\",\"li\",null,{\"children\":\"Load model: load draft model weights (no-op for n-gram).\"}]]}]\n83:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":[\"After that in the \",[\"$\",\"code\",null,{\"children\":\"generate\"}],\" function\"]}],\" (assume we get a brand new request):\"]}]\n"])</script><script>self.__next_f.push([1,"84:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Run the regular prefill step with the large model.\"}],[\"$\",\"li\",null,{\"children\":[\"After the forward pass and standard sampling, call \",[\"$\",\"code\",null,{\"children\":\"propose_draft_token_ids(k)\"}],\" to sample \",[\"$\",\"code\",null,{\"children\":\"k\"}],\" draft tokens from the draft model.\"]}],[\"$\",\"li\",null,{\"children\":[\"Store these in \",[\"$\",\"code\",null,{\"children\":\"request.spec_token_ids\"}],\" (update the request metadata).\"]}],[\"$\",\"li\",null,{\"children\":[\"On the next engine step, when the request is in the running queue, add \",[\"$\",\"code\",null,{\"children\":\"len(request.spec_token_ids)\"}],\" to the \\\"new tokens\\\" count so \",[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}],\" reserves sufficient KV blocks for the fwd pass.\"]}],[\"$\",\"li\",null,{\"children\":[\"Copy \",[\"$\",\"code\",null,{\"children\":\"spec_token_ids\"}],\" into \",[\"$\",\"code\",null,{\"children\":\"input_batch.token_ids_cpu\"}],\" to form (context + draft) tokens.\"]}],[\"$\",\"li\",null,{\"children\":[\"Compute metadata via \",[\"$\",\"code\",null,{\"children\":\"_calc_spec_decode_metadata\"}],\" (this copies over tokens from \",[\"$\",\"code\",null,{\"children\":\"input_batch.token_ids_cpu\"}],\", prepares logits, etc.), then run a large-model forward pass over the draft tokens.\"]}],[\"$\",\"li\",null,{\"children\":[\"Instead of regular sampling from logits, use the \",[\"$\",\"code\",null,{\"children\":\"rejection_sampler\"}],\" to accept/reject left-to-right and produce \",[\"$\",\"code\",null,{\"children\":\"output_token_ids\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":\"Repeat steps 2-7 until a stop condition is met.\"}]]}]\n"])</script><script>self.__next_f.push([1,"85:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/specdec_pt1.png\",\"alt\":\"Drafting stage\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n86:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/specdec_pt2.png\",\"alt\":\"Verify stage \u0026 rejection sampling stage\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],\"\"]}]\n87:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Disaggregated P/D\"}]\n88:[\"$\",\"p\",null,{\"children\":\"I've already previously hinted at the motivation behind disaggregated P/D (prefill/decode).\"}]\n89:[\"$\",\"p\",null,{\"children\":[\"Prefill and decode have very different performance profiles (compute-bound vs. memory-bandwidth-bound), so separating their execution is a sensible design. It gives tighter control over latency ‚Äî both \",[\"$\",\"code\",null,{\"children\":\"TFTT\"}],\" (time-to-first-token) and \",[\"$\",\"code\",null,{\"children\":\"ITL\"}],\" (inter-token latency) ‚Äî more on this in the \",[\"$\",\"a\",null,{\"href\":\"#cpt5\",\"rel\":\"noopener noreferrer\",\"className\":\"text-yellow-600 hover:text-yellow-800 \",\"children\":\"benchmarking\"}],\" section.\"]}]\n8a:[\"$\",\"p\",null,{\"children\":[\"In practice, we run \",[\"$\",\"code\",null,{\"children\":\"N\"}],\" vLLM prefill instances and \",[\"$\",\"code\",null,{\"children\":\"M\"}],\" vLLM decode instances, autoscaling them based on the live request mix. Prefill workers write KV to a dedicated KV-cache service; decode workers read from it. This isolates long, bursty prefill from steady, latency-sensitive decode.\"]}]\n8b:[\"$\",\"p\",null,{\"children\":\"How does this work in vLLM?\"}]\n8c:[\"$\",\"p\",null,{\"children\":[\"For clarity, the example below relies on \",[\"$\",\"code\",null,{\"children\":\"SharedStorageConnector\"}],\", a debugging connector implementation used to illustrate the mechanics.\"]}]\n8d:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"classNa"])</script><script>self.__next_f.push([1,"me\":\"text-sm leading-relaxed\",\"children\":\"Connector is vLLM's abstraction for handling the exchange of KVs between instances. Connector interface is not yet stable, there are some near-term improvements planned which will involve changes, some potentially breaking.\"}]]}]\n8e:[\"$\",\"p\",null,{\"children\":\"We launch 2 vLLM instances (GPU 0 for prefill and GPU 1 for decode), and then transfer the KV cache between them:\"}]\n"])</script><script>self.__next_f.push([1,"8f:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" os\\n\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" time\\n\"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" multiprocessing \"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" Event\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" Process\\n\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" multiprocessing \"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"as\"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" mp\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-20\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm \"]}],[\"$\",\"span\",\"code-segment-23\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-24\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\\n\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"from\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" vllm\"]}],[\"$\",\"span\",\"code-segment-30\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"config \"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"import\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" KVTransferConfig\\n\"]}],\"\\n\",[\"$\",\"span\",\"code-segment-35\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts \"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}],[\"$\",\"span\",\"code-segment-37\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}],[\"$\",\"span\",\"code-segment-38\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}],[\"$\",\"span\",\"code-segment-39\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-40\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}],\"$L1d8\",\"$L1d9\",\"$L1da\",\"$L1db\",\"$L1dc\",\"$L1dd\",\"$L1de\",\"$L1df\",\"$L1e0\",\"$L1e1\",\"\\n\",\"$L1e2\",\"$L1e3\",\"$L1e4\",\"$L1e5\",\"$L1e6\",\"$L1e7\",\"$L1e8\",\"$L1e9\",\"$L1ea\",\"$L1eb\",\"$L1ec\",\"$L1ed\",\"$L1ee\",\"$L1ef\",\"$L1f0\",\"$L1f1\",\"$L1f2\",\"$L1f3\",\"$L1f4\",\"$L1f5\",\"\\n\",\"$L1f6\",\"$L1f7\",\"$L1f8\",\"$L1f9\",\"$L1fa\",\"$L1fb\",\"$L1fc\",\"$L1fd\",\"$L1fe\",\"$L1ff\",\"$L200\",\"$L201\",\"$L202\",\"$L203\",\"$L204\",\"$L205\",\"$L206\",\"\\n\",\"$L207\",\"$L208\",\"$L209\",\"$L20a\",\"$L20b\",\"$L20c\",\"$L20d\",\"$L20e\",\"$L20f\",\"$L210\",\"$L211\",\"$L212\",\"$L213\",\"$L214\",\"$L215\",\"$L216\",\"$L217\",\"$L218\",\"$L219\",\"$L21a\",\"$L21b\",\"$L21c\",\"$L21d\",\"$L21e\",\"$L21f\",\"$L220\",\"$L221\",\"$L222\",\"\\n\",\"$L223\",\"$L224\",\"$L225\",\"$L226\",\"$L227\",\"$L228\",\"$L229\",\"$L22a\",\"$L22b\",\"$L22c\",\"$L22d\",\"$L22e\",\"$L22f\",\"$L230\",\"$L231\",\"$L232\",\"$L233\",\"$L234\",\"$L235\",\"$L236\",\"$L237\",\"$L238\",\"\\n\",\"$L239\",\"$L23a\",\"$L23b\",\"$L23c\",\"$L23d\",\"$L23e\",\"$L23f\",\"$L240\",\"\\n\",\"$L241\",\"$L242\",\"$L243\",\"$L244\",\"$L245\",\"$L246\",\"$L247\",\"$L248\",\"$L249\",\"$L24a\",\"$L24b\",\"$L24c\",\"$L24d\",\"$L24e\",\"$L24f\",\"$L250\",\"$L251\",\"$L252\",\"$L253\",\"$L254\",\"$L255\",\"$L256\",\"$L257\",\"$L258\",\"$L259\",\"$L25a\",\"$L25b\",\"$L25c\",\"$L25d\",\"$L25e\",\"$L25f\",\"$L260\",\"$L261\",\"$L262\",\"\\n\",\"$L263\",\"$L264\",\"$L265\",\"$L266\",\"$L267\",\"$L268\",\"$L269\",\"$L26a\",\"$L26b\",\"$L26c\",\"$L26d\",\"$L26e\",\"$L26f\",\"$L270\",\"$L271\",\"$L272\",\"$L273\",\"$L274\",\"$L275\",\"$L276\",\"\\n\",\"$L277\",\"$L278\",\"$L279\",\"$L27a\",\"$L27b\",\"$L27c\",\"$L27d\",\"$L27e\",\"$L27f\",\"$L280\",\"$L281\",\"$L282\",\"$L283\",\"\\n\",\"$L284\",\"$L285\",\"$L286\",\"$L287\",\"$L288\",\"$L289\",\"$L28a\",\"$L28b\",\"$L28c\",\"$L28d\",\"$L28e\",\"$L28f\",\"$L290\",\"$L291\",\"$L292\",\"$L293\",\"$L294\",\"$L295\",\"$L296\",\"$L297\",\"$L298\",\"$L299\",\"$L29a\",\"$L29b\",\"$L29c\",\"$L29d\",\"$L29e\",\"$L29f\",\"\\n\",\"$L2a0\",\"$L2a1\",\"$L2a2\",\"$L2a3\",\"$L2a4\",\"$L2a5\",\"$L2a6\",\"$L2a7\",\"$L2a8\",\"$L2a9\",\"$L2aa\",\"$L2ab\",\"$L2ac\",\"\\n\",\"$L2ad\",\"$L2ae\",\"$L2af\",\"$L2b0\",\"$L2b1\",\"$L2b2\",\"$L2b3\",\"$L2b4\",\"\\n\",\"$L2b5\",\"$L2b6\",\"$L2b7\",\"$L2b8\",\"$L2b9\",\"$L2ba\",\"$L2bb\",\"$L2bc\",\"$L2bd\",\"$L2be\",\"$L2bf\",\"$L2c0\",\"$L2c1\",\"$L2c2\",\"\\n\",\"$L2c3\",\"$L2c4\",\"$L2c5\",\"$L2c6\",\"$L2c7\",\"$L2c8\",\"$L2c9\",\"$L2ca\",\"$L2cb\",\"$L2cc\",\"$L2cd\",\"$L2ce\",\"$L2cf\",\"$L2d0\",\"$L2d1\",\"$L2d2\",\"$L2d3\",\"$L2d4\",\"$L2d5\",\"$L2d6\",\"$L2d7\",\"$L2d8\",\"$L2d9\",\"$L2da\",\"$L2db\",\"$L2dc\",\"$L2dd\",\"$L2de\",\"$L2df\",\"$L2e0\",\"$L2e1\",\"$L2e2\",\"$L2e3\",\"$L2e4\",\"$L2e5\",\"$L2e6\",\"$L2e7\",\"$L2e8\",\"$L2e9\",\"$L2ea\",\"$L2eb\",\"$L2ec\",\"$L2ed\",\"$L2ee\",\"$L2ef\",\"$L2f0\",\"\\n\",\"$L2f1\",\"$L2f2\",\"$L2f3\",\"$L2f4\",\"$L2f5\",\"$L2f6\",\"$L2f7\",\"$L2f8\",\"$L2f9\",\"$L2fa\",\"$L2fb\",\"$L2fc\",\"\\n\",\"$L2fd\",\"$L2fe\",\"$L2ff\",\"$L300\",\"$L301\",\"$L302\",\"$L303\",\"$L304\",\"$L305\",\"$L306\",\"$L307\",\"$L308\",\"\"]]}]}]\n"])</script><script>self.__next_f.push([1,"90:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"I've also experimented with \",[\"$\",\"code\",null,{\"children\":\"LMCache\"}],\" \",[\"$\",\"a\",null,{\"href\":\"#ref-11\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 \",\"children\":\"[11]\"}],\", the fastest production-ready connector (uses NVIDIA's NIXL as the backend), but it's still at the bleeding edge and I ran into some bugs. Since much of its complexity lives in an external repo, \",[\"$\",\"code\",null,{\"children\":\"SharedStorageConnector\"}],\" is a better choice for explanation.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"91:[\"$\",\"p\",null,{\"children\":\"These are the steps in vLLM:\"}]\n"])</script><script>self.__next_f.push([1,"92:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Instantiation\"}],\" ‚Äî During engine construction, connectors are created in two places:\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Inside the worker's init device procedure (under init worker distributed environment function), with role \\\"worker\\\".\"}],[\"$\",\"li\",null,{\"children\":\"Inside the scheduler constructor, with role \\\"scheduler\\\".\"}]]}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Cache lookup\"}],\" ‚Äî When the scheduler processes prefill requests from the \",[\"$\",\"code\",null,{\"children\":\"waiting\"}],\" queue (after local prefix-cache checks), it calls connector's \",[\"$\",\"code\",null,{\"children\":\"get_num_new_matched_tokens\"}],\". This checks for externally cached tokens in the KV-cache server. Prefill always sees 0 here; decode may have a cache hit. The result is added to the local count before calling \",[\"$\",\"code\",null,{\"children\":\"allocate_slots\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"State update\"}],\" ‚Äî The scheduler then calls \",[\"$\",\"code\",null,{\"children\":\"connector.update_state_after_alloc\"}],\", which records requests that had a cache (no-op for prefill).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Meta build\"}],\" ‚Äî At the end of scheduling, the scheduler calls \",[\"$\",\"code\",null,{\"children\":\"meta = connector.build_connector_meta\"}],\":\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Prefill adds all requests with \",[\"$\",\"code\",null,{\"children\":\"is_store=True\"}],\" (to upload KV).\"]}],[\"$\",\"li\",null,{\"children\":[\"Decode adds requests with \",[\"$\",\"code\",null,{\"children\":\"is_store=False\"}],\" (to fetch KV).\"]}]]}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Context manager\"}],\" ‚Äî Before the forward pass, the engine enters a KV-connector context manager:\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"On enter: \",[\"$\",\"code\",null,{\"children\":\"kv_connector.start_load_kv\"}],\" is called. For decode, this loads KV from the external server and injects it into paged memory. For prefill, it's a no-op.\"]}],[\"$\",\"li\",null,{\"children\":[\"On exit: \",[\"$\",\"code\",null,{\"children\":\"kv_connector.wait_for_save\"}],\" is called. For prefill, this blocks until KV is uploaded to the external server. For decode, it's a no-op.\"]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"93:[\"$\",\"p\",null,{\"children\":\"Here is a visual example:\"}]\n94:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/pd.png\",\"alt\":\"disaggregated P/D\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"disaggregated P/D\"}]]}]\n"])</script><script>self.__next_f.push([1,"95:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Additional notes:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"For \",[\"$\",\"code\",null,{\"children\":\"SharedStorageConnector\"}],\" \\\"external server\\\" is just a local file system.\"]}],[\"$\",\"li\",null,{\"children\":\"Depending on configuration, KV transfers can also be done layer-by-layer (before/after each attention layer).\"}],[\"$\",\"li\",null,{\"children\":\"Decode loads external KV only once, on the first step of its requests; afterwards it computes/stores locally.\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"96:[\"$\",\"h2\",null,{\"id\":\"cpt3\",\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"From UniprocExecutor to MultiProcExecutor\"}]\n97:[\"$\",\"p\",null,{\"children\":\"With the core techniques in place, we can now talk about scaling up.\"}]\n98:[\"$\",\"p\",null,{\"children\":\"Suppose your model weights no longer fit into a single GPU's VRAM.\"}]\n99:[\"$\",\"p\",null,{\"children\":[\"The first option is to shard the model across multiple GPUs on the same node using tensor parallelism (e.g., \",[\"$\",\"code\",null,{\"children\":\"TP=8\"}],\"). If the model still doesn't fit, the next step is pipeline parallelism across nodes.\"]}]\n"])</script><script>self.__next_f.push([1,"9a:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Notes:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Intranode bandwidth is significantly higher than internode, which is why tensor parallelism (TP) is generally preferred over pipeline parallelism (PP). (It is also true that PP communicates less data than TP.)\"}],[\"$\",\"li\",null,{\"children\":\"I'm not covering expert parallelism (EP) since we're focusing on standard transformers rather than MoE, nor sequence parallelism, as TP and PP are the most commonly used in practice.\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"9b:[\"$\",\"p\",null,{\"children\":[\"At this stage, we need multiple GPU processes (workers) and an orchestration layer to coordinate them. That's exactly what \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" provides.\"]}]\n9c:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/multiprocexecutor.png\",\"alt\":\"MultiProcExecutor\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"MultiProcExecutor in a TP=8 setting (driver worker being rank 0)\"}]]}]\n9d:[\"$\",\"p\",null,{\"children\":\"How this works in vLLM:\"}]\n"])</script><script>self.__next_f.push([1,"9e:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" initializes an \",[\"$\",\"code\",null,{\"children\":\"rpc_broadcast_mq\"}],\" message queue (implemented with shared memory under the hood).\"]}],[\"$\",\"li\",null,{\"children\":[\"The constructor loops over \",[\"$\",\"code\",null,{\"children\":\"world_size\"}],\" (e.g. \",[\"$\",\"code\",null,{\"children\":\"TP=8 ‚áí world_size=8\"}],\") and spawns a daemon process for each rank via \",[\"$\",\"code\",null,{\"children\":\"WorkerProc.make_worker_process\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":\"For each worker, the parent first creates a reader and writer pipe.\"}],[\"$\",\"li\",null,{\"children\":[\"The new process runs \",[\"$\",\"code\",null,{\"children\":\"WorkerProc.worker_main\"}],\", which instantiates a worker (going through the same \\\"init device\\\", \\\"load model\\\", etc. as in \",[\"$\",\"code\",null,{\"children\":\"UniprocExecutor\"}],\").\"]}],[\"$\",\"li\",null,{\"children\":[\"Each worker determines whether it is the driver (rank 0 in the TP group) or a regular worker. Every worker sets up two queues:\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"rpc_broadcast_mq\"}],\" (shared with the parent) for receiving work.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"worker_response_mq\"}],\" for sending responses back.\"]}]]}]]}],[\"$\",\"li\",null,{\"children\":[\"During initialization, each child sends its \",[\"$\",\"code\",null,{\"children\":\"worker_response_mq\"}],\" handle to the parent via the pipe. Once all are received, the parent unblocks ‚Äî this completes coordination.\"]}],[\"$\",\"li\",null,{\"children\":[\"Workers then enter a busy loop, blocking on \",[\"$\",\"code\",null,{\"children\":\"rpc_broadcast_mq.dequeue\"}],\". When a work item arrives, they execute it (just like in \",[\"$\",\"code\",null,{\"children\":\"UniprocExecutor\"}],\", but now with TP/PP-specific partitioned work). Results are sent back through \",[\"$\",\"code\",null,{\"children\":\"worker_response_mq.enqueue\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"At runtime, when a request arrives, \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" enqueues it into \",[\"$\",\"code\",null,{\"children\":\"rpc_broadcast_mq\"}],\" (non-blocking) for all children workers. It then waits on the designated output rank's \",[\"$\",\"code\",null,{\"children\":\"worker_response_mq.dequeue\"}],\" to collect the final result.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"9f:[\"$\",\"p\",null,{\"children\":[\"From the engine's perspective, nothing has changed ‚Äî all of this multiprocessing complexity is abstracted away through a call to model executor's \",[\"$\",\"code\",null,{\"children\":\"execute_model\"}],\".\"]}]\na0:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"In the \",[\"$\",\"code\",null,{\"children\":\"UniProcExecutor\"}],\" case: execute_model directly leads to calling execute_model on the worker\"]}],[\"$\",\"li\",null,{\"children\":[\"In the \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" case: execute_model indirectly leads to calling execute_model on each worker through \",[\"$\",\"code\",null,{\"children\":\"rpc_broadcast_mq\"}]]}]]}]\na1:[\"$\",\"p\",null,{\"children\":\"At this point, we can run models that are as large as resources allow using the same engine interface.\"}]\na2:[\"$\",\"p\",null,{\"children\":[\"The next step is to scale out: enable data parallelism (\",[\"$\",\"code\",null,{\"children\":[\"DP \",\"\u003e\",\" 1\"]}],\") replicating the model across nodes, add a lightweight DP coordination layer, introduce load balancing across replicas, and place one or more API servers in front to handle incoming traffic.\"]}]\na3:[\"$\",\"h2\",null,{\"id\":\"cpt4\",\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Distributed system serving vLLM\"}]\na4:[\"$\",\"p\",null,{\"children\":\"There are many ways to set up serving infrastructure, but to stay concrete, here's one example: suppose we have two H100 nodes and want to run four vLLM engines across them.\"}]\na5:[\"$\",\"p\",null,{\"children\":[\"If the model requires \",[\"$\",\"code\",null,{\"children\":\"TP=4\"}],\", we can configure the nodes like this.\"]}]\na6:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/server_setup.png\",\"alt\":\"server configuration with 2 8xH100 nodes\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"server configuration with 2 8xH100 nodes (1 headless, 1 api server)\"}]]}]\na7:[\"$\",\"p\",null,{\"children\":\"On the first node, run the engin"])</script><script>self.__next_f.push([1,"e in headless mode (no API server) with the following arguments:\"}]\n"])</script><script>self.__next_f.push([1,"a8:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"vllm serve \"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003c\"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"name\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003e\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"tensor\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size \"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"4\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-23\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-24\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size \"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"4\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-30\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"local \"]}],[\"$\",\"span\",\"code-segment-37\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"2\"]}],[\"$\",\"span\",\"code-segment-38\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"$L309\",\"$L30a\",\"$L30b\",\"$L30c\",\"$L30d\",\"$L30e\",\"$L30f\",\"$L310\",\"$L311\",\"$L312\",\"$L313\",\"$L314\",\"$L315\",\"$L316\",\"$L317\",\"$L318\",\"$L319\",\"$L31a\",\"$L31b\",\"$L31c\",\"$L31d\",\"$L31e\",\"$L31f\",\"$L320\",\"$L321\",\"$L322\",\"$L323\",\"$L324\",\"$L325\",\"$L326\",\"$L327\",\"$L328\",\"$L329\",\"$L32a\",\"$L32b\",\"$L32c\",\"$L32d\",\"$L32e\",\"$L32f\",\"$L330\",\"$L331\",\"$L332\",\"\"]]}]}]\n"])</script><script>self.__next_f.push([1,"a9:[\"$\",\"p\",null,{\"children\":\"and run that same command on the other node with few tweaks:\"}]\naa:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"no \",[\"$\",\"code\",null,{\"children\":\"--headless\"}]]}],[\"$\",\"li\",null,{\"children\":\"modify DP start rank\"}]]}]\n"])</script><script>self.__next_f.push([1,"ab:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-python\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"vllm serve \"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003c\"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"name\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003e\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"tensor\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size \"]}],[\"$\",\"span\",\"code-segment-15\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"4\"]}],[\"$\",\"span\",\"code-segment-16\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-17\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-18\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-19\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-20\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}],[\"$\",\"span\",\"code-segment-21\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-22\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-23\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-24\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size \"]}],[\"$\",\"span\",\"code-segment-25\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"4\"]}],[\"$\",\"span\",\"code-segment-26\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-27\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}],[\"$\",\"span\",\"code-segment-28\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-29\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-30\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}],[\"$\",\"span\",\"code-segment-31\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-32\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}],[\"$\",\"span\",\"code-segment-33\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-34\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"size\"]}],[\"$\",\"span\",\"code-segment-35\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}],[\"$\",\"span\",\"code-segment-36\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"local \"]}],[\"$\",\"span\",\"code-segment-37\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"2\"]}],[\"$\",\"span\",\"code-segment-38\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"$L333\",\"$L334\",\"$L335\",\"$L336\",\"$L337\",\"$L338\",\"$L339\",\"$L33a\",\"$L33b\",\"$L33c\",\"$L33d\",\"$L33e\",\"$L33f\",\"$L340\",\"$L341\",\"$L342\",\"$L343\",\"$L344\",\"$L345\",\"$L346\",\"$L347\",\"$L348\",\"$L349\",\"$L34a\",\"$L34b\",\"$L34c\",\"$L34d\",\"$L34e\",\"$L34f\",\"$L350\",\"$L351\",\"$L352\",\"$L353\",\"$L354\",\"$L355\",\"$L356\",\"$L357\",\"$L358\",\"\"]]}]}]\n"])</script><script>self.__next_f.push([1,"ac:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"This assumes networking is configured so all nodes can reach the specified IP and port.\"}]]}]\nad:[\"$\",\"p\",null,{\"children\":\"How does this work in VLLM?\"}]\nae:[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"On the headless server node\"}]\naf:[\"$\",\"p\",null,{\"children\":[\"On the headless node, a \",[\"$\",\"code\",null,{\"children\":\"CoreEngineProcManager\"}],\" launches 2 processes (per \",[\"$\",\"code\",null,{\"children\":\"--data-parallel-size-local\"}],\") each running \",[\"$\",\"code\",null,{\"children\":\"EngineCoreProc.run_engine_core\"}],\". Each of these functions creates a \",[\"$\",\"code\",null,{\"children\":\"DPEngineCoreProc\"}],\" (the engine core) and then enters its busy loop.\"]}]\nb0:[\"$\",\"p\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"DPEngineCoreProc\"}],\" initializes its parent \",[\"$\",\"code\",null,{\"children\":\"EngineCoreProc\"}],\" (child of \",[\"$\",\"code\",null,{\"children\":\"EngineCore\"}],\"), which:\"]}]\n"])</script><script>self.__next_f.push([1,"b1:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Creates an \",[\"$\",\"code\",null,{\"children\":\"input_queue\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"output_queue\"}],\" (\",[\"$\",\"code\",null,{\"children\":\"queue.Queue\"}],\").\"]}],[\"$\",\"li\",null,{\"children\":[\"Performs an initial handshake with the frontend on the other node using a \",[\"$\",\"code\",null,{\"children\":\"DEALER\"}],\" ZMQ socket (async messaging lib), and receives coordination address info.\"]}],[\"$\",\"li\",null,{\"children\":\"Initializes DP group (e.g. using NCCL backend).\"}],[\"$\",\"li\",null,{\"children\":[\"Initializes the \",[\"$\",\"code\",null,{\"children\":\"EngineCore\"}],\" with \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" (\",[\"$\",\"code\",null,{\"children\":\"TP=4\"}],\" on 4 GPUs as described earlier).\"]}],[\"$\",\"li\",null,{\"children\":[\"Creates a \",[\"$\",\"code\",null,{\"children\":\"ready_event\"}],\" (\",[\"$\",\"code\",null,{\"children\":\"threading.Event\"}],\").\"]}],[\"$\",\"li\",null,{\"children\":[\"Starts an input deamon thread (\",[\"$\",\"code\",null,{\"children\":\"threading.Thread\"}],\") running \",[\"$\",\"code\",null,{\"children\":\"process_input_sockets(‚Ä¶, ready_event)\"}],\". Similarly starts an output thread.\"]}],[\"$\",\"li\",null,{\"children\":[\"Still in the main thread, waits on \",[\"$\",\"code\",null,{\"children\":\"ready_event\"}],\" until all input threads across all 4 processes (spanning the 2 nodes) have completed the coordination handshake finally executing \",[\"$\",\"code\",null,{\"children\":\"ready_event.set()\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"Once unblocked, sends a \\\"ready\\\" message to the frontend with metadata (e.g., \",[\"$\",\"code\",null,{\"children\":\"num_gpu_blocks\"}],\" available in paged KV cache memory).\"]}],[\"$\",\"li\",null,{\"children\":\"The main, input, and output threads then enter their respective busy loops.\"}]]}]\n"])</script><script>self.__next_f.push([1,"b2:[\"$\",\"p\",null,{\"children\":\"TL;DR: We end up with 4 child processes (one per DP replica), each running a main, input, and output thread. They complete a coordination handshake with the DP coordinator and frontend, then all three threads per process run in steady-state busy loops.\"}]\nb3:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/dpenginecoreproc.png\",\"alt\":\"distributed system with 4 DPEngineCoreProc\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"distributed system with 4 DP replicas running 4 DPEngineCoreProc\"}]]}]\nb4:[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Current steady state:\"}]}]\n"])</script><script>self.__next_f.push([1,"b5:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Input thread\"}],\" ‚Äî blocks on the input socket until a request is routed from the API server; upon receipt, it decodes the payload, enqueues a work item via \",[\"$\",\"code\",null,{\"children\":\"input_queue.put_nowait(...)\"}],\", and returns to blocking on the socket.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Main thread\"}],\" ‚Äî wakes on \",[\"$\",\"code\",null,{\"children\":\"input_queue.get(...)\"}],\", feeds the request to the engine; \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" runs the forward pass and enqueues results to \",[\"$\",\"code\",null,{\"children\":\"output_queue\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Output thread\"}],\" ‚Äî wakes on \",[\"$\",\"code\",null,{\"children\":\"output_queue.get(...)\"}],\", sends the result back to the API server, then resumes blocking.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"b6:[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Additional mechanics:\"}]}]\n"])</script><script>self.__next_f.push([1,"b7:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"DP wave counter\"}],\" ‚Äî the system tracks \\\"waves\\\"; when all engines become idle they quiesce, and the counter increments when new work arrives (useful for coordination/metrics).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Control messages\"}],\" ‚Äî the API server can send more than just inference requests (e.g., aborts and utility/control RPCs).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Dummy steps for lockstep\"}],\" ‚Äî if any DP replica has work, all replicas execute a forward step; replicas without requests perform a dummy step to participate in required synchronization points (avoids blocking the active replica).\"]}]]}]\n"])</script><script>self.__next_f.push([1,"b8:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"Lockstep clarification: this is actually only required for MoE models where the expert layers form an EP or TP group while attention layers are still DP. It's currently always done with DP - this is just because there's limited use for \\\"built-in\\\" non-MoE DP since you could just run multiple independent vLLMs and load-balance between them in a normal way.\"}]]}]\nb9:[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"On the API server node\"}]\nba:[\"$\",\"p\",null,{\"children\":[\"We instantiate an \",[\"$\",\"code\",null,{\"children\":\"AsyncLLM\"}],\" object (an asyncio wrapper around the LLM engine). Internally this creates a \",[\"$\",\"code\",null,{\"children\":\"DPLBAsyncMPClient\"}],\" (data-parallel, load-balancing, asynchronous, multiprocessing client).\"]}]\nbb:[\"$\",\"p\",null,{\"children\":[\"Inside the parent class of \",[\"$\",\"code\",null,{\"children\":\"MPClient\"}],\", the \",[\"$\",\"code\",null,{\"children\":\"launch_core_engines\"}],\" function runs and:\"]}]\nbc:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Creates the ZMQ addresses used for the startup handshake (as seen on the headless node).\"}],[\"$\",\"li\",null,{\"children\":[\"Spawns a \",[\"$\",\"code\",null,{\"children\":\"DPCoordinator\"}],\" process.\"]}],[\"$\",\"li\",null,{\"children\":[\"Creates a \",[\"$\",\"code\",null,{\"children\":\"CoreEngineProcManager\"}],\" (same as on the headless node).\"]}]]}]\nbd:[\"$\",\"p\",null,{\"children\":[\"Inside \",[\"$\",\"code\",null,{\"children\":\"AsyncMPClient\"}],\" (child of \",[\"$\",\"code\",null,{\"children\":\"MPClient\"}],\"), we:\"]}]\n"])</script><script>self.__next_f.push([1,"be:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Create an \",[\"$\",\"code\",null,{\"children\":\"outputs_queue\"}],\" (\",[\"$\",\"code\",null,{\"children\":\"asyncio.Queue\"}],\").\"]}],[\"$\",\"li\",null,{\"children\":[\"We create an asyncio task \",[\"$\",\"code\",null,{\"children\":\"process_outputs_socket\"}],\" which communicates (through the output socket) with output threads of all 4 \",[\"$\",\"code\",null,{\"children\":\"DPEngineCoreProc\"}],\" and writes into \",[\"$\",\"code\",null,{\"children\":\"outputs_queue\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"Subsequently one more asyncio task \",[\"$\",\"code\",null,{\"children\":\"output_handler\"}],\" from \",[\"$\",\"code\",null,{\"children\":\"AsyncLLM\"}],\" reads from this queue and finally sends out information to the \",[\"$\",\"code\",null,{\"children\":\"create_completion\"}],\" function.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"bf:[\"$\",\"p\",null,{\"children\":[\"Inside \",[\"$\",\"code\",null,{\"children\":\"DPAsyncMPClient\"}],\" we create an asyncio task \",[\"$\",\"code\",null,{\"children\":\"run_engine_stats_update_task\"}],\" which communicates with DP coordinator.\"]}]\nc0:[\"$\",\"p\",null,{\"children\":\"The DP coordinator mediates between the frontend (API server) and backend (engine cores). It:\"}]\nc1:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Periodically sends load-balancing info (queue sizes, waiting/running requests) to the frontend's \",[\"$\",\"code\",null,{\"children\":\"run_engine_stats_update_task\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"Handles \",[\"$\",\"code\",null,{\"children\":\"SCALE_ELASTIC_EP\"}],\" commands from the frontend by dynamically changing the number of engines (only works with Ray backend).\"]}],[\"$\",\"li\",null,{\"children\":[\"Sends \",[\"$\",\"code\",null,{\"children\":\"START_DP_WAVE\"}],\" events to the backend (when triggered by frontend) and reports wave-state updates back.\"]}]]}]\nc2:[\"$\",\"p\",null,{\"children\":[\"To recap, the frontend (\",[\"$\",\"code\",null,{\"children\":\"AsyncLLM\"}],\") runs several asyncio tasks (remember: concurrent, not parallel):\"]}]\nc3:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"A class of tasks handles input requests through the \",[\"$\",\"code\",null,{\"children\":\"generate\"}],\" path (each new client request spawns a new asyncio task).\"]}],[\"$\",\"li\",null,{\"children\":[\"Two tasks (\",[\"$\",\"code\",null,{\"children\":\"process_outputs_socket\"}],\", \",[\"$\",\"code\",null,{\"children\":\"output_handler\"}],\") process output messages from the underlying engines.\"]}],[\"$\",\"li\",null,{\"children\":[\"One task (\",[\"$\",\"code\",null,{\"children\":\"run_engine_stats_update_task\"}],\") maintains communication with the DP coordinator: sending wave triggers, polling LB state, and handling dynamic scaling requests.\"]}]]}]\nc4:[\"$\",\"p\",null,{\"children\":[\"Finally, the main server process creates a FastAPI app and mounts endpoints such as \",[\"$\",\"code\",null,{\"children\":\"OpenAIServingCompletion\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"OpenAIServingChat\"}],\", which "])</script><script>self.__next_f.push([1,"expose \",[\"$\",\"code\",null,{\"children\":\"/completion\"}],\", \",[\"$\",\"code\",null,{\"children\":\"/chat/completion\"}],\", and others. The stack is then served via Uvicorn.\"]}]\nc5:[\"$\",\"p\",null,{\"children\":\"So, putting it all together, here's the full request lifecycle!\"}]\nc6:[\"$\",\"p\",null,{\"children\":\"You send from your terminal:\"}]\n"])</script><script>self.__next_f.push([1,"c7:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-bash\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"curl\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" -X POST http://localhost:8000/v1/completions -H \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Content-Type: application/json\\\"\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" -d \"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"'{\\n\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"  \\\"model\\\": \\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\",\\n\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"  \\\"prompt\\\": \\\"The capital of France is\\\",\\n\"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"  \\\"max_tokens\\\": 50,\\n\"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"  \\\"temperature\\\": 0.7\\n\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"}'\"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\"]]}]}]\n"])</script><script>self.__next_f.push([1,"c8:[\"$\",\"p\",null,{\"children\":\"What happens next:\"}]\n"])</script><script>self.__next_f.push([1,"c9:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"The request hits \",[\"$\",\"code\",null,{\"children\":\"OpenAIServingCompletion\"}],\"'s \",[\"$\",\"code\",null,{\"children\":\"create_completion\"}],\" route on the API server.\"]}],[\"$\",\"li\",null,{\"children\":\"The function tokenizes the prompt asynchronously, and prepares metadata (request ID, sampling params, timestamp, etc.).\"}],[\"$\",\"li\",null,{\"children\":[\"It then calls \",[\"$\",\"code\",null,{\"children\":\"AsyncLLM.generate\"}],\", which follows the same flow as the synchronous engine, eventually invoking \",[\"$\",\"code\",null,{\"children\":\"DPAsyncMPClient.add_request_async\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"This in turn calls \",[\"$\",\"code\",null,{\"children\":\"get_core_engine_for_request\"}],\", which does load balancing across engines based on the DP coordinator's state (picking the one that has minimal score / lowest load: \",[\"$\",\"code\",null,{\"children\":\"score = len(waiting) * 4 + len(running)\"}],\").\"]}],[\"$\",\"li\",null,{\"children\":[\"The \",[\"$\",\"code\",null,{\"children\":\"ADD\"}],\" request is sent to the chosen engine's \",[\"$\",\"code\",null,{\"children\":\"input_socket\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[\"At that engine:\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Input thread ‚Äî unblocks, decodes data from the input socket, and places a work item on the \",[\"$\",\"code\",null,{\"children\":\"input_queue\"}],\" for the main thread.\"]}],[\"$\",\"li\",null,{\"children\":[\"Main thread ‚Äî unblocks on \",[\"$\",\"code\",null,{\"children\":\"input_queue\"}],\", adds the request to the engine, and repeatedly calls \",[\"$\",\"code\",null,{\"children\":\"engine_core.step()\"}],\", enqueueing intermediate results to \",[\"$\",\"code\",null,{\"children\":\"output_queue\"}],\" until a stop condition is met.\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"Reminder: \",[\"$\",\"code\",null,{\"children\":\"step()\"}],\" calls the scheduler, model executor (which in turn can be \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\"!), etc. We have already seen this!\"]}]]}],[\"$\",\"li\",null,{\"children\":[\"Output thread ‚Äî unblocks on \",[\"$\",\"code\",null,{\"children\":\"output_queue\"}],\" and sends results back through the output socket.\"]}]]}]]}],[\"$\",\"li\",null,{\"children\":[\"Those results trigger the \",[\"$\",\"code\",null,{\"children\":\"AsyncLLM\"}],\" output asyncio tasks (\",[\"$\",\"code\",null,{\"children\":\"process_outputs_socket\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"output_handler\"}],\"), which propagate tokens back to FastAPI's \",[\"$\",\"code\",null,{\"children\":\"create_completion\"}],\" route.\"]}],[\"$\",\"li\",null,{\"children\":[\"FastAPI attaches metadata (finish reason, logprobs, usage info, etc.) and returns a \",[\"$\",\"code\",null,{\"children\":\"JSONResponse\"}],\" via Uvicorn to your terminal!\"]}]]}]\n"])</script><script>self.__next_f.push([1,"ca:[\"$\",\"p\",null,{\"children\":[\"And just like that, your completion came back ‚Äî the whole distributed machinery hidden behind a simple \",[\"$\",\"code\",null,{\"children\":\"curl\"}],\" command! :) So much fun!!!\"]}]\n"])</script><script>self.__next_f.push([1,"cb:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Additional notes:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"When adding more API servers, load balancing is handled at the OS/socket level. From the application's perspective, nothing significant changes ‚Äî the complexity is hidden.\"}],[\"$\",\"li\",null,{\"children\":[\"With Ray as a DP backend, you can expose a URL endpoint (\",[\"$\",\"code\",null,{\"children\":\"/scale_elastic_ep\"}],\") that enables automatic scaling of the number of engine replicas up or down.\"]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"cc:[\"$\",\"h2\",null,{\"id\":\"cpt5\",\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Benchmarks and auto-tuning - latency vs throughput\"}]\ncd:[\"$\",\"p\",null,{\"children\":\"So far we've been analyzing the \\\"gas particles\\\" ‚Äî the internals of how requests flow through the engine/system. Now it's time to zoom out and look at the system as a whole, and ask: how do we measure the performance of an inference system?\"}]\nce:[\"$\",\"p\",null,{\"children\":\"At the highest level there are two competing metrics:\"}]\ncf:[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Latency\"}],\" ‚Äî the time from when a request is submitted until tokens are returned\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Throughput\"}],\" ‚Äî the number of tokens/requests per second the system can generate/process\"]}]]}]\nd0:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Latency\"}],\" matters most for interactive applications, where users are waiting on responses.\"]}]\nd1:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Throughput\"}],\" matters in offline workloads like synthetic data generation for pre/post-training runs, data cleaning/processing, and in general - any type of offline batch inference jobs.\"]}]\nd2:[\"$\",\"p\",null,{\"children\":\"Before explaining why latency and throughput compete, let's define a few common inference metrics:\"}]\n"])</script><script>self.__next_f.push([1,"d3:[\"$\",\"table\",null,{\"className\":\"border border-gray-300 border-collapse w-full my-4\",\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"className\":\"bg-gray-100\",\"children\":[[\"$\",\"th\",null,{\"className\":\"border border-gray-300 px-4 py-2 text-left font-semibold\",\"children\":\"Metric\"}],[\"$\",\"th\",null,{\"className\":\"border border-gray-300 px-4 py-2 text-left font-semibold\",\"children\":\"Definition\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[[\"$\",\"code\",null,{\"children\":\"TTFT\"}],[\"$\",\"br\",null,{}],\"(time to first token)\"]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"Time from request submission until the first output token is received\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[[\"$\",\"code\",null,{\"children\":\"ITL\"}],[\"$\",\"br\",null,{}],\"(inter-token latency)\"]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"Time between two consecutive tokens (e.g., from token i-1 to token i)\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[[\"$\",\"code\",null,{\"children\":\"TPOT\"}],[\"$\",\"br\",null,{}],\"(time per output token)\"]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"The average ITL across all output tokens in a request\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[[\"$\",\"code\",null,{\"children\":\"Latency / E2E\"}],[\"$\",\"br\",null,{}],\"(end-to-end latency)\"]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"Total time to process a request, i.e. TTFT + sum of all ITLs, or equivalently the time between submitting request and receiving the last output token\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[\"$\",\"code\",null,{\"children\":\"Throughput\"}]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"Total tokens processed per second (input, output, or both), or alternatively requests per second\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":[\"$\",\"code\",null,{\"children\":\"Goodput\"}]}],[\"$\",\"td\",null,{\"className\":\"border border-gray-300 px-4 py-2\",\"children\":\"Throughput that meets service-level objectives (SLOs) such as max TTFT, TPOT, or e2e latency. For example, only tokens from requests meeting those SLOs are counted\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"d4:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/latency_diagram.png\",\"alt\":\"ttft, itl, e2e latency\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-sm mt-2\",\"children\":\"ttft, itl, e2e latency\"}]]}]\nd5:[\"$\",\"p\",null,{\"children\":\"Here is a simplified model explaining the competing nature of these 2 metrics.\"}]\nd6:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":\"Assumption: weight i/o and not KV cache i/o dominates; i.e. we're dealing with short sequences.\"}]]}]\nd7:[\"$\",\"p\",null,{\"children\":[\"The tradeoff becomes clear when looking at how batch size \",[\"$\",\"code\",null,{\"children\":\"B\"}],\" affects a single decode step. As \",[\"$\",\"code\",null,{\"children\":\"B ‚Üì\"}],\" toward 1, ITL drops: there's less work per step and the token isn't \\\"competing\\\" with others. As \",[\"$\",\"code\",null,{\"children\":\"B ‚Üë\"}],\" toward infinity, ITL rises because we do more FLOPs per step‚Äîbut throughput improves (until we hit peak perf) because weight I/O is amortized across more tokens.\"]}]\nd8:[\"$\",\"p\",null,{\"children\":[\"A roofline model helps with understanding here: below a saturation batch \",[\"$\",\"code\",null,{\"children\":\"B_sat\"}],\", the step time is dominated by HBM bandwidth (streaming weights layer-by-layer into on-chip memory), so step latency is nearly flat‚Äîcomputing 1 vs 10 tokens can take a similar time. Beyond \",[\"$\",\"code\",null,{\"children\":\"B_sat\"}],\", the kernels become compute-bound and step time grows roughly with \",[\"$\",\"code\",null,{\"children\":\"B\"}],\"; each extra token adds to ITL.\"]}]\nd9:[\"$\",\"div\",null,{\"className\":\"my-6\",\"children\":[[\"$\",\"img\",null,{\"src\":\"/blog/vllm/roofline.png\",\"alt\":\"roofline perf model\",\"className\":\"w-max max-w-full h-auto rounded-lg mx-auto \"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500 text-center text-"])</script><script>self.__next_f.push([1,"sm mt-2\",\"children\":\"roofline perf model\"}]]}]\n"])</script><script>self.__next_f.push([1,"da:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#f5f5f5\",\"borderLeftColor\":\"#757575\",\"color\":\"#424242\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üìù\"}],\"Note:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"For a more rigorous treatment, we have to account for kernel auto-tuning: as \",[\"$\",\"code\",null,{\"children\":\"B\"}],\" grows, the runtime may switch to more efficient kernels for that shape, changing the achieved performance \",[\"$\",\"code\",null,{\"children\":\"P_kernel\"}],\". Step latency is \",[\"$\",\"code\",null,{\"children\":\"t = FLOPs_step / P_kernel\"}],\", where \",[\"$\",\"code\",null,{\"children\":\"FLOPs_step\"}],\" is the work in the step. You can see that as \",[\"$\",\"code\",null,{\"children\":\"P_kernel\"}],\" hits \",[\"$\",\"code\",null,{\"children\":\"P_peak\"}],\" more compute per step will directly lead to an increase in latency.\"]}]]}]\n"])</script><script>self.__next_f.push([1,"db:[\"$\",\"h2\",null,{\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"How to benchmark in vLLM\"}]\ndc:[\"$\",\"p\",null,{\"children\":[\"vLLM provides a \",[\"$\",\"code\",null,{\"children\":[\"vllm bench \",\"{\",\"serve,latency,throughput\",\"}\"]}],\" CLI that wraps vllm / benchmarks / \",\"{\",\"server,latency,throughput\",\"}\",\".py.\"]}]\ndd:[\"$\",\"p\",null,{\"children\":\"Here is what the scripts do:\"}]\n"])</script><script>self.__next_f.push([1,"de:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"latency\"}],\" ‚Äî uses a short input (default 32 tokens) and samples 128 output tokens with a small batch (default 8). It runs several iterations and reports e2e latency for the batch.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"throughput\"}],\" ‚Äî submits a fixed set of prompts (default: 1000 ShareGPT samples) all at once (aka as \",[\"$\",\"code\",null,{\"children\":\"QPS=Inf\"}],\" mode), and reports input/output/total tokens and requests per second across the run.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"serve\"}],\" ‚Äî Launches a vLLM server and simulates a real-world workload by sampling request inter-arrival times from a Poisson (or more generally, Gamma) distribution. It sends requests over a time window, measures all the metrics we‚Äôve discussed, and can optionally enforce a server-side max concurrency (via a semaphore, e.g. limiting the server to 64 concurrent requests).\"]}]]}]\n"])</script><script>self.__next_f.push([1,"df:[\"$\",\"pre\",null,{\"style\":{\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"whiteSpace\":\"pre\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\",\"padding\":\"1em\",\"margin\":\"1rem 0\",\"overflow\":\"auto\",\"borderRadius\":\"6px\",\"backgroundColor\":\"#f8f9fa\",\"border\":\"1px solid #e9ecef\",\"fontSize\":\"14px\"},\"children\":[\"$\",\"code\",null,{\"className\":\"language-bash\",\"style\":{\"whiteSpace\":\"pre\",\"background\":\"hsl(230, 1%, 98%)\",\"color\":\"hsl(230, 8%, 24%)\",\"fontFamily\":\"\\\"Fira Code\\\", \\\"Fira Mono\\\", Menlo, Consolas, \\\"DejaVu Sans Mono\\\", monospace\",\"direction\":\"ltr\",\"textAlign\":\"left\",\"wordSpacing\":\"normal\",\"wordBreak\":\"normal\",\"lineHeight\":\"1.5\",\"MozTabSize\":\"2\",\"OTabSize\":\"2\",\"tabSize\":\"2\",\"WebkitHyphens\":\"none\",\"MozHyphens\":\"none\",\"msHyphens\":\"none\",\"hyphens\":\"none\"},\"children\":[false,[[\"$\",\"span\",\"code-segment-0\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"vllm bench latency\\n\"]}],[\"$\",\"span\",\"code-segment-1\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  --model \"]}],[\"$\",\"span\",\"code-segment-2\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003c\"]}],[\"$\",\"span\",\"code-segment-3\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model-name\"]}],[\"$\",\"span\",\"code-segment-4\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003e\"]}],[\"$\",\"span\",\"code-segment-5\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-6\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  --input-tokens \"]}],[\"$\",\"span\",\"code-segment-7\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"32\"]}],[\"$\",\"span\",\"code-segment-8\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-9\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  --output-tokens \"]}],[\"$\",\"span\",\"code-segment-10\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"128\"]}],[\"$\",\"span\",\"code-segment-11\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],[\"$\",\"span\",\"code-segment-12\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  --batch-size \"]}],[\"$\",\"span\",\"code-segment-13\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"8\"]}],[\"$\",\"span\",\"code-segment-14\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}],\"\"]]}]}]\n"])</script><script>self.__next_f.push([1,"e0:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"Benchmark configs used in CI live under \",[\"$\",\"code\",null,{\"children\":\".buildkite/nightly-benchmarks/tests\"}],\".\"]}]]}]\ne1:[\"$\",\"p\",null,{\"children\":[\"There is also an auto-tune script that drives the serve benchmark to find argument settings that meet target SLOs (e.g., \\\"maximize throughput while keeping p99 e2e \",\"\u003c\",\" 500 ms\\\"), returning a suggested config.\"]}]\ne2:[\"$\",\"h2\",null,{\"className\":\"font-semibold text-black text-xl mb-3 mt-6\",\"children\":\"Epilogue\"}]\ne3:[\"$\",\"p\",null,{\"children\":[\"We began with the basic engine core (\",[\"$\",\"code\",null,{\"children\":\"UniprocExecutor\"}],\"), added advanced features like speculative decoding and prefix caching, scaled up to \",[\"$\",\"code\",null,{\"children\":\"MultiProcExecutor\"}],\" (with \",[\"$\",\"code\",null,{\"children\":[\"TP/PP \",\"\u003e\",\" 1\"]}],\"), and finally scaled out, wrapped everything in the asynchronous engine and distributed serving stack‚Äîclosing with how to measure system performance.\"]}]\ne4:[\"$\",\"p\",null,{\"children\":\"vLLM also includes specialized handling that I've skipped. E.g.:\"}]\n"])</script><script>self.__next_f.push([1,"e5:[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Diverse hardware backends:\"}],\" TPUs, AWS Neuron (Trainium/Inferentia), etc.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Architectures/techniques:\"}],\" \",[\"$\",\"code\",null,{\"children\":\"MLA\"}],\", \",[\"$\",\"code\",null,{\"children\":\"MoE\"}],\", encoder-decoder (e.g., Whisper), pooling/embedding models, \",[\"$\",\"code\",null,{\"children\":\"EPLB\"}],\", \",[\"$\",\"code\",null,{\"children\":\"m-RoPE\"}],\", \",[\"$\",\"code\",null,{\"children\":\"LoRA\"}],\", \",[\"$\",\"code\",null,{\"children\":\"ALiBi\"}],\", attention-free variants, sliding-window attention, multimodal LMs, and state-space models (e.g., Mamba/Mamba-2, Jamba)\"]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"TP/PP/SP\"}]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Hybrid KV-cache logic\"}],\" (Jenga), more complex sampling methods like beam sampling, and more\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Experimental\"}],\": async scheduling\"]}]]}]\n"])</script><script>self.__next_f.push([1,"e6:[\"$\",\"p\",null,{\"children\":\"The nice thing is that most of these are orthogonal to the main flow described above‚Äîyou can almost treat them like \\\"plugins\\\" (in practice there's some coupling, of course).\"}]\ne7:[\"$\",\"p\",null,{\"children\":\"I love understanding systems. Having said that, the resolution definitely suffered at this altitude. In the next posts I'll zoom in on specific subsystems and get into the nitty-gritty details.\"}]\n"])</script><script>self.__next_f.push([1,"e8:[\"$\",\"div\",null,{\"className\":\"my-4 p-4 rounded-lg border-l-4\",\"style\":{\"backgroundColor\":\"#e3f2fd\",\"borderLeftColor\":\"#2196f3\",\"color\":\"#0d47a1\"},\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-2 font-semibold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mr-2 text-lg\",\"children\":\"üí°\"}],\"Get in touch:\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm leading-relaxed\",\"children\":[\"If you spot any errors in the post, please DM me - feel free to drop me a message on \",[\"$\",\"a\",null,{\"href\":\"https://x.com/gordic_aleksa\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"X\"}],\" or \",[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/aleksagordic/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"LinkedIn\"}],\" or via \",[\"$\",\"a\",null,{\"href\":\"https://docs.google.com/forms/d/1z1fEirrN2xtGxAsJvptpM7yV4ByT5SF25S-XiMPrXNA/edit\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"anon feedback\"}],\".\"]}]]}]\n"])</script><script>self.__next_f.push([1,"e9:[\"$\",\"h2\",null,{\"id\":\"references\",\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"Acknowledgements\"}]\nea:[\"$\",\"p\",null,{\"children\":[\"A huge thank you to \",[\"$\",\"a\",null,{\"href\":\"https://www.hyperstack.cloud/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"Hyperstack\"}],\" for providing me with H100s for my experiments over the past year!\"]}]\n"])</script><script>self.__next_f.push([1,"eb:[\"$\",\"p\",null,{\"children\":[\"Thanks to \",[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/nickhillprofile/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"Nick Hill\"}],\" (core vLLM contributor, RedHat), \",[\"$\",\"a\",null,{\"href\":\"https://x.com/marksaroufim\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"Mark Saroufim\"}],\" (PyTorch), \",[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/kyle-kranen/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"Kyle Krannen\"}],\" (NVIDIA, Dynamo), and \",[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/ashish-vaswani-99892181/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"Ashish Vaswani\"}],\" for reading pre-release version of this blog post and providing feedback!\"]}]\n"])</script><script>self.__next_f.push([1,"ec:[\"$\",\"h2\",null,{\"id\":\"references\",\"className\":\"text-black text-xl mb-3 mt-6\",\"children\":\"References\"}]\n"])</script><script>self.__next_f.push([1,"ed:[\"$\",\"ol\",null,{\"className\":\"break-words overflow-hidden\",\"children\":[[\"$\",\"li\",null,{\"id\":\"ref-1\",\"children\":[\"vLLM \",[\"$\",\"a\",null,{\"href\":\"https://github.com/vllm-project/vllm\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://github.com/vllm-project/vllm\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-2\",\"children\":[\"\\\"Attention Is All You Need\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/1706.03762\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/1706.03762\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-3\",\"children\":[\"\\\"Efficient Memory Management for Large Language Model Serving with PagedAttention\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2309.06180\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2309.06180\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-4\",\"children\":[\"\\\"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2405.04434\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2405.04434\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-5\",\"children\":[\"\\\"Jenga: Effective Memory Management for Serving LLM with Heterogeneity\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2503.18292\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2503.18292\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-6\",\"children\":[\"\\\"Orca: A Distributed Serving System for Transformer-Based Generative Models\\\", \",[\"$\",\"a\",null,{\"href\":\"https://www.usenix.org/conference/osdi22/presentation/yu\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://www.usenix.org/conference/osdi22/presentation/yu\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-7\",\"children\":[\"\\\"XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2411.15100\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2411.15100\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-8\",\"children\":[\"\\\"Accelerating Large Language Model Decoding with Speculative Sampling\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2302.01318\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2302.01318\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-9\",\"children\":[\"\\\"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2401.15077\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2401.15077\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-10\",\"children\":[\"\\\"Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads\\\", \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2401.10774\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://arxiv.org/abs/2401.10774\"}]]}],[\"$\",\"li\",null,{\"id\":\"ref-11\",\"children\":[\"LMCache, \",[\"$\",\"a\",null,{\"href\":\"https://github.com/LMCache/LMCache\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 underline hover:text-blue-800 \",\"children\":\"https://github.com/LMCache/LMCache\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"ee:[\"$\",\"$L359\",null,{\"children\":[\"$L35a\",[\"$\",\"$L35b\",null,{\"promise\":\"$@35c\"}]]}]\nef:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L35d\",null,{\"children\":\"$L35e\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L35f\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$360\",null,{\"fallback\":null,\"children\":\"$L361\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"f1:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\nf2:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"main\"]}]\nf3:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\nf4:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\nf5:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\nf6:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\nf7:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    llm \"]}]\nf8:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\nf9:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\nfa:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\nfb:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\nfc:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\nfd:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\nfe:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\nff:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n100:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    outputs \"]}]\n101:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n102:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" llm\"]}]\n103:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n104:[\"$\",\"span\",\"code-segment-60\",{\""])</script><script>self.__next_f.push([1,"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n105:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n106:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts\"]}]\n107:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n108:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n109:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n10a:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n10b:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n10c:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"if\"]}]\n10d:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" __name__ \"]}]\n10e:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"==\"]}]\n10f:[\"$\",\"span\",\"code-segment-72\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n110:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"__main__\\\"\"]}]\n111:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n112:[\"$\",\"span\",\"code-segment-75\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n113:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    main\"]}]\n114:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n115:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n116:[\"$\",\"span\",\"code-segment-39\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n117:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"}"])</script><script>self.__next_f.push([1,",\"children\":[\"0.95\"]}]\n118:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n119:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n11a:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n11b:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}]\n11c:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n11d:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"main\"]}]\n11e:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n11f:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n120:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n121:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n122:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    llm \"]}]\n123:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n124:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\n125:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n126:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\n127:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n128:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\n129:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n12a:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n12b:[\"$\",\""])</script><script>self.__next_f.push([1,"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    outputs \"]}]\n12c:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n12d:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" llm\"]}]\n12e:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n12f:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n130:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n131:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"long_prefix \"]}]\n132:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"+\"]}]\n133:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" prompts\"]}]\n134:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}]\n135:[\"$\",\"span\",\"code-segment-72\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0\"]}]\n136:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n137:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n138:[\"$\",\"span\",\"code-segment-75\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n139:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n13a:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n13b:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    outputs \"]}]\n13c:[\"$\",\"span\",\"code-segment-79\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n13d:[\"$\",\"span\",\"code-segment-80\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" llm\"]}]\n13e:[\"$\",\"span\",\"code-segment-81\",{\"className\":\"token\",\""])</script><script>self.__next_f.push([1,"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n13f:[\"$\",\"span\",\"code-segment-82\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n140:[\"$\",\"span\",\"code-segment-83\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n141:[\"$\",\"span\",\"code-segment-84\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"long_prefix \"]}]\n142:[\"$\",\"span\",\"code-segment-85\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"+\"]}]\n143:[\"$\",\"span\",\"code-segment-86\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" prompts\"]}]\n144:[\"$\",\"span\",\"code-segment-87\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}]\n145:[\"$\",\"span\",\"code-segment-88\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"1\"]}]\n146:[\"$\",\"span\",\"code-segment-89\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n147:[\"$\",\"span\",\"code-segment-90\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n148:[\"$\",\"span\",\"code-segment-91\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n149:[\"$\",\"span\",\"code-segment-92\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n14a:[\"$\",\"span\",\"code-segment-93\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n14b:[\"$\",\"span\",\"code-segment-95\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n14c:[\"$\",\"span\",\"code-segment-96\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"if\"]}]\n14d:[\"$\",\"span\",\"code-segment-97\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" __name__ \"]}]\n14e:[\"$\",\"span\",\"code-segment-98\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"==\"]}]\n14f:[\"$\",\"span\",\"code-segment-99\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n150:[\"$\",\"span\",\"code-segment-100\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"__main__\\\"\"]}]\n151:[\"$\",\"span\",\"code-segment-101\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%"])</script><script>self.__next_f.push([1,", 24%)\"},\"children\":[\":\"]}]\n152:[\"$\",\"span\",\"code-segment-102\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n153:[\"$\",\"span\",\"code-segment-103\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    main\"]}]\n154:[\"$\",\"span\",\"code-segment-104\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n155:[\"$\",\"span\",\"code-segment-105\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n156:[\"$\",\"span\",\"code-segment-39\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n157:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n158:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Negative\\\"\"]}]\n159:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n15a:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n15b:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n15c:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sampling_params \"]}]\n15d:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n15e:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}]\n15f:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n160:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"guided_decoding\"]}]\n161:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n162:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"guided_decoding_params\"]}]\n163:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n164:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}"])</script><script>self.__next_f.push([1,"]\n165:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n166:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}]\n167:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n168:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"main\"]}]\n169:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n16a:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n16b:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n16c:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n16d:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    llm \"]}]\n16e:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n16f:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\n170:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n171:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\n172:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n173:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\n174:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n175:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n176:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    outputs \"]}]\n177:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n178:[\"$\",\"span\",\"cod"])</script><script>self.__next_f.push([1,"e-segment-75\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" llm\"]}]\n179:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n17a:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n17b:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n17c:[\"$\",\"span\",\"code-segment-79\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts\"]}]\n17d:[\"$\",\"span\",\"code-segment-80\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n17e:[\"$\",\"span\",\"code-segment-81\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n17f:[\"$\",\"span\",\"code-segment-82\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n180:[\"$\",\"span\",\"code-segment-83\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n181:[\"$\",\"span\",\"code-segment-85\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n182:[\"$\",\"span\",\"code-segment-86\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"if\"]}]\n183:[\"$\",\"span\",\"code-segment-87\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" __name__ \"]}]\n184:[\"$\",\"span\",\"code-segment-88\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"==\"]}]\n185:[\"$\",\"span\",\"code-segment-89\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n186:[\"$\",\"span\",\"code-segment-90\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"__main__\\\"\"]}]\n187:[\"$\",\"span\",\"code-segment-91\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n188:[\"$\",\"span\",\"code-segment-92\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n189:[\"$\",\"span\",\"code-segment-93\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    main\"]}]\n18a:[\"$\",\"span\",\"code-segment-94\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n18b:[\"$\",\"span\",\"code-segment-95\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"ch"])</script><script>self.__next_f.push([1,"ildren\":[\")\"]}]\n18c:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"{\"]}]\n18d:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n18e:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}]\n18f:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"method\\\"\"]}]\n190:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n191:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n192:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"ngram\\\"\"]}]\n193:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n194:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n195:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}]\n196:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"prompt_lookup_max\\\"\"]}]\n197:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n198:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n199:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"5\"]}]\n19a:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n19b:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n19c:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}]\n19d:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"prompt_lookup_min\\\"\"]}]\n19e:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n19f:[\"$"])</script><script>self.__next_f.push([1,"\",\"span\",\"code-segment-59\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1a0:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"3\"]}]\n1a1:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1a2:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1a3:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}]\n1a4:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"num_speculative_tokens\\\"\"]}]\n1a5:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n1a6:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1a7:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"3\"]}]\n1a8:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1a9:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1aa:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n1ab:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"}\"]}]\n1ac:[\"$\",\"span\",\"code-segment-72\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1ad:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n1ae:[\"$\",\"span\",\"code-segment-75\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}]\n1af:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1b0:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"main\"]}]\n1b1:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1b2:[\"$\",\"span\",\"code-segment-79\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24"])</script><script>self.__next_f.push([1,"%)\"},\"children\":[\")\"]}]\n1b3:[\"$\",\"span\",\"code-segment-80\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n1b4:[\"$\",\"span\",\"code-segment-81\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1b5:[\"$\",\"span\",\"code-segment-82\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    llm \"]}]\n1b6:[\"$\",\"span\",\"code-segment-83\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1b7:[\"$\",\"span\",\"code-segment-84\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\n1b8:[\"$\",\"span\",\"code-segment-85\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1b9:[\"$\",\"span\",\"code-segment-86\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\n1ba:[\"$\",\"span\",\"code-segment-87\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1bb:[\"$\",\"span\",\"code-segment-88\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\n1bc:[\"$\",\"span\",\"code-segment-89\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1bd:[\"$\",\"span\",\"code-segment-90\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" speculative_config\"]}]\n1be:[\"$\",\"span\",\"code-segment-91\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1bf:[\"$\",\"span\",\"code-segment-92\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"speculative_config\"]}]\n1c0:[\"$\",\"span\",\"code-segment-93\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n1c1:[\"$\",\"span\",\"code-segment-94\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1c2:[\"$\",\"span\",\"code-segment-96\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    outputs \"]}]\n1c3:[\"$\",\"span\",\"code-segment-97\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1c4:[\"$\",\"span\",\"code-segment-98\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" llm\"]}]\n1c5:[\"$\",\"span\",\"code-segment-99\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"child"])</script><script>self.__next_f.push([1,"ren\":[\".\"]}]\n1c6:[\"$\",\"span\",\"code-segment-100\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n1c7:[\"$\",\"span\",\"code-segment-101\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1c8:[\"$\",\"span\",\"code-segment-102\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts\"]}]\n1c9:[\"$\",\"span\",\"code-segment-103\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1ca:[\"$\",\"span\",\"code-segment-104\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n1cb:[\"$\",\"span\",\"code-segment-105\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n1cc:[\"$\",\"span\",\"code-segment-106\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1cd:[\"$\",\"span\",\"code-segment-108\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n1ce:[\"$\",\"span\",\"code-segment-109\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"if\"]}]\n1cf:[\"$\",\"span\",\"code-segment-110\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" __name__ \"]}]\n1d0:[\"$\",\"span\",\"code-segment-111\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"==\"]}]\n1d1:[\"$\",\"span\",\"code-segment-112\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1d2:[\"$\",\"span\",\"code-segment-113\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"__main__\\\"\"]}]\n1d3:[\"$\",\"span\",\"code-segment-114\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n1d4:[\"$\",\"span\",\"code-segment-115\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1d5:[\"$\",\"span\",\"code-segment-116\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    main\"]}]\n1d6:[\"$\",\"span\",\"code-segment-117\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1d7:[\"$\",\"span\",\"code-segment-118\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n1d8:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Hello, my name is\\\"\"]}]\n1d9:["])</script><script>self.__next_f.push([1,"\"$\",\"span\",\"code-segment-42\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1da:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1db:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"    \"]}]\n1dc:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"The president of the United States is\\\"\"]}]\n1dd:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1de:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1df:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n1e0:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n1e1:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1e2:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n1e3:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}]\n1e4:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1e5:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"run_prefill\"]}]\n1e6:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1e7:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prefill_done\"]}]\n1e8:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n1e9:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n1ea:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1eb:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  os\"]}]\n1ec:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"token\",\"style\":{\"color\""])</script><script>self.__next_f.push([1,":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n1ed:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"environ\"]}]\n1ee:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}]\n1ef:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"CUDA_VISIBLE_DEVICES\\\"\"]}]\n1f0:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n1f1:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1f2:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1f3:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n1f4:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"0\\\"\"]}]\n1f5:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n1f6:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  sampling_params \"]}]\n1f7:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1f8:[\"$\",\"span\",\"code-segment-75\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}]\n1f9:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n1fa:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"temperature\"]}]\n1fb:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n1fc:[\"$\",\"span\",\"code-segment-79\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0\"]}]\n1fd:[\"$\",\"span\",\"code-segment-80\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n1fe:[\"$\",\"span\",\"code-segment-81\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" top_p\"]}]\n1ff:[\"$\",\"span\",\"code-segment-82\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, "])</script><script>self.__next_f.push([1,"87%, 60%)\"},\"children\":[\"=\"]}]\n200:[\"$\",\"span\",\"code-segment-83\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.95\"]}]\n201:[\"$\",\"span\",\"code-segment-84\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n202:[\"$\",\"span\",\"code-segment-85\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" max_tokens\"]}]\n203:[\"$\",\"span\",\"code-segment-86\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n204:[\"$\",\"span\",\"code-segment-87\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"1\"]}]\n205:[\"$\",\"span\",\"code-segment-88\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n206:[\"$\",\"span\",\"code-segment-89\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n207:[\"$\",\"span\",\"code-segment-91\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  ktc\"]}]\n208:[\"$\",\"span\",\"code-segment-92\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n209:[\"$\",\"span\",\"code-segment-93\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"KVTransferConfig\"]}]\n20a:[\"$\",\"span\",\"code-segment-94\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n20b:[\"$\",\"span\",\"code-segment-95\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n20c:[\"$\",\"span\",\"code-segment-96\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_connector\"]}]\n20d:[\"$\",\"span\",\"code-segment-97\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n20e:[\"$\",\"span\",\"code-segment-98\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"SharedStorageConnector\\\"\"]}]\n20f:[\"$\",\"span\",\"code-segment-99\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n210:[\"$\",\"span\",\"code-segment-100\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n211:[\"$\",\"span\",\"code-segment-101\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_role\"]}]\n212:[\"$\",\"span\",\"code-segment-102\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221,"])</script><script>self.__next_f.push([1," 87%, 60%)\"},\"children\":[\"=\"]}]\n213:[\"$\",\"span\",\"code-segment-103\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"kv_both\\\"\"]}]\n214:[\"$\",\"span\",\"code-segment-104\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n215:[\"$\",\"span\",\"code-segment-105\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n216:[\"$\",\"span\",\"code-segment-106\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_connector_extra_config\"]}]\n217:[\"$\",\"span\",\"code-segment-107\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n218:[\"$\",\"span\",\"code-segment-108\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"{\"]}]\n219:[\"$\",\"span\",\"code-segment-109\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"shared_storage_path\\\"\"]}]\n21a:[\"$\",\"span\",\"code-segment-110\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n21b:[\"$\",\"span\",\"code-segment-111\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n21c:[\"$\",\"span\",\"code-segment-112\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"local_storage\\\"\"]}]\n21d:[\"$\",\"span\",\"code-segment-113\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"}\"]}]\n21e:[\"$\",\"span\",\"code-segment-114\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n21f:[\"$\",\"span\",\"code-segment-115\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n220:[\"$\",\"span\",\"code-segment-116\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n221:[\"$\",\"span\",\"code-segment-117\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n222:[\"$\",\"span\",\"code-segment-118\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n223:[\"$\",\"span\",\"code-segment-120\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  llm \"]}]\n224:[\"$\",\"span\",\"code-segment-121\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n225:[\"$\",\"span\",\"code-segment-122\",{\"classNa"])</script><script>self.__next_f.push([1,"me\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\n226:[\"$\",\"span\",\"code-segment-123\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n227:[\"$\",\"span\",\"code-segment-124\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\n228:[\"$\",\"span\",\"code-segment-125\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n229:[\"$\",\"span\",\"code-segment-126\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\n22a:[\"$\",\"span\",\"code-segment-127\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n22b:[\"$\",\"span\",\"code-segment-128\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" kv_transfer_config\"]}]\n22c:[\"$\",\"span\",\"code-segment-129\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n22d:[\"$\",\"span\",\"code-segment-130\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"ktc\"]}]\n22e:[\"$\",\"span\",\"code-segment-131\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n22f:[\"$\",\"span\",\"code-segment-132\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n230:[\"$\",\"span\",\"code-segment-133\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  llm\"]}]\n231:[\"$\",\"span\",\"code-segment-134\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n232:[\"$\",\"span\",\"code-segment-135\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n233:[\"$\",\"span\",\"code-segment-136\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n234:[\"$\",\"span\",\"code-segment-137\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts\"]}]\n235:[\"$\",\"span\",\"code-segment-138\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n236:[\"$\",\"span\",\"code-segment-139\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n237:[\"$\",\"span\",\"code-segment-140\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n238:[\"$\",\"span\",\"code-segment-141\",{\"classN"])</script><script>self.__next_f.push([1,"ame\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n239:[\"$\",\"span\",\"code-segment-143\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_done\"]}]\n23a:[\"$\",\"span\",\"code-segment-144\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n23b:[\"$\",\"span\",\"code-segment-145\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"set\"]}]\n23c:[\"$\",\"span\",\"code-segment-146\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n23d:[\"$\",\"span\",\"code-segment-147\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n23e:[\"$\",\"span\",\"code-segment-148\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n23f:[\"$\",\"span\",\"code-segment-149\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 4%, 64%)\",\"fontStyle\":\"italic\"},\"children\":[\"# notify decode instance that KV cache is ready\"]}]\n240:[\"$\",\"span\",\"code-segment-150\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n241:[\"$\",\"span\",\"code-segment-152\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n242:[\"$\",\"span\",\"code-segment-153\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 4%, 64%)\",\"fontStyle\":\"italic\"},\"children\":[\"# To keep the prefill node running in case the decode node is not done;\"]}]\n243:[\"$\",\"span\",\"code-segment-154\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n244:[\"$\",\"span\",\"code-segment-155\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n245:[\"$\",\"span\",\"code-segment-156\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 4%, 64%)\",\"fontStyle\":\"italic\"},\"children\":[\"# otherwise, the script might exit prematurely, causing incomplete decoding.\"]}]\n246:[\"$\",\"span\",\"code-segment-157\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n247:[\"$\",\"span\",\"code-segment-158\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n248:[\"$\",\"span\",\"code-segment-159\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"try\"]}]\n249:[\"$\",\"span\",\"code-segment-160\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, "])</script><script>self.__next_f.push([1,"24%)\"},\"children\":[\":\"]}]\n24a:[\"$\",\"span\",\"code-segment-161\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n24b:[\"$\",\"span\",\"code-segment-162\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      \"]}]\n24c:[\"$\",\"span\",\"code-segment-163\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"while\"]}]\n24d:[\"$\",\"span\",\"code-segment-164\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n24e:[\"$\",\"span\",\"code-segment-165\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"True\"]}]\n24f:[\"$\",\"span\",\"code-segment-166\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n250:[\"$\",\"span\",\"code-segment-167\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n251:[\"$\",\"span\",\"code-segment-168\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"          time\"]}]\n252:[\"$\",\"span\",\"code-segment-169\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n253:[\"$\",\"span\",\"code-segment-170\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"sleep\"]}]\n254:[\"$\",\"span\",\"code-segment-171\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n255:[\"$\",\"span\",\"code-segment-172\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"1\"]}]\n256:[\"$\",\"span\",\"code-segment-173\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n257:[\"$\",\"span\",\"code-segment-174\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n258:[\"$\",\"span\",\"code-segment-175\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n259:[\"$\",\"span\",\"code-segment-176\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"except\"]}]\n25a:[\"$\",\"span\",\"code-segment-177\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" KeyboardInterrupt\"]}]\n25b:[\"$\",\"span\",\"code-segment-178\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n25c:[\"$\",\"span\",\"code-segment-179\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n25d:[\"$\",\"span\",\"code-segment-180\",{\""])</script><script>self.__next_f.push([1,"className\":\"$undefined\",\"style\":{},\"children\":[\"      \"]}]\n25e:[\"$\",\"span\",\"code-segment-181\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"print\"]}]\n25f:[\"$\",\"span\",\"code-segment-182\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n260:[\"$\",\"span\",\"code-segment-183\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"Script stopped by user.\\\"\"]}]\n261:[\"$\",\"span\",\"code-segment-184\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n262:[\"$\",\"span\",\"code-segment-185\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n263:[\"$\",\"span\",\"code-segment-187\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n264:[\"$\",\"span\",\"code-segment-188\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"def\"]}]\n265:[\"$\",\"span\",\"code-segment-189\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n266:[\"$\",\"span\",\"code-segment-190\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"run_decode\"]}]\n267:[\"$\",\"span\",\"code-segment-191\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n268:[\"$\",\"span\",\"code-segment-192\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prefill_done\"]}]\n269:[\"$\",\"span\",\"code-segment-193\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n26a:[\"$\",\"span\",\"code-segment-194\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n26b:[\"$\",\"span\",\"code-segment-195\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n26c:[\"$\",\"span\",\"code-segment-196\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  os\"]}]\n26d:[\"$\",\"span\",\"code-segment-197\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n26e:[\"$\",\"span\",\"code-segment-198\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"environ\"]}]\n26f:[\"$\",\"span\",\"code-segment-199\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"[\"]}]\n270:[\"$\",\"span\",\"code-segment-200\",{\"classN"])</script><script>self.__next_f.push([1,"ame\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"CUDA_VISIBLE_DEVICES\\\"\"]}]\n271:[\"$\",\"span\",\"code-segment-201\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"]\"]}]\n272:[\"$\",\"span\",\"code-segment-202\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n273:[\"$\",\"span\",\"code-segment-203\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n274:[\"$\",\"span\",\"code-segment-204\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n275:[\"$\",\"span\",\"code-segment-205\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"1\\\"\"]}]\n276:[\"$\",\"span\",\"code-segment-206\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n277:[\"$\",\"span\",\"code-segment-208\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  sampling_params \"]}]\n278:[\"$\",\"span\",\"code-segment-209\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n279:[\"$\",\"span\",\"code-segment-210\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" SamplingParams\"]}]\n27a:[\"$\",\"span\",\"code-segment-211\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n27b:[\"$\",\"span\",\"code-segment-212\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"temperature\"]}]\n27c:[\"$\",\"span\",\"code-segment-213\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n27d:[\"$\",\"span\",\"code-segment-214\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0\"]}]\n27e:[\"$\",\"span\",\"code-segment-215\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n27f:[\"$\",\"span\",\"code-segment-216\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" top_p\"]}]\n280:[\"$\",\"span\",\"code-segment-217\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n281:[\"$\",\"span\",\"code-segment-218\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0.95\"]}]\n282:[\"$\",\"span\",\"code-segment-219\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n283:[\"$\",\"span\""])</script><script>self.__next_f.push([1,",\"code-segment-220\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n284:[\"$\",\"span\",\"code-segment-222\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  ktc\"]}]\n285:[\"$\",\"span\",\"code-segment-223\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n286:[\"$\",\"span\",\"code-segment-224\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"KVTransferConfig\"]}]\n287:[\"$\",\"span\",\"code-segment-225\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n288:[\"$\",\"span\",\"code-segment-226\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n289:[\"$\",\"span\",\"code-segment-227\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_connector\"]}]\n28a:[\"$\",\"span\",\"code-segment-228\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n28b:[\"$\",\"span\",\"code-segment-229\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"SharedStorageConnector\\\"\"]}]\n28c:[\"$\",\"span\",\"code-segment-230\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n28d:[\"$\",\"span\",\"code-segment-231\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n28e:[\"$\",\"span\",\"code-segment-232\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_role\"]}]\n28f:[\"$\",\"span\",\"code-segment-233\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n290:[\"$\",\"span\",\"code-segment-234\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"kv_both\\\"\"]}]\n291:[\"$\",\"span\",\"code-segment-235\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n292:[\"$\",\"span\",\"code-segment-236\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n293:[\"$\",\"span\",\"code-segment-237\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"      kv_connector_extra_config\"]}]\n294:[\"$\",\"span\",\"code-segment-238\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n295:[\"$\",\"span\",\"code-segment-239\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\""])</script><script>self.__next_f.push([1,":[\"{\"]}]\n296:[\"$\",\"span\",\"code-segment-240\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"shared_storage_path\\\"\"]}]\n297:[\"$\",\"span\",\"code-segment-241\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n298:[\"$\",\"span\",\"code-segment-242\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n299:[\"$\",\"span\",\"code-segment-243\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"local_storage\\\"\"]}]\n29a:[\"$\",\"span\",\"code-segment-244\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"}\"]}]\n29b:[\"$\",\"span\",\"code-segment-245\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n29c:[\"$\",\"span\",\"code-segment-246\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n29d:[\"$\",\"span\",\"code-segment-247\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n29e:[\"$\",\"span\",\"code-segment-248\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n29f:[\"$\",\"span\",\"code-segment-249\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2a0:[\"$\",\"span\",\"code-segment-251\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  llm \"]}]\n2a1:[\"$\",\"span\",\"code-segment-252\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2a2:[\"$\",\"span\",\"code-segment-253\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" LLM\"]}]\n2a3:[\"$\",\"span\",\"code-segment-254\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2a4:[\"$\",\"span\",\"code-segment-255\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"model\"]}]\n2a5:[\"$\",\"span\",\"code-segment-256\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2a6:[\"$\",\"span\",\"code-segment-257\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\\\"\"]}]\n2a7:[\"$\",\"span\",\"code-segment-258\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2a8:[\"$\",\"span\",\"code-segment-259\",{\"className\":\"$undefined\",\"st"])</script><script>self.__next_f.push([1,"yle\":{},\"children\":[\" kv_transfer_config\"]}]\n2a9:[\"$\",\"span\",\"code-segment-260\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2aa:[\"$\",\"span\",\"code-segment-261\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"ktc\"]}]\n2ab:[\"$\",\"span\",\"code-segment-262\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2ac:[\"$\",\"span\",\"code-segment-263\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2ad:[\"$\",\"span\",\"code-segment-265\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_done\"]}]\n2ae:[\"$\",\"span\",\"code-segment-266\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n2af:[\"$\",\"span\",\"code-segment-267\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"wait\"]}]\n2b0:[\"$\",\"span\",\"code-segment-268\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2b1:[\"$\",\"span\",\"code-segment-269\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2b2:[\"$\",\"span\",\"code-segment-270\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n2b3:[\"$\",\"span\",\"code-segment-271\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 4%, 64%)\",\"fontStyle\":\"italic\"},\"children\":[\"# block waiting for KV cache from prefill instance\"]}]\n2b4:[\"$\",\"span\",\"code-segment-272\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2b5:[\"$\",\"span\",\"code-segment-274\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n2b6:[\"$\",\"span\",\"code-segment-275\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 4%, 64%)\",\"fontStyle\":\"italic\"},\"children\":[\"# Internally it'll first fetch KV cache before starting the decoding loop\"]}]\n2b7:[\"$\",\"span\",\"code-segment-276\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2b8:[\"$\",\"span\",\"code-segment-277\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  outputs \"]}]\n2b9:[\"$\",\"span\",\"code-segment-278\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2ba:[\"$\",\"span\",\"code-segment-279\",{\"className\":\"$undefined\",\"style\":{},\"children\":"])</script><script>self.__next_f.push([1,"[\" llm\"]}]\n2bb:[\"$\",\"span\",\"code-segment-280\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n2bc:[\"$\",\"span\",\"code-segment-281\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"generate\"]}]\n2bd:[\"$\",\"span\",\"code-segment-282\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2be:[\"$\",\"span\",\"code-segment-283\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prompts\"]}]\n2bf:[\"$\",\"span\",\"code-segment-284\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2c0:[\"$\",\"span\",\"code-segment-285\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" sampling_params\"]}]\n2c1:[\"$\",\"span\",\"code-segment-286\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2c2:[\"$\",\"span\",\"code-segment-287\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2c3:[\"$\",\"span\",\"code-segment-289\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\"]}]\n2c4:[\"$\",\"span\",\"code-segment-290\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(301, 63%, 40%)\"},\"children\":[\"if\"]}]\n2c5:[\"$\",\"span\",\"code-segment-291\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" __name__ \"]}]\n2c6:[\"$\",\"span\",\"code-segment-292\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"==\"]}]\n2c7:[\"$\",\"span\",\"code-segment-293\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" \"]}]\n2c8:[\"$\",\"span\",\"code-segment-294\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(119, 34%, 47%)\"},\"children\":[\"\\\"__main__\\\"\"]}]\n2c9:[\"$\",\"span\",\"code-segment-295\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\":\"]}]\n2ca:[\"$\",\"span\",\"code-segment-296\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2cb:[\"$\",\"span\",\"code-segment-297\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_done \"]}]\n2cc:[\"$\",\"span\",\"code-segment-298\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2cd:[\"$\",\"span\",\"code-segment-299\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" Event\"]}]\n2ce:[\"$\",\"span\",\"code-segment-300\",{"])</script><script>self.__next_f.push([1,"\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2cf:[\"$\",\"span\",\"code-segment-301\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2d0:[\"$\",\"span\",\"code-segment-302\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2d1:[\"$\",\"span\",\"code-segment-303\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_process \"]}]\n2d2:[\"$\",\"span\",\"code-segment-304\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2d3:[\"$\",\"span\",\"code-segment-305\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" Process\"]}]\n2d4:[\"$\",\"span\",\"code-segment-306\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2d5:[\"$\",\"span\",\"code-segment-307\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"target\"]}]\n2d6:[\"$\",\"span\",\"code-segment-308\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2d7:[\"$\",\"span\",\"code-segment-309\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"run_prefill\"]}]\n2d8:[\"$\",\"span\",\"code-segment-310\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2d9:[\"$\",\"span\",\"code-segment-311\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" args\"]}]\n2da:[\"$\",\"span\",\"code-segment-312\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2db:[\"$\",\"span\",\"code-segment-313\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2dc:[\"$\",\"span\",\"code-segment-314\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prefill_done\"]}]\n2dd:[\"$\",\"span\",\"code-segment-315\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2de:[\"$\",\"span\",\"code-segment-316\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2df:[\"$\",\"span\",\"code-segment-317\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2e0:[\"$\",\"span\",\"code-segment-318\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2e1:[\"$\",\"span\",\"code-segment-319\",{\"className\":\"$unde"])</script><script>self.__next_f.push([1,"fined\",\"style\":{},\"children\":[\"  decode_process \"]}]\n2e2:[\"$\",\"span\",\"code-segment-320\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2e3:[\"$\",\"span\",\"code-segment-321\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" Process\"]}]\n2e4:[\"$\",\"span\",\"code-segment-322\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2e5:[\"$\",\"span\",\"code-segment-323\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"target\"]}]\n2e6:[\"$\",\"span\",\"code-segment-324\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2e7:[\"$\",\"span\",\"code-segment-325\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"run_decode\"]}]\n2e8:[\"$\",\"span\",\"code-segment-326\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2e9:[\"$\",\"span\",\"code-segment-327\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\" args\"]}]\n2ea:[\"$\",\"span\",\"code-segment-328\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"=\"]}]\n2eb:[\"$\",\"span\",\"code-segment-329\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2ec:[\"$\",\"span\",\"code-segment-330\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"prefill_done\"]}]\n2ed:[\"$\",\"span\",\"code-segment-331\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\",\"]}]\n2ee:[\"$\",\"span\",\"code-segment-332\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2ef:[\"$\",\"span\",\"code-segment-333\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2f0:[\"$\",\"span\",\"code-segment-334\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2f1:[\"$\",\"span\",\"code-segment-336\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_process\"]}]\n2f2:[\"$\",\"span\",\"code-segment-337\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n2f3:[\"$\",\"span\",\"code-segment-338\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"start\"]}]\n2f4:[\"$\",\"span\",\"code-segment-339\",{\"className\":\"token\",\"style\":{\"color\":\"hsl"])</script><script>self.__next_f.push([1,"(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2f5:[\"$\",\"span\",\"code-segment-340\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2f6:[\"$\",\"span\",\"code-segment-341\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2f7:[\"$\",\"span\",\"code-segment-342\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  decode_process\"]}]\n2f8:[\"$\",\"span\",\"code-segment-343\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n2f9:[\"$\",\"span\",\"code-segment-344\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"start\"]}]\n2fa:[\"$\",\"span\",\"code-segment-345\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n2fb:[\"$\",\"span\",\"code-segment-346\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n2fc:[\"$\",\"span\",\"code-segment-347\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n2fd:[\"$\",\"span\",\"code-segment-349\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  decode_process\"]}]\n2fe:[\"$\",\"span\",\"code-segment-350\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n2ff:[\"$\",\"span\",\"code-segment-351\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"join\"]}]\n300:[\"$\",\"span\",\"code-segment-352\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n301:[\"$\",\"span\",\"code-segment-353\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]\n302:[\"$\",\"span\",\"code-segment-354\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n303:[\"$\",\"span\",\"code-segment-355\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  prefill_process\"]}]\n304:[\"$\",\"span\",\"code-segment-356\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\".\"]}]\n305:[\"$\",\"span\",\"code-segment-357\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"terminate\"]}]\n306:[\"$\",\"span\",\"code-segment-358\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\"(\"]}]\n307:[\"$\",\"span\",\"code-segment-359\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(230, 8%, 24%)\"},\"children\":[\")\"]}]"])</script><script>self.__next_f.push([1,"\n308:[\"$\",\"span\",\"code-segment-360\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n309:[\"$\",\"span\",\"code-segment-39\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n30a:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n30b:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n30c:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n30d:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n30e:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n30f:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n310:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"start\"]}]\n311:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n312:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"rank \"]}]\n313:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"0\"]}]\n314:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n315:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n316:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n317:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n318:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n319:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n31a:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n31b:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"chi"])</script><script>self.__next_f.push([1,"ldren\":[\"-\"]}]\n31c:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"address \"]}]\n31d:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003c\"]}]\n31e:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"master\"]}]\n31f:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n320:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"ip\"]}]\n321:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003e\"]}]\n322:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n323:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n324:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n325:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n326:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n327:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n328:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n329:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n32a:[\"$\",\"span\",\"code-segment-72\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"rpc\"]}]\n32b:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n32c:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"port \"]}]\n32d:[\"$\",\"span\",\"code-segment-75\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"13345\"]}]\n32e:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n32f:[\"$\",\"span\",\"code-segment-77\",{\"className\":\"$undefined\",\"style\":{},\"children\""])</script><script>self.__next_f.push([1,":[\"  \"]}]\n330:[\"$\",\"span\",\"code-segment-78\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n331:[\"$\",\"span\",\"code-segment-79\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n332:[\"$\",\"span\",\"code-segment-80\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"headless\\n\"]}]\n333:[\"$\",\"span\",\"code-segment-39\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n334:[\"$\",\"span\",\"code-segment-40\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n335:[\"$\",\"span\",\"code-segment-41\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n336:[\"$\",\"span\",\"code-segment-42\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n337:[\"$\",\"span\",\"code-segment-43\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n338:[\"$\",\"span\",\"code-segment-44\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n339:[\"$\",\"span\",\"code-segment-45\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n33a:[\"$\",\"span\",\"code-segment-46\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"start\"]}]\n33b:[\"$\",\"span\",\"code-segment-47\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n33c:[\"$\",\"span\",\"code-segment-48\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"rank \"]}]\n33d:[\"$\",\"span\",\"code-segment-49\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"2\"]}]\n33e:[\"$\",\"span\",\"code-segment-50\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n33f:[\"$\",\"span\",\"code-segment-51\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n340:[\"$\",\"span\",\"code-segment-52\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n341:[\"$\",\"span\",\"code-segment-53\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n342:[\"$\",\"span\",\"code-segment-54\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n343:[\"$\",\"span\",\"code-segment-55\",{\"className\":\"token\",\"style\":{\"c"])</script><script>self.__next_f.push([1,"olor\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n344:[\"$\",\"span\",\"code-segment-56\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n345:[\"$\",\"span\",\"code-segment-57\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n346:[\"$\",\"span\",\"code-segment-58\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"address \"]}]\n347:[\"$\",\"span\",\"code-segment-59\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003c\"]}]\n348:[\"$\",\"span\",\"code-segment-60\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"master\"]}]\n349:[\"$\",\"span\",\"code-segment-61\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n34a:[\"$\",\"span\",\"code-segment-62\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"ip\"]}]\n34b:[\"$\",\"span\",\"code-segment-63\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"\u003e\"]}]\n34c:[\"$\",\"span\",\"code-segment-64\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n34d:[\"$\",\"span\",\"code-segment-65\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"  \"]}]\n34e:[\"$\",\"span\",\"code-segment-66\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n34f:[\"$\",\"span\",\"code-segment-67\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n350:[\"$\",\"span\",\"code-segment-68\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"data\"]}]\n351:[\"$\",\"span\",\"code-segment-69\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n352:[\"$\",\"span\",\"code-segment-70\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"parallel\"]}]\n353:[\"$\",\"span\",\"code-segment-71\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n354:[\"$\",\"span\",\"code-segment-72\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"rpc\"]}]\n355:[\"$\",\"span\",\"code-segment-73\",{\"className\":\"token\",\"style\":{\"color\":\"hsl(221, 87%, 60%)\"},\"children\":[\"-\"]}]\n356:[\"$\",\"span\",\"code-segment-74\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"port \"]}]\n357:[\"$\",\"span\",\"code-segment-75\",{\"className\""])</script><script>self.__next_f.push([1,":\"token\",\"style\":{\"color\":\"hsl(35, 99%, 36%)\"},\"children\":[\"13345\"]}]\n358:[\"$\",\"span\",\"code-segment-76\",{\"className\":\"$undefined\",\"style\":{},\"children\":[\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"35e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n35a:null\n"])</script><script>self.__next_f.push([1,"362:I[622,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"35c:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"How does vLLM work,how vllm works,vLLM explained,AGI,artificial intelligence,ASI,technology,vLLM,inference,engine\"}],[\"$\",\"meta\",\"3\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"link\",\"4\",{\"rel\":\"canonical\",\"href\":\"https://aleksagordic.com/blog/vllm\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:title\",\"content\":\"Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:description\",\"content\":\"From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale.\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://aleksagordic.com/blog/vllm/engine_constructor.png\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"vLLM\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:creator\",\"content\":\"@gordic_aleksa\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale.\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://aleksagordic.com/blog/vllm/engine_constructor.png\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:image:alt\",\"content\":\"vLLM\"}],[\"$\",\"link\",\"19\",{\"rel\":\"icon\",\"href\":\"/profile_favicon.ico\"}],[\"$\",\"$L362\",\"20\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"361:\"$35c:metadata\"\n"])</script><next-route-announcer style="position: absolute;"><template shadowrootmode="open"><div aria-live="assertive" id="__next-route-announcer__" role="alert" style="position: absolute; border: 0px; height: 1px; margin: -1px; padding: 0px; width: 1px; clip: rect(0px, 0px, 0px, 0px); overflow: hidden; white-space: nowrap; overflow-wrap: normal;"></div></template></next-route-announcer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "‚Äã";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* ÂΩìÂè™Êúâ‰∏§‰∏™Â∞èÁªÑ‰ª∂Êó∂ÁöÑÊ†∑Âºè‰ºòÂåñ */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup Âä®ÁîªÊïàÊûú */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 196px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg hidden="true" class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="ÂÖ≥Èó≠ÊÇ¨ÊµÆÁêÉ" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 196px; right: 65px;"></div></div></div></div></template></div></html>